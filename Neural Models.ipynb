{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Never do this, but warnings are annoying so I'm blocking them\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import keras.layers  as  klayers \n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, LSTM, Input, Embedding, GlobalAveragePooling1D, Concatenate, Activation, Lambda, BatchNormalization, Convolution1D, Dropout, merge\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "from keras.layers import Activation, Dense, BatchNormalization, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.activations import relu\n",
    "from keras.backend import reshape\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from skll.metrics import kappa\n",
    "from scipy import stats\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Import custom NEA layers\n",
    "from nea import Attention, MeanOverTime, Conv1DWithMasking\n",
    "from ats import Temporal_Mean_Pooling, Neural_Tensor_layer\n",
    "\n",
    "from essaysenseOther import load_asap, load_glove\n",
    "from essaysenseUtils import ASAPDataSet, SentenceLevelTestSet\n",
    "\n",
    "from customUtils import preprocess_asap, get_optimizer, limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NEA_HyperParameters:\n",
    "    def __init__(self):\n",
    "        self.method='lstm'     # gru, rnn, lstm\n",
    "        self.optimizer='adam'  # def: adam\n",
    "        self.aggregation='tmp' # tmp (ATS), mot (NEA), attsum, attmean, or nothing\n",
    "        self.dropout_prob=0    # def: 0.5; '0' for no dropout\n",
    "        self.cnn_dim=300       # '0' mean no CNN layer\n",
    "        self.rnn_dim=300\n",
    "        self.cnn_window_size=3 # def: 3\n",
    "        self.dropout_W = 0.5\n",
    "        self.dropout_U = 0.1   \n",
    "        self.cnn_border_mode='same' \n",
    "        self.activation=\"relu\"\n",
    "        self.maxlen=500        # TAKEN FROM ATSUTILS.PY\n",
    "        self.seed=1024\n",
    "nea_hp = NEA_HyperParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EssaySense_HyperParameters:\n",
    "    def __init__(self):\n",
    "        self.train_epochs = 700  # General training epochs.\n",
    "        self.w_dim = 50          # Word embedding dimension.\n",
    "        self.s_len = 20          # Sentence length in the sentence-level models.\n",
    "        self.e_len = 60          # Essay length in the sentence-level models.\n",
    "        self.w_window_len = 5    # Convolution window size of word level.\n",
    "        self.s_window_len = 3    # Convolution window size of sentence level.\n",
    "        self.w_convunits_size = 64 # Convolution unit number of word level.\n",
    "        self.s_convunits_size = 32 # Convolution unit number of sentence level.\n",
    "        self.hidden_size = 100     # Dense layer size of sentence-level models.\n",
    "        self.batch_size = 20       # Batch size.\n",
    "        self.learning_rate = 0.006 # Initial learning rate.\n",
    "        self.dropout_keep_prob = 0.3       # Dropout rate.\n",
    "        self.lstm_hidden_size = 150        # Dense layer size of LSTM models.\n",
    "        self.cnn_lstm_convunits_size = 80  # Conv units of CNN-LSTM models.\n",
    "        self.cnn_lstm_att_pool_size = 50   # Attention pool size.\n",
    "es_hp = EssaySense_HyperParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Score: 1.0 | Max Score: 6.0\n"
     ]
    }
   ],
   "source": [
    "prompt = '2'\n",
    "VALIDATION_SPLIT=0.30\n",
    "TEST_SPLIT=0.50\n",
    "range_max, range_min = limits(prompt)\n",
    "glove_dir = \"glove.6B.300d.txt\"\n",
    "data_dir = \"data/training_set.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing GloVe embedding...\n",
      "Embedding done!\n",
      "Min Score: 1.0 | Max Score: 6.0\n",
      "Number of Training Essays: 1800\n",
      "Found 14685 unique tokens!\n",
      "Shape of data tensor: (1800, 500)\n",
      "Splitting training/test data...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# NEA PREPROCESSING\n",
    "x_train, y_train, x_val, y_val, x_test, y_test, embedding_layer = preprocess_asap(prompt,VALIDATION_SPLIT,TEST_SPLIT, glove_dir, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loading] ASAP-AES domain 1 dataset...\n"
     ]
    }
   ],
   "source": [
    "# ESSAYSENSE PREPROCESSING\n",
    "glove_table = load_glove(es_hp, glove_dir)\n",
    "asap_train = load_asap(domain_id=prompt)\n",
    "\n",
    "asap_processed = SentenceLevelTestSet(\n",
    "    hyperparameters=es_hp,\n",
    "    lookup_table=glove_table,\n",
    "    raw_test_set=asap_train)\n",
    "train_essays, train_scores = asap_processed.all()\n",
    "\n",
    "indices=np.arange(train_essays.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "train_essays=train_essays[indices]\n",
    "train_scores=train_scores[indices]\n",
    "validation_size=int(VALIDATION_SPLIT*train_essays.shape[0])\n",
    "\n",
    "x_train=train_essays[:-validation_size]\n",
    "y_train=train_scores[:-validation_size]\n",
    "x_notrain=train_essays[-validation_size:]\n",
    "y_notrain=train_scores[-validation_size:]\n",
    "\n",
    "test_size=int(TEST_SPLIT*x_notrain.shape[0])\n",
    "x_val=x_notrain[:-test_size]\n",
    "y_val=y_notrain[:-test_size]\n",
    "x_test=x_notrain[-test_size:]\n",
    "y_test=y_notrain[-test_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi-directional LSTM\n",
    "def BLSTM(hp):    \n",
    "    # Embedding Layer\n",
    "    e = Input(name='essay',shape=(hp.maxlen,))\n",
    "    embed = embedding_layer(e)\n",
    "    \n",
    "    # BLSTM Layer\n",
    "    if hp.rnn_dim > 0:\n",
    "        forwards = LSTM(hp.rnn_dim, return_sequences=True, dropout_W=hp.dropout_W, dropout_U=hp.dropout_U)(embed)\n",
    "        backwards = LSTM(hp.rnn_dim, return_sequences=True, dropout_W=hp.dropout_W, dropout_U=hp.dropout_U, go_backwards=True)(embed)\n",
    "    if hp.dropout_prob > 0:\n",
    "        forwards = Dropout(hp.dropout_prob)(forwards)\n",
    "        backwards = Dropout(hp.dropout_prob)(backwards)\n",
    "    forwards_mean = MeanOverTime(mask_zero=True)(forwards)\n",
    "    backwards_mean = MeanOverTime(mask_zero=True)(backwards)\n",
    "    merged = merge([forwards_mean, backwards_mean], mode='concat', concat_axis=-1)\n",
    "    drop = Dense(num_outputs)(merged)\n",
    "    \n",
    "    # Optional Dropout Layer\n",
    "    if hp.dropout_prob > 0:\n",
    "        drop=Dropout(hp.dropout_prob)(hidden_states)\n",
    "    else:\n",
    "        drop=hidden_states\n",
    "    \n",
    "    # Aggregation Methods\n",
    "    if hp.aggregation == 'mot':\n",
    "        htm=MeanOverTime(mask_zero=True)(drop)\n",
    "    elif hp.aggregation == 'tmp':\n",
    "        htm=Temporal_Mean_Pooling()(drop)\n",
    "    elif hp.aggregation.startswith('att'):\n",
    "        htm=Attention(op=hp.aggregation, activation='tanh', init_stdev=0.01)(drop)\n",
    "    \n",
    "    # Connected Hidden Layer\n",
    "    dense = Dense(256, activation=hp.activation,kernel_initializer=initializers.glorot_normal(seed=hp.seed))(htm)\n",
    "    dense = Dense(128, activation=hp.activation,kernel_initializer=initializers.glorot_normal(seed=hp.seed))(dense)\n",
    "    dense = Dense(64, activation=hp.activation,kernel_initializer=initializers.glorot_normal(seed=hp.seed))(dense)\n",
    "    out = Dense(1, activation=\"sigmoid\")(dense)\n",
    "    \n",
    "    # Model Compiler\n",
    "    model = Model(inputs=[e], outputs=[out])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=get_optimizer(hp.optimizer), metrics=[\"MSE\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEA-based Networks\n",
    "def nea(hp, embedding_layer):\n",
    "    # Debug Outputs\n",
    "    print('RNN: %s | CNN: %s | Agg: %s' % (hp.method, hp.cnn_dim, hp.aggregation))\n",
    "    \n",
    "    # Embedding Layer\n",
    "    e = Input(name='essay',shape=(hp.maxlen,))\n",
    "    embed = embedding_layer(e)\n",
    "\n",
    "    # Optional Convolutional Layer\n",
    "    if hp.cnn_dim > 0:\n",
    "        cnn_layer=Conv1DWithMasking(nb_filter=hp.cnn_dim, filter_length=hp.cnn_window_size, border_mode=hp.cnn_border_mode, subsample_length=1)(embed)\n",
    "        embed=cnn_layer\n",
    "    \n",
    "    # Network Layer\n",
    "    if hp.method == 'lstm': # Typically uses 'tmp' aggregation method\n",
    "        lstm_layer=LSTM(hp.rnn_dim,return_sequences=True) \n",
    "        hidden_states=lstm_layer(embed)\n",
    "    elif hp.method == 'rnn': \n",
    "        rnn_layer=SimpleRNN(hp.rnn_dim, return_sequences=True, dropout_W=hp.dropout_W, dropout_U=hp.dropout_U)\n",
    "        hidden_states=rnn_layer(embed)\n",
    "    elif hp.method == 'gru': \n",
    "        rnn_layer=GRU(hp.rnn_dim, return_sequences=True, dropout_W=hp.dropout_W, dropout_U=hp.dropout_U)\n",
    "        hidden_states=rnn_layer(embed)\n",
    "        \n",
    "    # Optional Dropout Layer\n",
    "    if hp.dropout_prob > 0:\n",
    "        drop=Dropout(hp.dropout_prob)(hidden_states)\n",
    "    else:\n",
    "        drop=hidden_states\n",
    "    \n",
    "    # Aggregation Methods\n",
    "    if hp.aggregation == 'mot':\n",
    "        htm=MeanOverTime(mask_zero=True)(drop)\n",
    "    elif hp.aggregation == 'tmp':\n",
    "        htm=Temporal_Mean_Pooling()(drop)\n",
    "    elif hp.aggregation.startswith('att'):\n",
    "        htm=Attention(op=hp.aggregation, activation='tanh', init_stdev=0.01)(drop)\n",
    "    \n",
    "    # Connected Hidden Layer\n",
    "    dense = Dense(256, activation=hp.activation,kernel_initializer=initializers.glorot_normal(seed=hp.seed))(htm)\n",
    "    dense = Dense(128, activation=hp.activation,kernel_initializer=initializers.glorot_normal(seed=hp.seed))(dense)\n",
    "    dense = Dense(64, activation=hp.activation,kernel_initializer=initializers.glorot_normal(seed=hp.seed))(dense)\n",
    "    out = Dense(1, activation=\"sigmoid\")(dense)\n",
    "    \n",
    "    # Model Compiler\n",
    "    model = Model(inputs=[e], outputs=[out])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=get_optimizer(hp.optimizer), metrics=[\"MSE\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def essaysense_cnn_lstm(hp):\n",
    "    optimizer = 'adam'\n",
    "    \n",
    "    essays = Input(name='essays',shape=(hp.e_len, hp.s_len, hp.w_dim))\n",
    "    \n",
    "    # Convolutional layer\n",
    "    conv1 = Conv2d(filters=cnn_lstm_convunits_size, kernel_size=[1, w_window_len], padding=\"same\", activation=tf.nn.relu)(essays)\n",
    "\n",
    "    # Attention pooling\n",
    "    att1_mat = tf.Variable(tf.truncated_normal([cnn_lstm_convunits_size, cnn_lstm_convunits_size]), dtype=tf.float32)\n",
    "    att1_bias = tf.Variable(tf.truncated_normal([1, 1, 1, cnn_lstm_convunits_size]),dtype=tf.float32)\n",
    "    att1_weight = tf.tensordot(conv1, att1_mat, axes=[3, 0]) + att1_bias\n",
    "    att1_weight = tf.nn.tanh(att1_weight)\n",
    "    att1_vec = tf.Variable(tf.truncated_normal([cnn_lstm_convunits_size, 1]), dtype=tf.float32)\n",
    "    att1_weight = tf.tensordot(att1_weight, att1_vec, axes=[3, 0])\n",
    "    att1_weight = tf.nn.softmax(att1_weight, dim=2)\n",
    "    att1_output = att1_weight * conv1\n",
    "    att1_output = tf.reduce_sum(att1_output, axis=2)\n",
    "\n",
    "    # Long Short-Term Memory layer\n",
    "    lstm_cell = tfrnn.BasicLSTMCell(num_units=cnn_lstm_att_pool_size)\n",
    "    lstm_cell = tfrnn.DropoutWrapper(cell=lstm_cell, output_keep_prob=dropout_keep_prob)\n",
    "    init_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "    lstm, _ = tf.nn.dynamic_rnn(lstm_cell, att1_output, dtype=tf.float32)\n",
    "\n",
    "    # Attention pooling\n",
    "    att2_mat = tf.Variable(tf.truncated_normal([cnn_lstm_att_pool_size,cnn_lstm_att_pool_size]), dtype=tf.float32)\n",
    "    att2_bias = tf.Variable(tf.truncated_normal([1, 1, cnn_lstm_att_pool_size]), dtype=tf.float32)\n",
    "    att2_weight = tf.tensordot(lstm, att2_mat, axes=[2, 0])\n",
    "    att2_weight = tf.nn.tanh(att2_weight)\n",
    "    att2_vec = tf.Variable(tf.truncated_normal([cnn_lstm_att_pool_size, 1]), dtype=tf.float32)\n",
    "    att2_weight = tf.tensordot(att2_weight, att2_vec, axes=[2, 0])\n",
    "    att2_weight = tf.nn.softmax(att2_weight, dim=1)\n",
    "    att2_output = att2_weight * lstm\n",
    "    att2_output = tf.reduce_sum(att2_output, axis=1)\n",
    "\n",
    "    # Dense layer\n",
    "    out = Dense(1, activation=\"sigmoid\")(att2_output)\n",
    "\n",
    "    # Model Compiler\n",
    "    model = Model(inputs=[essays], outputs=[out])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=get_optimizer(optimizer), metrics=[\"MSE\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def essaysense_cnn_cnn(hp):    \n",
    "    optimizer = 'adam'\n",
    "    \n",
    "    essays = Input(name='essays',shape=(hp.e_len, hp.s_len, hp.w_dim))\n",
    "    \n",
    "    # Convolutional layer 1\n",
    "    conv1 = Conv2D(filters=hp.w_convunits_size,kernel_size=[1, hp.w_window_len],padding=\"same\",activation=None)(essays)\n",
    "    bn1 = BatchNormalization()(conv1)\n",
    "    activated1 = bn1 # activated1 = relu(bn1)\n",
    "    pool1 = MaxPooling2D(pool_size=[1, hp.s_len], strides=1)(activated1)\n",
    "    \n",
    "    # Convolutional layer 2\n",
    "    conv2 = Conv2D(filters=hp.s_convunits_size,kernel_size=[hp.s_window_len, 1],padding=\"same\",activation=None)(pool1)\n",
    "    bn2 = BatchNormalization()(conv2)\n",
    "    activated2 = bn2 # activated2 = relu(bn2)\n",
    "    pool2 = MaxPooling2D(pool_size=[hp.e_len, 1], strides=1)(activated2)\n",
    "    pool2_flat = Flatten()(pool2) # pool2_flat = reshape(pool2, [-1, hp.s_convunits_size])\n",
    "    \n",
    "    # Dense layers\n",
    "    dense1 = Dense(hp.hidden_size, activation=\"relu\")(pool2_flat)\n",
    "    out = Dense(1, activation=\"sigmoid\")(dense1)\n",
    "\n",
    "    # Model Compiler\n",
    "    model = Model(inputs=[essays], outputs=[out])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=get_optimizer(optimizer), metrics=[\"MSE\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN: lstm | CNN: 300 | Agg: tmp\n"
     ]
    }
   ],
   "source": [
    "# sf_1 = essaysense_cnn_cnn()\n",
    "sf_1 = nea()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1260 samples, validate on 270 samples\n",
      "Epoch 1/100\n",
      "  60/1260 [>.............................] - ETA: 1:23 - loss: 0.0270 - MSE: 0.0270"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-d0295211ae7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mearlystopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_MSE\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m hist = sf_1.fit([x_train], y_train, batch_size=20, epochs=100,\n\u001b[1;32m----> 3\u001b[1;33m                 validation_data=([x_val], y_val), callbacks=[earlystopping])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "earlystopping = EarlyStopping(monitor=\"val_MSE\", patience=5)\n",
    "hist = sf_1.fit([x_train], y_train, batch_size=20, epochs=100,\n",
    "                validation_data=([x_val], y_val), callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23443742750354424\n"
     ]
    }
   ],
   "source": [
    "# BHKappa Evaluation\n",
    "y_pred=sf_1.predict([x_test])\n",
    "y_val_fin = [int(round(a*(range_max-range_min)+range_min)) for a in y_test]\n",
    "y_pred_fin =[int(round(a*(range_max-range_min)+range_min)) for a in y_pred.reshape(x_test.shape[0]).tolist()]\n",
    "print(cohen_kappa_score(y_val_fin,y_pred_fin,weights=\"quadratic\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(hist.history['MSE'])\n",
    "plt.plot(hist.history['val_MSE'])\n",
    "plt.title('Model MSE')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(testID, method, cnn):\n",
    "    VALIDATION_SPLIT=0.30\n",
    "    TEST_SPLIT=0.50\n",
    "    glove_dir = \"glove.6B.300d.txt\"\n",
    "    data_dir = \"data/training_set.tsv\"\n",
    "    earlystopping = EarlyStopping(monitor=\"val_MSE\", patience=10)\n",
    "\n",
    "    # Results File\n",
    "    results = open(\"models/%s_Results.txt\" % testID, \"w+\")\n",
    "    print(\"Model: %s\" % testID)\n",
    "    t0 = datetime.now()\n",
    "    \n",
    "    # Configure Hyperparameters\n",
    "    nea_hp.method = method\n",
    "    if cnn:\n",
    "        nea_hp.cnn_dim = 300\n",
    "    else:\n",
    "        nea_hp.cnn_dim = 0\n",
    "\n",
    "    # Pipeline to evaluate all prompts\n",
    "    for prompt in range(8):\n",
    "        prompt = str(prompt+1) # Ad-hoc because I'm a bad programmer\n",
    "        print(\"Prompt: %s\" % prompt)\n",
    "        range_max, range_min = limits(prompt)\n",
    "        \n",
    "        for fold in range(5):\n",
    "            fold = str(fold+1)\n",
    "            print(\"Fold %s\" % fold)\n",
    "            \n",
    "            # Model Training\n",
    "            x_train, y_train, x_val, y_val, x_test, y_test, embedding_layer = preprocess_asap(prompt,VALIDATION_SPLIT,TEST_SPLIT, glove_dir, data_dir)\n",
    "            sf_1 = nea(nea_hp, embedding_layer)\n",
    "            hist = sf_1.fit([x_train], y_train, batch_size=20, epochs=100, validation_data=([x_val], y_val), callbacks=[earlystopping])\n",
    "\n",
    "            # BHKappa Evaluation\n",
    "            y_pred=sf_1.predict([x_test])\n",
    "            y_val_fin = [int(round(a*(range_max-range_min)+range_min)) for a in y_test]\n",
    "            y_pred_fin =[int(round(a*(range_max-range_min)+range_min)) for a in y_pred.reshape(x_test.shape[0]).tolist()]\n",
    "            score = cohen_kappa_score(y_val_fin, y_pred_fin, weights=\"quadratic\")\n",
    "            results.write(\"%s \\n\" % score)\n",
    "            print(\"QWK, Prompt %s, Fold %s: %s\" % (prompt, fold, score))\n",
    "            \n",
    "            # Plot training & validation loss values\n",
    "            plt.plot(hist.history['f%s MSE' % fold])\n",
    "            plt.plot(hist.history['f%s val_MSE'])\n",
    "            plt.title('Model %s, Essay %s MSE' % (testID, prompt))\n",
    "            plt.ylabel('Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "            plt.savefig('models/graphs/%s_%s.png' % (testID, prompt))\n",
    "\n",
    "            # Save Model Weights (Eh)\n",
    "            # sf_1.save('models/%s_%s_model.h5' % (testID, prompt))\n",
    "            # sf_1.save_weights('models/%s_%s_weights.h5' % (testID, prompt))\n",
    "        results.write(\"\\n ---- \\n\")\n",
    "        plt.clf()\n",
    "    results.close()\n",
    "\n",
    "    t1 = datetime.now()\n",
    "    print('Processing time: {}'.format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LSTM_CNN\n",
      "Prompt: 1\n",
      "Min Score: 2.0 | Max Score: 12.0\n",
      "Fold 1\n",
      "Processing GloVe embedding...\n",
      "Embedding done!\n",
      "Min Score: 2.0 | Max Score: 12.0\n",
      "Number of Training Essays: 1783\n",
      "Found 16200 unique tokens!\n",
      "Shape of data tensor: (1783, 500)\n",
      "Splitting training/test data...\n",
      "Done.\n",
      "RNN: lstm | CNN: 300 | Agg: tmp\n",
      "WARNING:tensorflow:From C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:3794: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\David\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1249 samples, validate on 267 samples\n",
      "Epoch 1/100\n",
      "1249/1249 [==============================] - 42s 34ms/step - loss: 0.0242 - MSE: 0.0242 - val_loss: 0.0258 - val_MSE: 0.0258\n",
      "Epoch 2/100\n",
      "1249/1249 [==============================] - 42s 33ms/step - loss: 0.0189 - MSE: 0.0189 - val_loss: 0.0189 - val_MSE: 0.0189\n",
      "Epoch 3/100\n",
      "1249/1249 [==============================] - 42s 34ms/step - loss: 0.0171 - MSE: 0.0171 - val_loss: 0.0217 - val_MSE: 0.0217\n",
      "Epoch 4/100\n",
      "1249/1249 [==============================] - 44s 35ms/step - loss: 0.0206 - MSE: 0.0206 - val_loss: 0.0234 - val_MSE: 0.0234\n",
      "Epoch 5/100\n",
      "1249/1249 [==============================] - 42s 34ms/step - loss: 0.0170 - MSE: 0.0170 - val_loss: 0.0193 - val_MSE: 0.0193\n",
      "Epoch 6/100\n",
      "1249/1249 [==============================] - 41s 33ms/step - loss: 0.0142 - MSE: 0.0142 - val_loss: 0.0183 - val_MSE: 0.0183\n",
      "Epoch 7/100\n",
      "1249/1249 [==============================] - 41s 33ms/step - loss: 0.0120 - MSE: 0.0120 - val_loss: 0.0142 - val_MSE: 0.0142\n",
      "Epoch 8/100\n",
      "1249/1249 [==============================] - 42s 34ms/step - loss: 0.0113 - MSE: 0.0113 - val_loss: 0.0135 - val_MSE: 0.0135\n",
      "Epoch 9/100\n",
      "1249/1249 [==============================] - 41s 33ms/step - loss: 0.0097 - MSE: 0.0097 - val_loss: 0.0128 - val_MSE: 0.0128\n",
      "Epoch 10/100\n",
      " 880/1249 [====================>.........] - ETA: 11s - loss: 0.0098 - MSE: 0.0098"
     ]
    }
   ],
   "source": [
    "pipeline('LSTM_CNN','lstm',1)\n",
    "pipeline('LSTM','lstm',0)\n",
    "pipeline('RNN_CNN','rnn',1)\n",
    "pipeline('RNN','rnn',0)\n",
    "pipeline('GRU_CNN','gru',1)\n",
    "pipeline('GRU','gru',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
