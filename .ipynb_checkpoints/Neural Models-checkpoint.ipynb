{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Neural Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import keras.layers  as  klayers \n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, LSTM, Input, Embedding, GlobalAveragePooling1D, Concatenate, Activation, Lambda, BatchNormalization, Convolution1D, Dropout, merge, Activation, Dense, BatchNormalization, Conv2D, MaxPooling2D, Flatten, concatenate\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
    "from keras.models import Model\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.activations import relu\n",
    "from keras.backend import reshape\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from skll.metrics import kappa\n",
    "from scipy import stats\n",
    "\n",
    "# Import custom Keras, EssaySense, & hand-made functions\n",
    "from customLayers import Attention, MeanOverTime, Conv1DWithMasking, Temporal_Mean_Pooling, Neural_Tensor_layer\n",
    "from essaysenseUtils import load_asap, load_glove, ASAPDataSet, SentenceLevelTestSet\n",
    "from customUtils import preprocess_asap, get_optimizer, limits\n",
    "from utils import customLayers, essaysenseUtils, customUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NEA_HyperParameters:\n",
    "    def __init__(self):\n",
    "        self.method='blstm'    # gru, rnn, lstm, blstm\n",
    "        self.optimizer='adam'  # def: adam\n",
    "        self.aggregation='mot' # tmp (ATS), mot (NEA), attsum, attmean, or nothing\n",
    "        self.dropout_prob=0    # def: 0.5; '0' for no dropout\n",
    "        self.cnn_dim=300       # '0' mean no CNN layer\n",
    "        self.rnn_dim=300\n",
    "        self.cnn_window_size=3 # def: 3\n",
    "        self.dropout_W = 0.5\n",
    "        self.dropout_U = 0.1   \n",
    "        self.cnn_border_mode='same' \n",
    "        self.activation=\"relu\"\n",
    "        self.maxlen=500        # TAKEN FROM ATSUTILS.PY\n",
    "        self.seed=1024\n",
    "nea_hp = NEA_HyperParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EssaySense_HyperParameters:\n",
    "    def __init__(self):\n",
    "        self.train_epochs = 700  # General training epochs.\n",
    "        self.w_dim = 50          # Word embedding dimension.\n",
    "        self.s_len = 20          # Sentence length in the sentence-level models.\n",
    "        self.e_len = 60          # Essay length in the sentence-level models.\n",
    "        self.w_window_len = 5    # Convolution window size of word level.\n",
    "        self.s_window_len = 3    # Convolution window size of sentence level.\n",
    "        self.w_convunits_size = 64 # Convolution unit number of word level.\n",
    "        self.s_convunits_size = 32 # Convolution unit number of sentence level.\n",
    "        self.hidden_size = 100     # Dense layer size of sentence-level models.\n",
    "        self.batch_size = 20       # Batch size.\n",
    "        self.learning_rate = 0.006 # Initial learning rate.\n",
    "        self.dropout_keep_prob = 0.3       # Dropout rate.\n",
    "        self.lstm_hidden_size = 150        # Dense layer size of LSTM models.\n",
    "        self.cnn_lstm_convunits_size = 80  # Conv units of CNN-LSTM models.\n",
    "        self.cnn_lstm_att_pool_size = 50   # Attention pool size.\n",
    "es_hp = EssaySense_HyperParameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Models\n",
    "\n",
    "## Single-Word Embedding Networks\n",
    "This is the traditional-style network utilized in the paper. More experimental versions are tested below (see essaysesne)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nea(hp, embedding_layer):\n",
    "    # Debug Outputs\n",
    "    print('RNN: %s | CNN: %s | Agg: %s' % (hp.method, hp.cnn_dim, hp.aggregation))\n",
    "    \n",
    "    # Embedding Layer\n",
    "    e = Input(name='essay',shape=(hp.maxlen,))\n",
    "    embed = embedding_layer(e)\n",
    "\n",
    "    # Optional Convolutional Layer\n",
    "    if hp.cnn_dim > 0:\n",
    "        cnn_layer=Conv1DWithMasking(nb_filter=hp.cnn_dim, filter_length=hp.cnn_window_size, border_mode=hp.cnn_border_mode, subsample_length=1)(embed)\n",
    "        embed=cnn_layer\n",
    "    \n",
    "    # Network Layer\n",
    "    if hp.method == 'blstm': # Has everything rolled into one\n",
    "        if hp.rnn_dim > 0:\n",
    "            forwards = LSTM(hp.rnn_dim, return_sequences=True, dropout_W=hp.dropout_W, dropout_U=hp.dropout_U)(embed)\n",
    "            backwards = LSTM(hp.rnn_dim, return_sequences=True, dropout_W=hp.dropout_W, dropout_U=hp.dropout_U, go_backwards=True)(embed)\n",
    "        if hp.dropout_prob > 0:\n",
    "            forwards = Dropout(hp.dropout_prob)(forwards)\n",
    "            backwards = Dropout(hp.dropout_prob)(backwards)\n",
    "        if hp.aggregation == 'mot':\n",
    "            forwards_mean = MeanOverTime(mask_zero=True)(forwards)\n",
    "            backwards_mean = MeanOverTime(mask_zero=True)(backwards)\n",
    "        elif hp.aggregation == 'tmp':\n",
    "            forwards_mean = Temporal_Mean_Pooling()(forwards)\n",
    "            backwards_mean = Temporal_Mean_Pooling()(backwards)\n",
    "        elif hp.aggregation.startswith('att'):\n",
    "            forwards_mean = Attention(op=hp.aggregation, activation='tanh', init_stdev=0.01)(forwards)\n",
    "            backwards_mean = Attention(op=hp.aggregation, activation='tanh', init_stdev=0.01)(backwards)\n",
    "        merged = concatenate([forwards_mean, backwards_mean], axis=-1)\n",
    "        htm = Dense(hp.rnn_dim)(merged) # hidden_states = Dense(num_outputs)(merged)\n",
    "    else: # Dropout and aggregation layers split up\n",
    "        if hp.method == 'lstm': # Typically uses 'tmp' aggregation method\n",
    "            lstm_layer=LSTM(hp.rnn_dim,return_sequences=True) \n",
    "            hidden_states=lstm_layer(embed)\n",
    "        elif hp.method == 'rnn': \n",
    "            rnn_layer=SimpleRNN(hp.rnn_dim, return_sequences=True, dropout_W=hp.dropout_W, dropout_U=hp.dropout_U)\n",
    "            hidden_states=rnn_layer(embed)\n",
    "        elif hp.method == 'gru': \n",
    "            rnn_layer=GRU(hp.rnn_dim, return_sequences=True, dropout_W=hp.dropout_W, dropout_U=hp.dropout_U)\n",
    "            hidden_states=rnn_layer(embed)\n",
    "        else:\n",
    "            hidden_states=embed\n",
    "\n",
    "        # Optional Dropout Layer\n",
    "        if hp.dropout_prob > 0:\n",
    "            drop=Dropout(hp.dropout_prob)(hidden_states)\n",
    "        else:\n",
    "            drop=hidden_states\n",
    "\n",
    "        # Aggregation Methods\n",
    "        if hp.aggregation == 'mot':\n",
    "            htm=MeanOverTime(mask_zero=True)(drop)\n",
    "        elif hp.aggregation == 'tmp':\n",
    "            htm=Temporal_Mean_Pooling()(drop)\n",
    "        elif hp.aggregation.startswith('att'):\n",
    "            htm=Attention(op=hp.aggregation, activation='tanh', init_stdev=0.01)(drop)\n",
    "    \n",
    "    # Connected Hidden Layer\n",
    "    dense = Dense(256, activation=hp.activation,kernel_initializer=initializers.glorot_normal(seed=hp.seed))(htm)\n",
    "    dense = Dense(128, activation=hp.activation,kernel_initializer=initializers.glorot_normal(seed=hp.seed))(dense)\n",
    "    dense = Dense(64, activation=hp.activation,kernel_initializer=initializers.glorot_normal(seed=hp.seed))(dense)\n",
    "    out = Dense(1, activation=\"sigmoid\")(dense)\n",
    "    \n",
    "    # Model Compiler\n",
    "    model = Model(inputs=[e], outputs=[out])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=get_optimizer(hp.optimizer), metrics=[\"MSE\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '1'\n",
    "VALIDATION_SPLIT=0.30\n",
    "TEST_SPLIT=0.50\n",
    "range_max, range_min = limits(prompt)\n",
    "glove_dir = \"data/glove.6B.300d.txt\"\n",
    "data_dir = \"data/training_set.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1783, 500)\n",
      "Splitting training/test data\n"
     ]
    }
   ],
   "source": [
    "# NEA PREPROCESSING\n",
    "x_train, y_train, x_val, y_val, x_test, y_test, embedding_layer = preprocess_asap(prompt,VALIDATION_SPLIT,TEST_SPLIT, glove_dir, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN: gru | CNN: 0 | Agg: tmp\n"
     ]
    }
   ],
   "source": [
    "sf_1 = nea(nea_hp, embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "GPU sync failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: GPU sync failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d0295211ae7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mearlystopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_MSE\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m hist = sf_1.fit([x_train], y_train, batch_size=20, epochs=100,\n\u001b[1;32m----> 3\u001b[1;33m                 validation_data=([x_val], y_val), callbacks=[earlystopping])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1211\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m             \u001b[0mfit_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m         \u001b[0mfit_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    331\u001b[0m                     \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmetrics_updates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m                     \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train_function'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m                     **self._function_kwargs)\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[0;32m   3004\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3005\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_tf_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3006\u001b[1;33m         \u001b[0mv1_variable_initialization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3007\u001b[0m     return tf_keras_backend.function(inputs, outputs,\n\u001b[0;32m   3008\u001b[0m                                      \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mv1_variable_initialization\u001b[1;34m()\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mv1_variable_initialization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m     \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[1;34m'`get_session` is not available when '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             'TensorFlow is executing eagerly.')\n\u001b[1;32m--> 385\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf_keras_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m(op_input_list)\u001b[0m\n\u001b[0;32m    484\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m       \u001b[0m_initialize_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[1;34m(session)\u001b[0m\n\u001b[0;32m    901\u001b[0m     \u001b[1;31m# marked as initialized.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m     is_initialized = session.run(\n\u001b[1;32m--> 903\u001b[1;33m         [variables_module.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[0;32m    904\u001b[0m     \u001b[0muninitialized_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1384\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: GPU sync failed"
     ]
    }
   ],
   "source": [
    "earlystopping = EarlyStopping(monitor=\"val_MSE\", patience=5)\n",
    "hist = sf_1.fit([x_train], y_train, batch_size=20, epochs=100,\n",
    "                validation_data=([x_val], y_val), callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7904836078823235\n"
     ]
    }
   ],
   "source": [
    "# QWK Evaluation\n",
    "y_pred=sf_1.predict([x_test])\n",
    "y_val_fin = [int(round(a*(range_max-range_min)+range_min)) for a in y_test]\n",
    "y_pred_fin =[int(round(a*(range_max-range_min)+range_min)) for a in y_pred.reshape(x_test.shape[0]).tolist()]\n",
    "print(cohen_kappa_score(y_val_fin,y_pred_fin,weights=\"quadratic\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXxU1fn48c+TPWQDEtYESAgo+xLWBNyq9StaRS1VcF9pbd2qbb/W77ebrb/afq1V61ZRsFoLWvdarVaLC7KDhFVkhxCWBMi+J+f3x5mEEDJkJpnJnZk879drXpncuffOkxHnueeec54jxhiUUkopT4U5HYBSSqngoolDKaWUVzRxKKWU8oomDqWUUl7RxKGUUsormjiUUkp5RROHUn4gIukiYkQkwoN9bxCRJZ0Rl1K+oIlDdXkisltEakQkpcX2da4v/3RnIjshAa1tsT3FFfPuZtumi8hSESkWkaMi8oWITHK9doOI1ItIWYtH/07+k1QI0MShlLULmNP4i4iMBmKdC+ckcSIyqtnvV2FjBkBEEoF3gT8BPYFU4FdAdbNjlhlj4ls88jshdhViNHEoZb0EXNfs9+uBF5vvICJJIvKiiBSIyB4R+V8RCXO9Fi4iD4tIoYjsBC5q5djnReSAiOwXkd+ISLiX8V3f7PfrWsR3GoAxZqExpt4YU2mM+dAYs96L91DKI5o4lLKWA4kiMtz1hX4l8NcW+/wJSAIGA2dhv7xvdL12K/AtYDwwEZjV4ti/AHXAENc+5wO3eBHfX4HZrgQ1HEgAVjR7/WugXkT+IiIzRKSHF+dWyiuaOJQ6rrHV8U3gK2B/4wvNkslPjTGlxpjdwB+Aa127XAE8aozZZ4w5Cvy22bF9gBnA3caYcmPMYeCPwGwvYssDtgLn0UpryBhTAkwHDDAPKBCRd1zv3WiqiBQ1e+zw4v2VatLmiA+lupCXgM+ADFp8MQMpQBSwp9m2Pdi+BID+wL4WrzUaBEQCB0SkcVtYi/098SJwA5ADnAkMbf6iMWaL63VEZBi2lfIox/tulhtjpnv5nkqdRFscSrkYY/ZgO5wvBN5o8XIhUItNAo0GcrxVcgAY0OK1RvuwndQpxpjurkeiMWaklyG+ju072emK9VR/y1fAC8CoU+2nVHto4lDqRDcD3zDGlDffaIypB14FHhSRBBEZBNzD8X6QV4E7RSTN1b9wX7NjDwAfAn8QkUQRCRORTBE5y5vAXDF9g1b6RkRkmIjcKyJprt8HYFsay715D6U8oYlDqWaMMTuMMavdvHwHUA7sBJYAfwPmu16bB3wA5AJrObnFch32Vtdm4BjwGtCvHfGtNsa01jdRCkwBVohIOTZhbATubbZPdivzOCZ5G4NSogs5KaWU8oa2OJRSSnlFE4dSSimvaOJQSinlFU0cSimlvNIlJgCmpKSY9PR0p8NQSqmgsmbNmkJjTK+W27tE4khPT2f1ancjLJVSSrVGRFqdaKq3qpRSSnlFE4dSSimvaOJQSinllS7Rx9Ga2tpa8vLyqKqqcjqUkBETE0NaWhqRkZFOh6KU8qMumzjy8vJISEggPT2dZqWuVTsZYzhy5Ah5eXlkZGQ4HY5Syo+67K2qqqoqkpOTNWn4iIiQnJysLTiluoAumzgATRo+pp+nUl1Dl04cbTlSVk1RRY3TYSilVEDRxHEKRytqOFLun8Rx5MgRxo0bx7hx4+jbty+pqalNv9fUePaeN954I1u3bvVLfEop5U6X7Rz3RHx0BIVlNTQ0GMLCfHsbJjk5mXXr1gHwy1/+kvj4eH70ox+dsI8xBmMMYWGt5/cFCxb4NCallPKEtjhOIT46AmMM5TV1nfae27dvZ9SoUXzve98jKyuLAwcOMHfuXCZOnMjIkSN54IEHmvadPn0669ato66uju7du3PfffcxduxYsrOzOXz4cKfFrJTqWrTFAfzqH5vYnF/S6mvl1XVERoQRFe5djh3RP5FfXDyyXfFs3ryZBQsW8MwzzwDw0EMP0bNnT+rq6jjnnHOYNWsWI0aMOOGY4uJizjrrLB566CHuuece5s+fz3333dfa6ZVSqkO0xdGGsDChvqFzl9fNzMxk0qTjS0EvXLiQrKwssrKy2LJlC5s3bz7pmNjYWGbMmAHAhAkT2L17d2eFq5TqYrTFAadsGRwsrqKgtJoR/RMId9PX4GtxcXFNz7dt28Zjjz3GypUr6d69O9dcc02rcyWioqKanoeHh1NX13m315RSXYu2ONoQHx2OwVBeXe/I+5eUlJCQkEBiYiIHDhzggw8+cCQOpZRqpC2ONnSLikBEKKuuIzG282swZWVlMWLECEaNGsXgwYOZNm1ap8eglFLNiTGde//eCRMnTjQtF3LasmULw4cP9+j4nQVl1DcYhvZJ8Ed4IcWbz1UpFdhEZI0xZmLL7XqrygNx0RFU1tZTV9/gdChKKeU4TRweiI+2d/Q6cz6HUkoFKk0cHoiNCidMhDKHOsiVUiqQaOLwQJgIcdERlFVpi0MppTRxeCg+OpzqunpqtZ9DKdXFaeLwUFxjP0e1tjqUUl2bJg4PxUaGEx5m53P4wtlnn33SZL5HH32U73//+26PiY+PByA/P59Zs2a5PW/LocctPfroo1RUVDT9fuGFF1JUVORp6EqpLk4Th4dEhLioCJ8ljjlz5rBo0aITti1atIg5c+a0eWz//v157bXX2v3eLRPHe++9R/fu3dt9PqVU16KJwwvx0RHU1DVQU9fx0VWzZs3i3Xffpbq6GoDdu3eTn5/PuHHjOPfcc8nKymL06NG8/fbbJx27e/duRo0aBUBlZSWzZ89mzJgxXHnllVRWVjbtd9tttzWVY//FL34BwOOPP05+fj7nnHMO55xzDgDp6ekUFhYC8MgjjzBq1ChGjRrFo48+2vR+w4cP59Zbb2XkyJGcf/75J7yPUqpr0ZIjAO/fBwc3tLlbD2OIqalHIsOgrYKHfUfDjIfcvpycnMzkyZP517/+xcyZM1m0aBFXXnklsbGxvPnmmyQmJlJYWMjUqVO55JJL3K7n/fTTT9OtWzfWr1/P+vXrycrKanrtwQcfpGfPntTX13Puueeyfv167rzzTh555BEWL15MSkrKCedas2YNCxYsYMWKFRhjmDJlCmeddRY9evRg27ZtLFy4kHnz5nHFFVfw+uuvc80117T5mSmlQo+2OLwQJiCCz8qsN79d1XibyhjD/fffz5gxYzjvvPPYv38/hw4dcnuOzz77rOkLfMyYMYwZM6bptVdffZWsrCzGjx/Ppk2bWi3H3tySJUu47LLLiIuLIz4+nssvv5zPP/8cgIyMDMaNGwdo2XalujptccApWwbNCVB4pJyKmnqG9U1w2wrw1KWXXso999zD2rVrqaysJCsrixdeeIGCggLWrFlDZGQk6enprZZRPyGuVuLYtWsXDz/8MKtWraJHjx7ccMMNbZ7nVHXLoqOjm56Hh4frrSqlujBtcXgpPjqC2voGauo6Pp8jPj6es88+m5tuuqmpU7y4uJjevXsTGRnJ4sWL2bNnzynPceaZZ/Lyyy8DsHHjRtavXw/YcuxxcXEkJSVx6NAh3n///aZjEhISKC0tbfVcb731FhUVFZSXl/Pmm29yxhlndPjvVEqFFr8mDhG5QES2ish2ETlpHVMRiRaRV1yvrxCRdNf2ZBFZLCJlIvKEm3O/IyIb/Rl/axrrVvlydFVubi6zZ88G4Oqrr2b16tVMnDiRl19+mWHDhp3y+Ntuu42ysjLGjBnD73//eyZPngzA2LFjGT9+PCNHjuSmm246oRz73LlzmTFjRlPneKOsrCxuuOEGJk+ezJQpU7jlllsYP368T/5OpVTo8FtZdREJB74GvgnkAauAOcaYzc32+T4wxhjzPRGZDVxmjLlSROKA8cAoYJQx5vYW574cmOU6dlRbsXS0rHpzxhi+OlhKXFQ4A5Pj2j6gi9Gy6kqFDifKqk8GthtjdhpjaoBFwMwW+8wE/uJ6/hpwroiIMabcGLMEOOmmvIjEA/cAv/Ff6O6JCPHREZRV15+yT0AppUKVPxNHKrCv2e95rm2t7mOMqQOKgeQ2zvtr4A9Axal2EpG5IrJaRFYXFBR4E3eb4qIjqGtooNoH/RxKKRVs/Jk4Whty1PIS3ZN9ju8sMg4YYox5s603N8Y8a4yZaIyZ2KtXL3f7tHWaVsVHhwO+6+cIFdoCU6pr8GfiyAMGNPs9Dch3t4+IRABJwNFTnDMbmCAiu4ElwGki8kl7gouJieHIkSPt+rKLiggnKiJMy6w3Y4zhyJEjxMTEOB2KUsrP/DmPYxUwVEQygP3AbOCqFvu8A1wPLMN2dv/HnOKb3BjzNPA0gGsE1rvGmLPbE1xaWhp5eXm09zbWsYoaKmvqqTgcSwenc4SMmJgY0tLSnA5DKeVnfkscxpg6Ebkd+AAIB+YbYzaJyAPAamPMO8DzwEsish3b0pjdeLyrVZEIRInIpcD5zUdkdVRkZCQZGRntPv7tdfu56+11vHvHdEalJvkqLKWUCnh+nTlujHkPeK/Ftp83e14FfMfNseltnHs3driuI7IH2z78pTsKNXEopboUnTneTr0TY8jsFcfSHUecDkUppTqVJo4OyMlMYdWuo7qcrFKqS9HE0QHZmcmU19SzPq/Y6VCUUqrTaOLogKmufo5lOwodjkQppTqPJo4O6BkXxfB+iSzbqf0cSqmuQxNHB+VkJrN69zGqaju+nKxSSgUDTRwdlD04meq6Br7cW+R0KEop1Sk0cXTQ5ME9CRP0dpVSqsvQxNFBiTGRjE7rrh3kSqkuQxOHD2QPTubLvUVU1GjRQ6VU6NPE4QM5mcnUNRhW7T7mdChKKeV3mjh8YGJ6DyLDhWVafkQp1QVo4vCBblERjBug/RxKqa5BE4ePZGemsGF/MSVVtU6HopRSfqWJw0dyMpNpMLBy56kWMFRKqeCnicNHxg/sTnREmJZZV0qFPE0cPhIdEc7E9B4s1X4OpVSI08ThQzmZKXx1sJSj5TVOh6KUUn6jicOHsjNtmfXlWn5EKRXCNHH40OjUJOKiwvV2lVIqpGni8KHI8DAmZ/TUiYBKqZCmicPHcjJT2FFQzqGSKqdDUUopv9DE4WON/Rza6lBKhSpNHD42vF8iSbGRmjiUUiFLE4ePhYcJUwf3ZOlO7SBXSoUmTRx+kD04mX1HK9l3tMLpUJRSyuc0cfhBzpAUQPs5lFKhSROHHwztHU9KfJSuQ66UCkmaOPxARJg6OJmlOwoxxjgdjlJK+ZQmDj/JyUzhUEk1OwvLnQ5FKaV8ShOHn+TofA6lVIjSxOEng5K70S8pRhOHUirkaOLwExEhOzOZZTuP0NCg/RxKqdChicOPcjJTOFpew9eHS50ORSmlfEYThx811q1aul1vVymlQocmDj9K7R7LoORuug65UiqkaOLws5zMZFbsOkK99nMopUKEXxOHiFwgIltFZLuI3NfK69Ei8orr9RUiku7aniwii0WkTESeaLZ/NxH5p4h8JSKbROQhf8bvC9mZKZRW1bEpv9jpUJRSyif8ljhEJBx4EpgBjADmiMiIFrvdDBwzxgwB/gj8zrW9CvgZ8KNWTv2wMWYYMB6YJiIz/BG/r0wd3BNAb1cppUKGP1sck4HtxpidxpgaYBEws8U+M4G/uJ6/BpwrImKMKTfGLMEmkCbGmApjzGLX8xpgLZDmx7+hw3onxDC0d7zO51BKhQx/Jo5UYF+z3/Nc21rdxxhTBxQDyZ6cXES6AxcDH3c4Uj/LyUxm1e6j1NQ1OB2KUkp1mD8Th7SyrWUPsSf7nHxikQhgIfC4MWanm33mishqEVldUFDQZrD+lJ2ZTEVNPevzihyNQymlfMGfiSMPGNDs9zQg390+rmSQBBz14NzPAtuMMY+628EY86wxZqIxZmKvXr28CtzXpmQkI6J1q5QfrPkLrHre6ShUF+PPxLEKGCoiGSISBcwG3mmxzzvA9a7ns4D/mDbqkIvIb7AJ5m4fx9u6hvoOn6JHXBQj+iVqB7nyrdpK+PBn8MH9UOZsq1p1LX5LHK4+i9uBD4AtwKvGmE0i8oCIXOLa7XkgWUS2A/cATUN2RWQ38Ahwg4jkicgIEUkD/gc7SmutiKwTkVv88gc01MPCOfDRL31yuuzByazZe4yq2o4nIqUA2PoeVBdDXRWses7paFQXEuHPkxtj3gPea7Ht582eVwHfcXNsupvTttYv4nth4RCdCCvnQfbtkNCnQ6fLGZLMc0t2sXbPsaalZZXqkNxFkJgKfUbBqnkw7S6I6uZ0VKoL0Jnjp3LWT6C+Bpb8scOnmpTek/Aw0eVklW+UHoLtH8OYK2D63VBxBHIXOh2V6iI0cZxKciaMuwpWz4fi/R06VUJMJGPSkrSfQ/nGhr+DqYexc2BgNqROgGVP+qRPTqm2aOJoy1k/AdMAn/+hw6fKHpxM7r4iyqvrfBCY6tJyF0L/LOh1OohAzh1wdAdsfd/pyFQXoImjLd0HQtZ1sPZFOLanQ6fKyUyhrsGwarcnI46VcuPgBji00baGGw27GLoPgqV/ci4u1WVo4vDEmT8CCYPPft+h00wY1IOo8DCdz6E6JncRhEXCyMuPbwuPgOwfwL7lsG+lc7GpLkEThycS+8PEm2DdQjiyo92niY0KZ9zA7trPodqvvg7Wvwqn/RfEtajOM+5qiOmurQ7ld5o4PDX9hxAeBZ/+ru19TyEnM5lN+cUUV9T6KDDVpez4D5Qftp3iLUXHw6SbYcs/4GirlXiU8glNHJ5K6AOTb7VXewVb232anMwUGgys2KWtDtUOuX+D2J4w9PzWX588F8IjYdlTnRuX6lI0cXhj2t0QFQef/Lbdpxg7IImYyDC9XaW8V1kEX70Ho2dBRFTr+yT0tXM7vvwrVOggDOUfmji8EZcMU74Hm96EgxvbdYroiHAmpfdkuU4EVN7a9CbUV8PY2afeL/sOqKvU4oddXckB2LvCL6fWxOGtnNshOqlDrY7szGS+OlhKYVm1DwNTIS93EaScbudvnErvYTD0v2Dln6G26tT7qtC17AlYMMMmEB/TxOGt2B522ONX70L+l+06RfZgOxpGWx3KY0d22KG2Y2fbCX9tybkDygtg/Sv+j00FnsoiWPMCjLocEvv5/PSaONpj6m02gSz+f+06fHRqEvHRETqfQ3lu/SuAwJgrPds/fTr0G2evOht05ckuZ/XzUFMGOXf65fSaONojJtH+B9n2YbsmW0WEhzElo6cmDuWZhgZbYmTwWZDUcvVlNxrLkBR+Dds+8G98KrDUVsHyZyDzG9BvjF/ewqPEISKZIhLten62iNzpWvO765ryXYjrBYsfbNfh2ZnJ7Cws50BxpY8DUyFn7zIo2tv63I1TGXEpJA3QCYFdzfpFdq7PtLv89haetjheB+pFZAh28aUM4G9+iyoYRMXZSYE7P4HdX3h9eHam7ecImlZH2WF4+3b7BaY6V+5CiIyD4Rd7d1x4BEz9Puz5AvLW+Cc2FVga6u2FQr9xkHGW397G08TR4FrR7zLgUWPMDwHf97gEm4k3QUI/2+o49Yq3JxneN5Hu3SKDI3EYY5PGly/Bx792OpqupaYCNr0FI2baixVvZV1rRwEu01ZHl7D1PTiy3bY2PBlE0U6eJo5aEZmDXR/8Xde2SP+EFEQiY+GMe+0V3c5PvDo0LEzIHpzM0h1HaGOZdeet/Yu9T55yGmx8DQq3OR1R17H1PagphXFe3qZqFJ0AE2+EzW/Dsd0+DU0FGGNgyaPQIx2GX9Lm7h3haeK4EcgGHjTG7BKRDOCv/gsriGRdB4lp7Wp1ZGcms7+okn1HA7if4+gu+Nf9ttl7/bsQHg2f/Z/TUXUd6/5m+ykGTW//OaZ8FyQclj/tu7hU4Nm7DPavtktdh/t1VXDPEocxZrMx5k5jzEIR6QEkGGMe8mtkwSIiGs76MeStgm3/9urQnMZ+jp2F/ois4xrq4c3vQVgEXPqUrdc16Wa7+lzhdqejC30lB2DnYjsEN6wDAyAT+8Po78Dal7QMSShb8ih0S7ZVkv3M01FVn4hIooj0BHKBBSLyiH9DCyLjrrbNw8W/8arVkdkrnl4J0YFbt2rp43bS2YW/h6Q0u23aXdrq6Cwb/m5Xn2yrxIgncm6H2nJYs6Dj51KB59Bmezt58nchqpvf387Ty5gkY0wJcDmwwBgzATjPf2EFmfBIOOu/4UCunVHuIZEA7uc4uBH+86C9V9p80ll8b1er41VtdfiTMXY0VepESBna8fP1GQmZ58KKP0OdlroJOUv/BJHdbAXvTuBp4ogQkX7AFRzvHFfNjb4CkofY2eRezNTNyUymoLSaHQXlfgzOS3XV8MZcOzv+W4+ePDqjsdXx+cPOxNcVHFwPhze3v1O8NTl3QNkh25JRoaN4v72Qy7oOuvXslLf0NHE8AHwA7DDGrBKRwYAOrWkuPALO/qn9n33zmx4flpOZAsCyHQHUz7H4QTi8CWY+cfIqc3C81bH+lQ6tiKhOYd1Cu3BY8+VhO2rw2dBntL06DbQWrmq/5U/Z/55Tv99pb+lp5/jfjTFjjDG3uX7faYz5tn9DC0IjL4dew+GTh2zHsgcG9IwltXts4PRz7FkKXzwOWdfb5UndybnTfrF9pq0On6uvta2C0y7w7RVkYxmSgq9g+0e+O69yTvNihj0Gddrbeto5niYib4rIYRE5JCKvi0iav4MLOmFhcM5PbX0gD28HiAjZmcks33mEhgaHrwKrS+0oqh6D4L/aKOCY0AcmaqvDL7Z/BBWF3pcY8cSoyyGhvx34oILf6vl+LWbojqe3qhYA7wD9gVTgH65tqqVhF0Pf0bbVUe/ZuuI5mckcq6jlq4Olfg6uDR/cb0uKXPZnu351W6bdZQcGfP4H/8fWleQutMMqh37T9+cOj7TVnXd9BvnrfH9+1Xlqq+zcHD8WM3TH08TRyxizwBhT53q8APTyY1zBKywMzvkfOLbLfgF4oLFu1VIn+zm2vg9rX7TJYOBUz45J6GPLruQu0laHr1Qctf8tRn/Hfsn7w4TrISrBllxXwasTihm642niKBSRa0Qk3PW4BgiQm/IB6LQLIHUCfPp/UFfT5u79kmLJSIlzbmGn8kJ45w7oMwrOud+7Y7XV4Vub3oT6Gv/cpmoUk2STx8Y3oGif/95H+U8nFTN0x9PEcRN2KO5B4AAwC1uGRLVGxH4BF++FL1/06JDszGRW7DxKXX0nL7pjDPzjLqgqhsuftTPhvZHQFybcaFsdR3f6J8auJHeRHWDRb6x/32fqbfbf6Ypn/Ps+yj86qZihO56OqtprjLnEGNPLGNPbGHMpdjKgcifzXBgwFT77g0frPudkJlNaXcfG/JJOCK6Z3EV20uI3/tdOEmuP6XfbVsdn2urokMLtkLfS8+VhOyIpDUZ9247IqSzy73sp3+rEYobudGQFwHt8FkUoEoFv/A+U5ntU5mHqYAf6OYr2wfs/gYE5tjBaeyX0hQk32D6do7t8Fl6Xs34RSJjny8N2VPbtdkTOmhc65/2Ub3RiMUN3OpI4Or99FGwyzoT0M+DzR+y6CqeQEh/N6X0SOm99joYGeOs2WwvpsqchLLxj55t2ty2GqLPJ26ehwbb+Bp8NiZ201E2/Mfb9VjzjUV+cChBfPNZpxQzd6Uji0KmnnvjG/9qRD6vmtblrdmYyq3YfpaauE/o5VjwDuz+HC35rm7wdldjPrvuQu0hbHe2x5wso3gdjr+rc9825A0oPwMbXO/d9Vfsc2gxf/6vTihm6c8rEISKlIlLSyqMUO6dDtWXgVBhynr0nWX3qeRrZmclU1Tawbp+f7zkf/go++iWcNgPGX+u780672677oCOsvJe70A6RHXZR575v5rnQe4SWIQkWnVzM0J1TJg5jTIIxJrGVR4Ixxpmba8HonPuh8mibI1imZiQj4ud1yOtq4M25doLfJY/7thM2sd/xvg5dbc5zNeV2hb6RMzv/KrKxDMnhTbDjP5373so7DhQzdKcjt6qUp1InwOkX2quFU4xgSeoWyaj+Sf7tIP/s/2z594sfs8UKfW363baDV1sdnvvqn7aT2p9zN05l1CxI6Gf/farA5UAxQ3c0cXSWc+63cyWWP3XK3bIzk/lybxFVtZ4VSfRK3mr7hT72Khh+se/PD3a1uQk32CVPj+3xz3uEmnV/g6SBdnSbEyKi7PKyOxfDwQ3OxKBOzaFihu74NXGIyAUislVEtovIfa28Hi0ir7heXyEi6a7tySKyWETKROSJFsdMEJENrmMeF3Fg9kt79B0NI2bCsqdOuXxndmYyNfUNrNlzzLfvX1Nu19hI7A8z/Lzq7zRtdXisJB92fmLnbnRkediOmnAjRMXDUi1DEpAcKmbojt/+pYpIOPAkMAMYAcwRkREtdrsZOGaMGQL8Efida3sV8DPgR62c+mlgLjDU9bjA99H7ydk/tf/xv3jM7S6T0nsSESa+v13175/D0R127fCYJN+eu6WkVFuWfd3L2upoy/pXAOOb5WE7Ira7vXe+8TV7L10Fjtoq2z/qQDFDd/x5iTMZ2O5au6MGWATMbLHPTOAvruevAeeKiBhjyo0xS7AJpIlrFcJEY8wyY9dafRG41I9/g2/1Hg6jZ8HKZ6HscKu7xEdHMCYtybfrc2z/CFY9B1N/YOeWdIbpP7StjiW6NL1bxtjhywOmQHKm09HAlO/ZmLQMSWBZv8iu3OhAMUN3/Jk4UoHmFdTyXNta3ccYUwcUA60sOXfC/nltnBMAEZkrIqtFZHVBQYGXofvRWfdBXZUdnutGTmYK6/OKKauu6/j7VRyFt2+HlNPh3J91/HyeSkq1V7Bf/tWWalcny//SLqrkdGujUY9BMPJSey+9qpNL36jWOVzM0B1/Jo7W+h5aDhT3ZJ927W+MedYYM9EYM7FXrwCqAJ8yxI6eWf08lBxodZeczGTqGwyrdrnvC/HYez+C8gJbwDAytuPn80Zjq+NzbXW0KneRXbt95GVOR3Jc9u1QXWJL7CvnOVzM0B1/Jo48YECz39OAfHf7iEgEkASc6tsyz3WeU50z8J31E2ioc9t5nDWoB1ERYR3v59jwmp0RfNZ90H9cx87VHklpdqq/x3MAAB/YSURBVIKhtjpOVldj+xNOnwGxPZyO5rjULFsmZ/nTHi9EpvwkAIoZuuPPxLEKGCoiGSISBczGriLY3DvA9a7ns4D/uPouWmWMOQCUishU12iq64C3fR+6n/VIh/HXwNq/tLoeQkxkOFkDu7OsI+tzlOTDP++F1In2yt8pZ7hqYWqr40Tb/w0VR2BcJ5cY8UTOHVCSB5vecjqSri0Aihm647fE4eqzuB34ANgCvGqM2SQiD4hIY/p8HkgWke3YartNQ3ZFZDfwCHCDiOQ1G5F1G/AcsB3YAbzvr7/Br878sf352f+1+nJOZgqb8ksoqmhH8TljbL9GXbVdBtbJf3RJac36OnTRoCa5CyGulx0pE2iGfNP2iS19XMuQOCkAihm649eB48aY94wxpxljMo0xD7q2/dwY847reZUx5jvGmCHGmMnGmJ3Njk03xvQ0xsQbY9KMMZtd21cbY0a5znn7qVooAS0pzTVR7uVWiwLmZCZjDCzf2Y5+jlXPwY6P4fxf2z4VpzW2eHSElVVxFLb+y7/Lw3ZEWBjk3A4H19u1yVXnO7wlIIoZuqMzx510xr22FPmnvz/ppTFp3YmNDGeZt/0chdvhw5/Z4nWTbvFRoB3UfQBkXQtrX4LivLb3D3UbX4eGWudKjHhi9BUQ11vLkDjli8cDopihO5o4nJTQ1365r18EhdtOeCkqIoxJGT296+eor4M3v2uXf535RECNwmC69nU0yV0IvUfaagKBKjIGpsy1fTGHNjsdTdcSQMUM3dHE4bRpd0NELHxychmQnMxkvj5URkFptWfnWvJH25l20R9saZFA0n2AHRDwZRdvdRR8DfvXwLg5gZXYWzPxZnvVu0zLkHSqACpm6I4mDqfF97JXdhtfP+nKLtu1nKxHrY78L+HTh+w60qNn+SPSjjvjHtcQwz86HYlzchfauS2jv+N0JG3r1tMOp17/qts5R8rHAqyYoTuaOAJBzp22wNwnvz1h88j+iSTERLS9PkdtJbzxXTtK58IAXrq1+0AYf7WdXNYV6yE1NNjaVJnn2tuUwWDqbWDqYeWfnY6kawiwYobuaOIIBN16Qvb3Ycs7cGB90+aI8DCmZCS33UH+8a+hcKvt1wjQe6JNzrjXrnPeFVsduz+Hkv2BU2LEEz0z7OSz1fPbXMFSdVAAFjN0RxNHoJj6fVu1dvH/O2FzdmYyu49UkF9U2fpxuz6D5U/aTvYh53VCoB3UfaAdl772L12v1ZG7EKITO3952I7KucOuJfPlX52OJLStf8VVzPBupyNpkyaOQBHb3f4P+vX7kLemaXNOpu3n+PTrVgo1VhXDm7dBz0z45gOdFWnHNbY6vnBf6DHkVJfB5ndsEcHOrhnWUWkT7SJTy56yI/eU7zXU2wmX/cZ1XgXrDtDEEUimfM/OFF38YNOm0/skMLxfIg+9/xV7jpSfuP/790Fpvp0dHhXXycF2QI9BttTGmhdsaZSuYMs/oLY8sOdunErOHVC8F7YEX4WfoBCgxQzd0cQRSKITbDN1x8ewZxkAYWHCM9dkATD3xTWUN5Za3/IPyP2bvXofMMmpiNuvqa+ji7Q6chdC90EwMNvpSNrntAsgeYidmBakxRoCVgAXM3RHE0egmXQLxPc5odUxKDmOP80Zz7bDpfz4tVxM6UH4x13Qbyyc9d8OBtsBPdLt1XdXaHUU59m+qLFBMHfDnbAwW2zvwDrY84XT0YSWAC5m6I4mjkAT1c3Ost79Oez8tGnzmaf14r4Zw3hvwwF2L7jF3jO/7NnArHXkqTPutUM9Q73VESjLw3bU2NnQLUXLkPhaABczdEcTRyCacAMkptpWR7PbAreeMZj/N2gdGUc/Z9uYe6H3MOdi9IWeGc1aHSE6waxxediB2fbvDWaRsTB5ri2+V7DV6WhCQ4AXM3RHE0cgioyxV+P7VsD2j5s2y7HdzDn2NLkRY/j2l2PYWVDmYJA+csa9dlGrUB1htX8tFH4dvJ3iLU26BSJitAyJryz9U0AXM3RHE0egGn+tnfOw+Df2qrWhHt66DZEwel/7PBHhEcx9aQ2lVUG+SlvPDFu3ac0LUHrQ6Wh8L3eha3nYS52OxDfiXLdUchdB6SGnowluxfttOZcALmbojiaOQBURBWf+xNag2vq+vTLZuwxm/I5+g07jiavGs6uwnHtezaWhIchHuZzxI7tMaaj1ddRV2+Vhh11kJ3eGiuwf2P9eq+Y5HUlwW/6UHVkYwMUM3dHEEcjGzoGeg+GD+21/x7BvNd3yyMlM4X8vGs6/Nx/i8f9sa+NEAa6pr2NBaLU6tn0IlccCc3nYjkjOtMlw1XNQU972/upkQVLM0B1NHIEsPALOug+O7YKY7nDxYycM57whJ51vZ6Xx6Efb+HBTkH/hnnmvvYr94jGnI/GddQvt0OrB5zgdie/l3GmT4rq/OR1JcAqSYobuaOIIdKNn2absd16AuJQTXhIRHrxsFGPTkvjhK+vYdiiIi9D1HGyHe66eHxr3zsuPwLYPXMvDBsfYfK8MnAJpk20neUO909EElyAqZuiOJo5AFxYOF/wW0qe1+nJMZDjPXDuB2Khw5r60huLKIO4sPyOEWh0bX7OjxUJlNFVrcu6AY7ttFQPluSAqZuiOJo4Q0C8plqeunsC+oxXctehL6oO1szw5E8ZcCaufD/5WR+5CuzRs31FOR+I/wy6CHhm2OJ+WIfFMQ0NQFTN0RxNHiJic0ZNfXDKST7YW8Mi/g3hy1pmuEVZLH3c6kvY7/JUdDRfKrQ2wreHsH9ilcPcudzqa4LD1n0FVzNAdTRwh5JopA5k9aQBPLt7BexuCdCZ2ciaMuQJWPQ9lh52Opn1yF4KEB8fysB017mqI7allSDwRhMUM3dHEEUJEhF/NHMn4gd350d9z+epgidMhtc+ZP4b66uDs62iot5O6hpwH8b2djsb/olyznre+Z1tayr0gLGbojiaOEBMdEc4z10wgPjqCuS+uoaiixumQvNfY1xGMrY5dn9o1UoK9oKE3Jt0KEdHw1BR4+HSYPwPe+gF8/gfY9KZdDlmXnQ3KYobuBHfaU63qkxjDM9dOYPafl3PHwi9ZcMMkIsKD7BrhzB/b0SdLH4fzf+N0NJ7LXQTRSXD6hU5H0nnie8FNH9h1ZI7uhCM7YftHsK7F3KL4PnbYdfNHcqb9GZ3gTOydpbGY4dn3B1UxQ3c0cYSorIE9eGDmSO57YwP/98FWfnrhcKdD8k5yJoy+AlY+Bzl32S+nQFddaoemjrnCFqrsSvqPs4/mqsvs5NUjO2xCOboDju6CHf+BdS+fuG9c72bJpDGxuJJKTGLn/R3+EqTFDN3RxBHCZk8eyKb8Ev782U5G9E9k5rhUp0Pyzpk/hg2vwtLHgqPVsfkdqK2AsSFWYqS9ouNdQ5JHn/xaTblNIkddSeWIK6ns/MSubNlcXK9mrZRMW6KmsaUSDDXAGosZTro56IoZuqOJI8T97Fsj2HqwlP9+fT2ZveIZlRoE/6M1ShliRyatej44Wh25C+2X2YDJTkcS+KLi7ByX1ua51JTbiYUtWyo7P7WfcXPdko+3TBqTSb9x9nmgDHcN4mKG7ojpAhN3Jk6caFavXu10GI4pKK3mkieWECbCO7dPIzk+2umQPFe4DZ6cbEeinP9rp6Nxr2gvPDoazvkfOOsnTkcTumoqbFI5oaWy0z5K9h/fL6Y7pE2E1ImQNglSs5y52q8sgj+OhNNnwLef6/z37yARWWOMmdhyu7Y4uoBeCdH8+doJzHpmGbf/7UtevHkykcHSWZ4yFEbNspVYp911Ur2ugLH+FftzzBXOxhHqorpBnxH20VJtpU0k+Wshb7V97Pi9vdoHSB7iSiIT7M8+I/2/9HKQFzN0R1scXcjra/K49++53DgtnV9cPNLpcDxX8LUd6plzB3zzAaejOZkx8KcJkNAXbnzP6WhUc9WldhZ/3irIW2N/lruGeEfEQP/xxxNJ2iRI8mE/YG0VPDbGJqhr3/TdeTuRtjgU356Qxsb8YhZ8sZuR/ZOYNSHN6ZA80+s0GPVt1wirOwOv1ZG32t46mf5DpyNRLUUn2JpQjXWhjIHifScmkpXzji+Fm9DvxFtc/cfZ/pj2aCxmeHnoLXiliaOLuf/C4Xx1oJT739zA0N7xjB3Q3emQPHPmT2DDa3ZY4zd/5XQ0J8r9G0TEwoiZTkei2iJil2TuPtBejADU1cChDcdvb+WtOl7xV8LtbbHGRJI2yd7yCmvjVm+IFDN0R29VdUFHyqq55IkvaDCGd26fTq+EIOksf+1mu4zu3Rvs2teBoK4aHh4KQ88Pys5P5UZ5oS3emLfKJpP9a6DaVcInOgnSJjRLJhNP7njf8g945RqYtcCu8hek3N2q0sTRRW3cX8ysZ5YyOjWJl2+ZSlREEHSWF2yFJ6fA9LvhvF86HY21+W149Tq45nVbn8oPquvqKauqo7y6nrLqOsqq6yh3/SyrriM6IozU7rGk9oilb2JM8FUJCAYNDXBkmyuRuG5zHd50vOO952BXx/tEm0je/wmUF8Dta4K6LpX2cagTjEpN4nffHsNdi9bx63c38+tLg2DdiF6n29sLy56C/Wtd4/abjeHvkW5rJnWmdQshvu8Jy8MaY6iqbTjpC/6k51V1lFXXu92n8ffaes8v7sLDhL6JMU2JpLWfMZHh/vgkQltYmP331+t0GH+N3VZdBgfWHW+V7Pz0+Og6gAsfDuqkcSqh+Vcpj8wcl8pm18zykf0TmT15oNMhte38X2MiojCHtyIb30CqippeMgj1CanUJGVQnTiIqoQMKhIGUhGfTlm3VGqJoq6hgdp6Q129afa8gdoG+7Ou3lDbYH82317r2r+u3jQ9j6o8wm/3fMg/ul3K048tcSWCOspr6j1aTEsE4qIiiI+OIC46nPjoCOJjIugZ163peVy0fd3uE0F8dDjx0ZFN+8dFR1BVW8/+okr2H6ts+plXVMnKXUc5WFJ1Uiwp8dGk9oglrXlSaXzeI5bEGD8PUQ0V0fGQPt0+wHa8l+y3iaQ4D7KuczY+P/Jr4hCRC4DHgHDgOWPMQy1ejwZeBCYAR4ArjTG7Xa/9FLgZqAfuNMZ84Nr+Q+AWwAAbgBuNMVX+/DtC2U8uGMbmAyX8/O1NDO2TwIRBPZwOqVWFZdX8a+NB/rn+ACt3X0x9w7cASKKMDDnIIDlIRthB0osOkl6cT7qspZ+UNx3fYIR8ktnV0Jd804ddpi97TF92mb7sM72pofUvy8hwISIsjIhwITI8jIgw189w4cr694mgnpUJ55OZEH/yl3yM/aKPi2p8fmIiiI0MJyzMN7ObB/eKb3V7XX0DB0uqTkgq+4vsY8uBEj7acojquoYTjkmIiSC1eyxpzVoqaT26NT1PjotCAmVWdiARgaQ0+whxfuvjEJFw4Gvgm0AesAqYY4zZ3Gyf7wNjjDHfE5HZwGXGmCtFZASwEJgM9Ac+Ak4D+gJLgBHGmEoReRV4zxjzwqli0T6OUyuqqOGSJ76gqraef9wxnT6JgVGg70hZNf/aZJPF8p1HaDAwuFcc3zi9N4mxkfbL3PWlHhEeRmSY66fryz62vpjEir3El+8lrmwP3cr2EFO6h+iSXURUFze9j0FoSEyjocdgTM8MJDmTsJ6DCUsZgvTMcH/768+u0TLf/awTPg3/MMZQWFbTLKlUkHfsxNZLaXXdCcfERIbR39VKaUwuaT26cfbpvejeLcqhv0T5gxN9HJOB7caYna4AFgEzgc3N9pkJ/NL1/DXgCbGXMjOBRcaYamCXiGx3nW+vK+ZYEakFugH5fvwbuoTu3aJ49roJXP7UUr731zUsmjuV6Ahn7oMfKavmg02H+OeGfJbtsMkiIyWOH5wzhAtH92NY3wQvrnb7AcNaf6niaFOpCjmyg/CjOwg/uhO2vAXNbn+BQNKAEyu2JmeChMGBXLjgodbPHyREhF4J0fRKiGacm6HZxZW1zRJJRVOLZf+xSv59oITCMrvmS0ZKHAtvnUrfpMC48FD+48/EkQrsa/Z7HjDF3T7GmDoRKQaSXduXtzg21RizTEQexiaQSuBDY8yHrb25iMwF5gIMHBgE9+4dNqxvIg9/Zyzff3ktP39rEw99e3Sn3Y44Vl7DB5sO8s8NB1i64wj1DYb05G7cdnYmF43uz/B+3iQLD3XraR9pJ11MnZBUbC0kVz2kjW+cmFTCImw5lBCXFBtJUmwkI/q3Xt68sqaeVbuP8v2X1zL72WUsnDuVfkmxnRyl6kz+TByt/Z/e8r6Yu31a3S4iPbCtkQygCPi7iFxjjPnrSTsb8yzwLNhbVd4E3lVdOLofPzgnkycX72BUWhLXTh3kt/c6Vl7Dh5sP8u7648liUHI3vnvmYC4a048R/RKdu4/uaVKJ7Rn4FXs7QWxUOGee1osXb57M9c+v5Mo/L2fh3KmkdtfkEar8mTjygAHNfk/j5NtKjfvkiUgEkAQcPcWx5wG7jDEFACLyBpADnJQ4VPvc883T2Zxfwq/e2cTpfRKYnOG7iqJFFTV8uOkQ/9xwgC+2F1LXYBjYsxtzzxzMRaP7MbK/g8nCU6dKKl1c1sAevHjzZK57fqVtedw6lbQewb/anTqZPzvHI7Cd4+cC+7Gd41cZYzY12+cHwOhmneOXG2OuEJGRwN843jn+MTAUmAjMByZhb1W9AKw2xvzpVLFo57h3iitrufTJLyitquWd26fTvwNXjsUVtXy42d6GWrLNJosBPWO5cHQ/vjW6P6NSgyBZKK/k7ivi2udXkBgbycJbpzKgpyaPYOXIzHERuRB4FDscd74x5kEReQD7Zf+OiMQALwHjsS2N2c060/8HuAmoA+42xrzv2v4r4ErX9i+BW1yd6G5p4vDe9sOlXPrkUjJS4vj797K9mjRWXFnLvzcf4p/r81myvZDaekNq91i+NaYfF43px+jUJE0WIW5DXjHXPL+C+OgIFt46lYHJmjyCkZYc0cThtQ83HWTuS2u4PCuVP3xn7Cm/7Euqavlo8yH+uf4An20raEoWF43px4Wj+zE2TZNFV7NxfzFXP7eCuKhwFs6dyqDkdlaZVY7RxKGJo10e/ehrHv1oG7+4eAQ3Tss44bXSqlo+2uJKFl8XUlPfQP+kGC4cbVsW4wZ012TRxW3Kt8kjNjKchbdOJT1Fk0cw0cShiaNdGhoM3/3rGv7z1WFeunkyY9K68/GWQ7y7/gCffl1ATV0D/Zoni7TuPpsNrULD5vwSrn5uOVERYSyam02GJo+goYlDE0e7lVbVctlTSzlQVEltg6GmroG+iY3Joi/jB/TQZKFO6auDJVw9bwXhYcLCuVPJdFMiRQUWTRyaODpkZ0EZP3ltPaNSk/jWmH5kDdRkobzz9aFSrpq3HBFh4a1TGNI7wemQVBs0cWjiUMpx2w6VMmfeCgAW3jqFoX00eQQyd4lDV3xRSnWaoX0SWDR3KiIwZ95yth4sdTok1Q6aOJRSnWpI73gWzZ1KmAhz5i3nq4MlToekvKSJQynV6TJ72eQRGS7MeXY5m/M1eQQTTRxKKUcM7hXPK3NtVYKrnlvOpvzitg9SAUETh1LKMekpcSyaO5VukeFcNW8FG/dr8ggGmjiUUo4alBzHornZxEdHcNW85WzI0+QR6DRxKKUcNzC5G4vmTiUhJpKrnltO7r6itg8KQA0NhsVbD/PLdzbxr40HqKqtdzokv9B5HEqpgJF3rII585ZTVF7LizdPZvzAHk6H5JGKmjpeX7ufBV/sYmdBOeFhQn2DISEmghmj+nLpuFSmDE4mPMgmzeoEQE0cSgWF/UWVzHl2OcfKa3jhpslMGBS4yWN/USUvLtvNwhV7KamqY0xaEjdPz+C/RvZl5a6jvL0unw82HaSsuo7eCdFcPLY/l45LDZp1aDRxaOJQKmjkF1UyZ95yjpTV8JebJjFhkO9WouwoYwxr9xYx/4td/GvjQYwxzBjVj5ump5M1sMdJCaGqtp6PtxzmrXX7+WTrYWrrDYNT4rhkXH9mjksN6KKPmjg0cSgVVA4WVzFn3nIOl1Txwk2TmZTubPKorW/gvQ0HmP/FbnL3FZEYE8GcyQO5NnuQx0vkFlfU8v7GA7y1bj8rdh3FGBiblsQl41K5eGw/eifE+Pmv8I4mDk0cSgWdQyVVzHl2OQdLqlhwwySmDE7u9BiOldfwt5V7eWnZHg6WVDE4JY4bp6VzeVYacdER7T7vgeJK3s21SWRTfglhAjmZKcwc15//GtWXxJhIH/4V7aOJQxOHUkHpcIlteeQXVbHgxklM7aTkse1QKfO/2M2bX+ZRVdvAGUNTuGlaBmed1svnlaG3Hy7lnXX5vLUun71HK4iKCOPcYb2ZOS6Vs0/v5dXSzb6kiUMTh1JB63BpFVfNW8H+Y5U8f8NEcjJT/PI+DQ2GT7cVMH/JLj7fVkh0RBiXZ6VyQ04Gp/f1fyVfYwzr9hXx9rp83l2fT2FZDQkxEVw4qh8zx/Xv9JFZmjg0cSgV1ApKq7n6ueXsPVrB89dPYtoQ3yWPipo63nANp91RUE7vhGiuz0lnzuSB9IyL8tn7eKOuvoGlO47w1rr9fLDxIOU19fRJjObiMbZTvTNGZmni0MShVNArLKvmmudWsKuwnOeun8gZQ3t16Hz5RZW8uGwPC1fupbiytmk47YxR/YiKCJz50VW19Xy05RBvr8s/PjKrVxwzx6Zyybj+fhuZpYlDE4dSIeFIWTVXP7eCnYXlzLtuImed5n3yWLv3GPOX7OJ913DaC0b15aZpGUwYdPJw2kBTXFHLexsP8HaLkVkzx6XyLR+PzNLEoYlDqZBxtLyGa55bwfaCMv587QTOOb13m8fU1jfw/saDzF+yi3X7ikhwDae9zovhtIHmQHEl/8jN5+11+U0js6YNSeGSsb4ZmaWJQxOHUiHlWHkN1zy/gm2Hynjm2iy+MayP2/0WrtrLi0vtcNoM13Dab3dwOG2g2X64lLfX2STSODLrvOG9+c2lo9vdT6OJQxOHUiGnqKKGa59fyVcHS3j66gmcN+J48th+2A6nfWOtHU47fUgKN01P5+zTevt8OG0gaT4ya/nOI7x7x3QiwtvXX6OJQxOHUiGpuKKW6+avYPOBEp64KovoiDDmf7Gbz74uICoijMvHp3LjtM4ZThtojDEd6rPRxKGJQ6mQVVxZy3XzVzaVY++dEM112YOYM3kgyfHRDkcXvNwljtC5waeU6rKSYiN56ebJPPLh14wb0J0LRwfWcNpQo4lDKRUSEmMi+eUlI50Oo0vQlKyUUsormjiUUkp5RROHUkopr2jiUEop5RVNHEoppbyiiUMppZRXNHEopZTyiiYOpZRSXukSJUdEpADY087DU4BCH4YT7PTzOE4/ixPp53FcqHwWg4wxJy140iUSR0eIyOrWarV0Vfp5HKefxYn08zgu1D8LvVWllFLKK5o4lFJKeUUTR9uedTqAAKOfx3H6WZxIP4/jQvqz0D4OpZRSXtEWh1JKKa9o4lBKKeUVTRxuiMgFIrJVRLaLyH1Ox+MkERkgIotFZIuIbBKRu5yOKRCISLiIfCki7zodi5NEpLuIvCYiX7n+jWQ7HZOTROSHrv9PNorIQhGJcTomX9PE0QoRCQeeBGYAI4A5IjLC2agcVQfca4wZDkwFftDFP49GdwFbnA4iADwG/MsYMwwYSxf+TEQkFbgTmGiMGQWEA7Odjcr3NHG0bjKw3Riz0xhTAywCZjock2OMMQeMMWtdz0uxXwypzkblLBFJAy4CnnM6FieJSCJwJvA8gDGmxhhT5GxUjosAYkUkAugG5Dscj89p4mhdKrCv2e95dPEvykYikg6MB1Y4G4njHgV+AjQ4HYjDBgMFwALXbbvnRCTO6aCcYozZDzwM7AUOAMXGmA+djcr3NHG0TlrZ1uXHLYtIPPA6cLcxpsTpeJwiIt8CDhtj1jgdSwCIALKAp40x44FyoMv2CYpID+zdiQygPxAnItc4G5XvaeJoXR4woNnvaYRgc9MbIhKJTRovG2PecDoeh00DLhGR3djbmN8Qkb86G5Jj8oA8Y0xjC/Q1bCLpqs4DdhljCowxtcAbQI7DMfmcJo7WrQKGikiGiERhO7fecTgmx4iIYO9hbzHGPOJ0PE4zxvzUGJNmjEnH/tv4jzEm5K4qPWGMOQjsE5HTXZvOBTY7GJLT9gJTRaSb6/+bcwnBwQIRTgcQiIwxdSJyO/ABdlTEfGPMJofDctI04Fpgg4isc2273xjznoMxqcBxB/Cy6yJrJ3Cjw/E4xhizQkReA9ZiRyN+SQiWH9GSI0oppbyit6qUUkp5RROHUkopr2jiUEop5RVNHEoppbyiiUMppZRXNHEo5QMiUi8i65o9fDZ7WkTSRWSjr86nVEfpPA6lfKPSGDPO6SCU6gza4lDKj0Rkt4j8TkRWuh5DXNsHicjHIrLe9XOga3sfEXlTRHJdj8ZyFeEiMs+1zsOHIhLr2B+lujxNHEr5RmyLW1VXNnutxBgzGXgCW1UX1/MXjTFjgJeBx13bHwc+NcaMxdZ8aqxYMBR40hgzEigCvu3nv0cpt3TmuFI+ICJlxpj4VrbvBr5hjNnpKhR50BiTLCKFQD9jTK1r+wFjTIqIFABpxpjqZudIB/5tjBnq+v2/gUhjzG/8/5cpdTJtcSjlf8bNc3f7tKa62fN6tH9SOUgTh1L+d2Wzn8tcz5dyfEnRq4ElrucfA7dB05rmiZ0VpFKe0qsWpXwjtlnlYLBrcDcOyY0WkRXYC7U5rm13AvNF5MfYFfQaK8reBTwrIjdjWxa3YVeSUypgaB+HUn7k6uOYaIwpdDoWpXxFb1UppZTyirY4lFJKeUVbHEoppbyiiUMppZRXNHEopZTyiiYOpZRSXtHEoZRSyiv/H879I3A4vP9lAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(hist.history['MSE'])\n",
    "plt.plot(hist.history['val_MSE'])\n",
    "plt.title('Model MSE')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EssaySense Experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loading] ASAP-AES domain 1 dataset...\n"
     ]
    }
   ],
   "source": [
    "# ESSAYSENSE PREPROCESSING\n",
    "glove_table = load_glove(es_hp, glove_dir)\n",
    "asap_train = load_asap(domain_id=prompt)\n",
    "\n",
    "asap_processed = SentenceLevelTestSet(\n",
    "    hyperparameters=es_hp,\n",
    "    lookup_table=glove_table,\n",
    "    raw_test_set=asap_train)\n",
    "train_essays, train_scores = asap_processed.all()\n",
    "\n",
    "indices=np.arange(train_essays.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "train_essays=train_essays[indices]\n",
    "train_scores=train_scores[indices]\n",
    "validation_size=int(VALIDATION_SPLIT*train_essays.shape[0])\n",
    "\n",
    "x_train=train_essays[:-validation_size]\n",
    "y_train=train_scores[:-validation_size]\n",
    "x_notrain=train_essays[-validation_size:]\n",
    "y_notrain=train_scores[-validation_size:]\n",
    "\n",
    "test_size=int(TEST_SPLIT*x_notrain.shape[0])\n",
    "x_val=x_notrain[:-test_size]\n",
    "y_val=y_notrain[:-test_size]\n",
    "x_test=x_notrain[-test_size:]\n",
    "y_test=y_notrain[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def essaysense_cnn_lstm(hp):\n",
    "    optimizer = 'adam'\n",
    "    \n",
    "    essays = Input(name='essays',shape=(hp.e_len, hp.s_len, hp.w_dim))\n",
    "    \n",
    "    # Convolutional layer\n",
    "    conv1 = Conv2d(filters=cnn_lstm_convunits_size, kernel_size=[1, w_window_len], padding=\"same\", activation=tf.nn.relu)(essays)\n",
    "\n",
    "    # Attention pooling\n",
    "    att1_mat = tf.Variable(tf.truncated_normal([cnn_lstm_convunits_size, cnn_lstm_convunits_size]), dtype=tf.float32)\n",
    "    att1_bias = tf.Variable(tf.truncated_normal([1, 1, 1, cnn_lstm_convunits_size]),dtype=tf.float32)\n",
    "    att1_weight = tf.tensordot(conv1, att1_mat, axes=[3, 0]) + att1_bias\n",
    "    att1_weight = tf.nn.tanh(att1_weight)\n",
    "    att1_vec = tf.Variable(tf.truncated_normal([cnn_lstm_convunits_size, 1]), dtype=tf.float32)\n",
    "    att1_weight = tf.tensordot(att1_weight, att1_vec, axes=[3, 0])\n",
    "    att1_weight = tf.nn.softmax(att1_weight, dim=2)\n",
    "    att1_output = att1_weight * conv1\n",
    "    att1_output = tf.reduce_sum(att1_output, axis=2)\n",
    "\n",
    "    # Long Short-Term Memory layer\n",
    "    lstm_cell = tfrnn.BasicLSTMCell(num_units=cnn_lstm_att_pool_size)\n",
    "    lstm_cell = tfrnn.DropoutWrapper(cell=lstm_cell, output_keep_prob=dropout_keep_prob)\n",
    "    init_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "    lstm, _ = tf.nn.dynamic_rnn(lstm_cell, att1_output, dtype=tf.float32)\n",
    "\n",
    "    # Attention pooling\n",
    "    att2_mat = tf.Variable(tf.truncated_normal([cnn_lstm_att_pool_size,cnn_lstm_att_pool_size]), dtype=tf.float32)\n",
    "    att2_bias = tf.Variable(tf.truncated_normal([1, 1, cnn_lstm_att_pool_size]), dtype=tf.float32)\n",
    "    att2_weight = tf.tensordot(lstm, att2_mat, axes=[2, 0])\n",
    "    att2_weight = tf.nn.tanh(att2_weight)\n",
    "    att2_vec = tf.Variable(tf.truncated_normal([cnn_lstm_att_pool_size, 1]), dtype=tf.float32)\n",
    "    att2_weight = tf.tensordot(att2_weight, att2_vec, axes=[2, 0])\n",
    "    att2_weight = tf.nn.softmax(att2_weight, dim=1)\n",
    "    att2_output = att2_weight * lstm\n",
    "    att2_output = tf.reduce_sum(att2_output, axis=1)\n",
    "\n",
    "    # Dense layer\n",
    "    out = Dense(1, activation=\"sigmoid\")(att2_output)\n",
    "\n",
    "    # Model Compiler\n",
    "    model = Model(inputs=[essays], outputs=[out])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=get_optimizer(optimizer), metrics=[\"MSE\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def essaysense_cnn_cnn(hp):    \n",
    "    optimizer = 'adam'\n",
    "    \n",
    "    essays = Input(name='essays',shape=(hp.e_len, hp.s_len, hp.w_dim))\n",
    "    \n",
    "    # Convolutional layer 1\n",
    "    conv1 = Conv2D(filters=hp.w_convunits_size,kernel_size=[1, hp.w_window_len],padding=\"same\",activation=None)(essays)\n",
    "    bn1 = BatchNormalization()(conv1)\n",
    "    activated1 = bn1 # activated1 = relu(bn1)\n",
    "    pool1 = MaxPooling2D(pool_size=[1, hp.s_len], strides=1)(activated1)\n",
    "    \n",
    "    # Convolutional layer 2\n",
    "    conv2 = Conv2D(filters=hp.s_convunits_size,kernel_size=[hp.s_window_len, 1],padding=\"same\",activation=None)(pool1)\n",
    "    bn2 = BatchNormalization()(conv2)\n",
    "    activated2 = bn2 # activated2 = relu(bn2)\n",
    "    pool2 = MaxPooling2D(pool_size=[hp.e_len, 1], strides=1)(activated2)\n",
    "    pool2_flat = Flatten()(pool2) # pool2_flat = reshape(pool2, [-1, hp.s_convunits_size])\n",
    "    \n",
    "    # Dense layers\n",
    "    dense1 = Dense(hp.hidden_size, activation=\"relu\")(pool2_flat)\n",
    "    out = Dense(1, activation=\"sigmoid\")(dense1)\n",
    "\n",
    "    # Model Compiler\n",
    "    model = Model(inputs=[essays], outputs=[out])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=get_optimizer(optimizer), metrics=[\"MSE\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_1 = essaysense_cnn_cnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-Fold Cross Pipeline\n",
    "Here's the final network pipeline which evaluates research-quality QWK scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(testID, method, cnn, agg):\n",
    "    VALIDATION_SPLIT=0.30\n",
    "    TEST_SPLIT=0.50\n",
    "    glove_dir = \"data/glove.6B.300d.txt\"\n",
    "    data_dir = \"data/training_set.tsv\"\n",
    "    earlystopping = EarlyStopping(monitor=\"val_MSE\", patience=10)\n",
    "\n",
    "    # Results File\n",
    "    results = open(\"models/%s_Results.txt\" % testID, \"w+\")\n",
    "    print(\"Model: %s\" % testID)\n",
    "    t0 = datetime.now()\n",
    "    \n",
    "    # Configure Hyperparameters\n",
    "    nea_hp.method = method\n",
    "    nea_hp.aggregation = agg\n",
    "    if cnn:\n",
    "        nea_hp.cnn_dim = 300\n",
    "    else:\n",
    "        nea_hp.cnn_dim = 0\n",
    "\n",
    "    # Pipeline to evaluate all prompts\n",
    "    for prompt in range(8):\n",
    "        prompt = str(prompt+1) # Ad-hoc because I'm a bad programmer\n",
    "        print(\"Prompt: %s\" % prompt)\n",
    "        range_max, range_min = limits(prompt)\n",
    "        \n",
    "        for fold in range(5):\n",
    "            fold = str(fold+1)\n",
    "            print(\"Fold %s\" % fold)\n",
    "            \n",
    "            # Model Training\n",
    "            x_train, y_train, x_val, y_val, x_test, y_test, embedding_layer = preprocess_asap(prompt,VALIDATION_SPLIT,TEST_SPLIT, glove_dir, data_dir)\n",
    "            sf_1 = nea(nea_hp, embedding_layer)\n",
    "            hist = sf_1.fit([x_train], y_train, batch_size=20, epochs=100, validation_data=([x_val], y_val), callbacks=[earlystopping])\n",
    "\n",
    "            # QWK Evaluation\n",
    "            y_pred=sf_1.predict([x_test])\n",
    "            y_val_fin = [int(round(a*(range_max-range_min)+range_min)) for a in y_test]\n",
    "            y_pred_fin =[int(round(a*(range_max-range_min)+range_min)) for a in y_pred.reshape(x_test.shape[0]).tolist()]\n",
    "            score = cohen_kappa_score(y_val_fin, y_pred_fin, weights=\"quadratic\")\n",
    "            results.write(\"%s \\n\" % score)\n",
    "            print(\"QWK, Prompt %s, Fold %s: %s\" % (prompt, fold, score))\n",
    "            \n",
    "            # Plot training & validation loss values\n",
    "            plt.plot(hist.history['MSE'])\n",
    "            plt.plot(hist.history['val_MSE'])\n",
    "            plt.title('Model %s, Essay %s MSE' % (testID, prompt))\n",
    "            plt.ylabel('Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "            plt.savefig('models/graphs/%s_%s.png' % (testID, prompt))\n",
    "\n",
    "            # Save Model Weights (Eh)\n",
    "            # sf_1.save('models/%s_%s_model.h5' % (testID, prompt))\n",
    "            # sf_1.save_weights('models/%s_%s_weights.h5' % (testID, prompt))\n",
    "        results.write(\"\\n ---- \\n\")\n",
    "        plt.clf()\n",
    "    results.close()\n",
    "\n",
    "    t1 = datetime.now()\n",
    "    print('Processing time: {}'.format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: CNN\n",
      "Prompt: 1\n",
      "Fold 1\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1783, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1249 samples, validate on 267 samples\n",
      "Epoch 1/100\n",
      "1249/1249 [==============================] - 6s 5ms/step - loss: 0.0237 - MSE: 0.0237 - val_loss: 0.0197 - val_MSE: 0.0197\n",
      "Epoch 2/100\n",
      "1249/1249 [==============================] - 1s 807us/step - loss: 0.0130 - MSE: 0.0130 - val_loss: 0.0110 - val_MSE: 0.0110\n",
      "Epoch 3/100\n",
      "1249/1249 [==============================] - 1s 790us/step - loss: 0.0099 - MSE: 0.0099 - val_loss: 0.0089 - val_MSE: 0.0089\n",
      "Epoch 4/100\n",
      "1249/1249 [==============================] - 1s 801us/step - loss: 0.0104 - MSE: 0.0104 - val_loss: 0.0110 - val_MSE: 0.0110\n",
      "Epoch 5/100\n",
      "1249/1249 [==============================] - 1s 795us/step - loss: 0.0093 - MSE: 0.0093 - val_loss: 0.0119 - val_MSE: 0.0119\n",
      "Epoch 6/100\n",
      "1249/1249 [==============================] - 1s 796us/step - loss: 0.0088 - MSE: 0.0088 - val_loss: 0.0104 - val_MSE: 0.0104\n",
      "Epoch 7/100\n",
      "1249/1249 [==============================] - 1s 796us/step - loss: 0.0084 - MSE: 0.0084 - val_loss: 0.0092 - val_MSE: 0.0092\n",
      "Epoch 8/100\n",
      "1249/1249 [==============================] - 1s 797us/step - loss: 0.0087 - MSE: 0.0087 - val_loss: 0.0121 - val_MSE: 0.0121\n",
      "Epoch 9/100\n",
      "1249/1249 [==============================] - 1s 830us/step - loss: 0.0091 - MSE: 0.0091 - val_loss: 0.0090 - val_MSE: 0.0090\n",
      "Epoch 10/100\n",
      "1249/1249 [==============================] - 1s 871us/step - loss: 0.0086 - MSE: 0.0086 - val_loss: 0.0097 - val_MSE: 0.0097\n",
      "Epoch 11/100\n",
      "1249/1249 [==============================] - 1s 867us/step - loss: 0.0091 - MSE: 0.0091 - val_loss: 0.0096 - val_MSE: 0.0096\n",
      "Epoch 12/100\n",
      "1249/1249 [==============================] - 1s 820us/step - loss: 0.0090 - MSE: 0.0090 - val_loss: 0.0092 - val_MSE: 0.0092\n",
      "Epoch 13/100\n",
      "1249/1249 [==============================] - 1s 802us/step - loss: 0.0092 - MSE: 0.0092 - val_loss: 0.0089 - val_MSE: 0.0089\n",
      "QWK, Prompt 1, Fold 1: 0.7317629065391132\n",
      "Fold 2\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1783, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1249 samples, validate on 267 samples\n",
      "Epoch 1/100\n",
      "1249/1249 [==============================] - 7s 5ms/step - loss: 0.0154 - MSE: 0.0154 - val_loss: 0.0092 - val_MSE: 0.0092\n",
      "Epoch 2/100\n",
      "1249/1249 [==============================] - 1s 814us/step - loss: 0.0101 - MSE: 0.0101 - val_loss: 0.0088 - val_MSE: 0.0088\n",
      "Epoch 3/100\n",
      "1249/1249 [==============================] - ETA: 0s - loss: 0.0100 - MSE: 0.010 - 1s 802us/step - loss: 0.0100 - MSE: 0.0100 - val_loss: 0.0085 - val_MSE: 0.0085\n",
      "Epoch 4/100\n",
      "1249/1249 [==============================] - 1s 799us/step - loss: 0.0100 - MSE: 0.0100 - val_loss: 0.0091 - val_MSE: 0.0091\n",
      "Epoch 5/100\n",
      "1249/1249 [==============================] - 1s 804us/step - loss: 0.0098 - MSE: 0.0098 - val_loss: 0.0118 - val_MSE: 0.0118\n",
      "Epoch 6/100\n",
      "1249/1249 [==============================] - 1s 826us/step - loss: 0.0088 - MSE: 0.0088 - val_loss: 0.0088 - val_MSE: 0.0088\n",
      "Epoch 7/100\n",
      "1249/1249 [==============================] - 1s 815us/step - loss: 0.0080 - MSE: 0.0080 - val_loss: 0.0085 - val_MSE: 0.0085\n",
      "Epoch 8/100\n",
      "1249/1249 [==============================] - 1s 806us/step - loss: 0.0080 - MSE: 0.0080 - val_loss: 0.0122 - val_MSE: 0.0122\n",
      "Epoch 9/100\n",
      "1249/1249 [==============================] - 1s 810us/step - loss: 0.0088 - MSE: 0.0088 - val_loss: 0.0092 - val_MSE: 0.0092\n",
      "Epoch 10/100\n",
      "1249/1249 [==============================] - 1s 831us/step - loss: 0.0084 - MSE: 0.0084 - val_loss: 0.0086 - val_MSE: 0.0086\n",
      "Epoch 11/100\n",
      "1249/1249 [==============================] - 1s 817us/step - loss: 0.0087 - MSE: 0.0087 - val_loss: 0.0088 - val_MSE: 0.0088\n",
      "Epoch 12/100\n",
      "1249/1249 [==============================] - 1s 836us/step - loss: 0.0080 - MSE: 0.0080 - val_loss: 0.0089 - val_MSE: 0.0089\n",
      "Epoch 13/100\n",
      "1249/1249 [==============================] - 1s 825us/step - loss: 0.0083 - MSE: 0.0083 - val_loss: 0.0091 - val_MSE: 0.0091\n",
      "QWK, Prompt 1, Fold 2: 0.7221101346958985\n",
      "Fold 3\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1783, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1249 samples, validate on 267 samples\n",
      "Epoch 1/100\n",
      "1249/1249 [==============================] - 6s 5ms/step - loss: 0.0204 - MSE: 0.0204 - val_loss: 0.0108 - val_MSE: 0.0108\n",
      "Epoch 2/100\n",
      "1249/1249 [==============================] - 1s 803us/step - loss: 0.0106 - MSE: 0.0106 - val_loss: 0.0117 - val_MSE: 0.0117\n",
      "Epoch 3/100\n",
      "1249/1249 [==============================] - 1s 788us/step - loss: 0.0105 - MSE: 0.0105 - val_loss: 0.0202 - val_MSE: 0.0202\n",
      "Epoch 4/100\n",
      "1249/1249 [==============================] - ETA: 0s - loss: 0.0108 - MSE: 0.010 - 1s 788us/step - loss: 0.0107 - MSE: 0.0107 - val_loss: 0.0102 - val_MSE: 0.0102\n",
      "Epoch 5/100\n",
      "1249/1249 [==============================] - 1s 793us/step - loss: 0.0094 - MSE: 0.0094 - val_loss: 0.0123 - val_MSE: 0.0123\n",
      "Epoch 6/100\n",
      "1249/1249 [==============================] - 1s 797us/step - loss: 0.0088 - MSE: 0.0088 - val_loss: 0.0106 - val_MSE: 0.0106\n",
      "Epoch 7/100\n",
      "1249/1249 [==============================] - 1s 792us/step - loss: 0.0088 - MSE: 0.0088 - val_loss: 0.0111 - val_MSE: 0.0111\n",
      "Epoch 8/100\n",
      "1249/1249 [==============================] - 1s 784us/step - loss: 0.0095 - MSE: 0.0095 - val_loss: 0.0092 - val_MSE: 0.0092\n",
      "Epoch 9/100\n",
      "1249/1249 [==============================] - 1s 785us/step - loss: 0.0084 - MSE: 0.0084 - val_loss: 0.0093 - val_MSE: 0.0093\n",
      "Epoch 10/100\n",
      "1249/1249 [==============================] - 1s 784us/step - loss: 0.0091 - MSE: 0.0091 - val_loss: 0.0126 - val_MSE: 0.0126\n",
      "Epoch 11/100\n",
      "1249/1249 [==============================] - 1s 845us/step - loss: 0.0090 - MSE: 0.0090 - val_loss: 0.0096 - val_MSE: 0.0096\n",
      "Epoch 12/100\n",
      "1249/1249 [==============================] - 1s 788us/step - loss: 0.0085 - MSE: 0.0085 - val_loss: 0.0119 - val_MSE: 0.0119\n",
      "Epoch 13/100\n",
      "1249/1249 [==============================] - 1s 777us/step - loss: 0.0094 - MSE: 0.0094 - val_loss: 0.0095 - val_MSE: 0.0095\n",
      "Epoch 14/100\n",
      "1249/1249 [==============================] - 1s 784us/step - loss: 0.0083 - MSE: 0.0083 - val_loss: 0.0092 - val_MSE: 0.0092\n",
      "Epoch 15/100\n",
      "1249/1249 [==============================] - 1s 793us/step - loss: 0.0079 - MSE: 0.0079 - val_loss: 0.0094 - val_MSE: 0.0094\n",
      "Epoch 16/100\n",
      "1249/1249 [==============================] - 1s 792us/step - loss: 0.0083 - MSE: 0.0083 - val_loss: 0.0093 - val_MSE: 0.0093\n",
      "Epoch 17/100\n",
      "1249/1249 [==============================] - 1s 817us/step - loss: 0.0081 - MSE: 0.0081 - val_loss: 0.0111 - val_MSE: 0.0111\n",
      "Epoch 18/100\n",
      "1249/1249 [==============================] - 1s 785us/step - loss: 0.0093 - MSE: 0.0093 - val_loss: 0.0093 - val_MSE: 0.0093\n",
      "QWK, Prompt 1, Fold 3: 0.7573114152418615\n",
      "Fold 4\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1783, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1249 samples, validate on 267 samples\n",
      "Epoch 1/100\n",
      "1249/1249 [==============================] - 6s 5ms/step - loss: 0.0219 - MSE: 0.0219 - val_loss: 0.0157 - val_MSE: 0.0157\n",
      "Epoch 2/100\n",
      "1249/1249 [==============================] - 1s 804us/step - loss: 0.0107 - MSE: 0.0107 - val_loss: 0.0098 - val_MSE: 0.0098\n",
      "Epoch 3/100\n",
      "1249/1249 [==============================] - 1s 794us/step - loss: 0.0096 - MSE: 0.0096 - val_loss: 0.0123 - val_MSE: 0.0123\n",
      "Epoch 4/100\n",
      "1249/1249 [==============================] - 1s 799us/step - loss: 0.0091 - MSE: 0.0091 - val_loss: 0.0095 - val_MSE: 0.0095\n",
      "Epoch 5/100\n",
      "1249/1249 [==============================] - 1s 794us/step - loss: 0.0089 - MSE: 0.0089 - val_loss: 0.0090 - val_MSE: 0.0090\n",
      "Epoch 6/100\n",
      "1249/1249 [==============================] - 1s 790us/step - loss: 0.0103 - MSE: 0.0103 - val_loss: 0.0091 - val_MSE: 0.0091\n",
      "Epoch 7/100\n",
      "1249/1249 [==============================] - 1s 817us/step - loss: 0.0087 - MSE: 0.0087 - val_loss: 0.0091 - val_MSE: 0.0091\n",
      "Epoch 8/100\n",
      "1249/1249 [==============================] - 1s 820us/step - loss: 0.0093 - MSE: 0.0093 - val_loss: 0.0095 - val_MSE: 0.0095\n",
      "Epoch 9/100\n",
      "1249/1249 [==============================] - 1s 781us/step - loss: 0.0104 - MSE: 0.0104 - val_loss: 0.0090 - val_MSE: 0.0090\n",
      "Epoch 10/100\n",
      "1249/1249 [==============================] - 1s 790us/step - loss: 0.0086 - MSE: 0.0086 - val_loss: 0.0107 - val_MSE: 0.0107\n",
      "Epoch 11/100\n",
      "1249/1249 [==============================] - 1s 793us/step - loss: 0.0085 - MSE: 0.0085 - val_loss: 0.0091 - val_MSE: 0.0091\n",
      "Epoch 12/100\n",
      "1249/1249 [==============================] - 1s 785us/step - loss: 0.0081 - MSE: 0.0081 - val_loss: 0.0100 - val_MSE: 0.0100\n",
      "Epoch 13/100\n",
      "1249/1249 [==============================] - ETA: 0s - loss: 0.0100 - MSE: 0.010 - 1s 786us/step - loss: 0.0100 - MSE: 0.0100 - val_loss: 0.0089 - val_MSE: 0.0089\n",
      "Epoch 14/100\n",
      "1249/1249 [==============================] - 1s 794us/step - loss: 0.0080 - MSE: 0.0080 - val_loss: 0.0092 - val_MSE: 0.0092\n",
      "Epoch 15/100\n",
      "1249/1249 [==============================] - 1s 807us/step - loss: 0.0086 - MSE: 0.0086 - val_loss: 0.0152 - val_MSE: 0.0152\n",
      "Epoch 16/100\n",
      "1249/1249 [==============================] - 1s 797us/step - loss: 0.0087 - MSE: 0.0087 - val_loss: 0.0091 - val_MSE: 0.0091\n",
      "Epoch 17/100\n",
      "1249/1249 [==============================] - 1s 787us/step - loss: 0.0080 - MSE: 0.0080 - val_loss: 0.0092 - val_MSE: 0.0092\n",
      "Epoch 18/100\n",
      "1249/1249 [==============================] - 1s 783us/step - loss: 0.0083 - MSE: 0.0083 - val_loss: 0.0092 - val_MSE: 0.0092\n",
      "Epoch 19/100\n",
      "1249/1249 [==============================] - 1s 791us/step - loss: 0.0084 - MSE: 0.0084 - val_loss: 0.0089 - val_MSE: 0.0089\n",
      "Epoch 20/100\n",
      "1249/1249 [==============================] - 1s 795us/step - loss: 0.0085 - MSE: 0.0085 - val_loss: 0.0099 - val_MSE: 0.0099\n",
      "Epoch 21/100\n",
      "1249/1249 [==============================] - 1s 797us/step - loss: 0.0080 - MSE: 0.0080 - val_loss: 0.0087 - val_MSE: 0.0087\n",
      "Epoch 22/100\n",
      "1249/1249 [==============================] - 1s 806us/step - loss: 0.0078 - MSE: 0.0078 - val_loss: 0.0094 - val_MSE: 0.0094\n",
      "Epoch 23/100\n",
      "1249/1249 [==============================] - 1s 810us/step - loss: 0.0075 - MSE: 0.0075 - val_loss: 0.0088 - val_MSE: 0.0088\n",
      "Epoch 24/100\n",
      "1249/1249 [==============================] - 1s 816us/step - loss: 0.0090 - MSE: 0.0090 - val_loss: 0.0089 - val_MSE: 0.0089\n",
      "Epoch 25/100\n",
      "1249/1249 [==============================] - 1s 799us/step - loss: 0.0085 - MSE: 0.0085 - val_loss: 0.0101 - val_MSE: 0.0101\n",
      "Epoch 26/100\n",
      "1249/1249 [==============================] - 1s 800us/step - loss: 0.0079 - MSE: 0.0079 - val_loss: 0.0090 - val_MSE: 0.0090\n",
      "Epoch 27/100\n",
      "1249/1249 [==============================] - 1s 787us/step - loss: 0.0078 - MSE: 0.0078 - val_loss: 0.0088 - val_MSE: 0.0088\n",
      "Epoch 28/100\n",
      "1249/1249 [==============================] - 1s 793us/step - loss: 0.0077 - MSE: 0.0077 - val_loss: 0.0091 - val_MSE: 0.0091\n",
      "Epoch 29/100\n",
      "1249/1249 [==============================] - 1s 785us/step - loss: 0.0080 - MSE: 0.0080 - val_loss: 0.0099 - val_MSE: 0.0099\n",
      "Epoch 30/100\n",
      "1249/1249 [==============================] - 1s 792us/step - loss: 0.0081 - MSE: 0.0081 - val_loss: 0.0089 - val_MSE: 0.0089\n",
      "Epoch 31/100\n",
      "1249/1249 [==============================] - 1s 789us/step - loss: 0.0075 - MSE: 0.0075 - val_loss: 0.0090 - val_MSE: 0.0090\n",
      "QWK, Prompt 1, Fold 4: 0.7371605101788776\n",
      "Fold 5\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1783, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1249 samples, validate on 267 samples\n",
      "Epoch 1/100\n",
      "1249/1249 [==============================] - 6s 5ms/step - loss: 0.0213 - MSE: 0.0213 - val_loss: 0.0151 - val_MSE: 0.0151\n",
      "Epoch 2/100\n",
      "1249/1249 [==============================] - 1s 806us/step - loss: 0.0099 - MSE: 0.0099 - val_loss: 0.0148 - val_MSE: 0.0148\n",
      "Epoch 3/100\n",
      "1249/1249 [==============================] - 1s 802us/step - loss: 0.0102 - MSE: 0.0102 - val_loss: 0.0096 - val_MSE: 0.0096\n",
      "Epoch 4/100\n",
      "1249/1249 [==============================] - 1s 799us/step - loss: 0.0086 - MSE: 0.0086 - val_loss: 0.0109 - val_MSE: 0.0109\n",
      "Epoch 5/100\n",
      "1249/1249 [==============================] - 1s 829us/step - loss: 0.0087 - MSE: 0.0087 - val_loss: 0.0091 - val_MSE: 0.0091\n",
      "Epoch 6/100\n",
      "1249/1249 [==============================] - 1s 788us/step - loss: 0.0089 - MSE: 0.0089 - val_loss: 0.0111 - val_MSE: 0.0111\n",
      "Epoch 7/100\n",
      "1249/1249 [==============================] - 1s 818us/step - loss: 0.0091 - MSE: 0.0091 - val_loss: 0.0095 - val_MSE: 0.0095\n",
      "Epoch 8/100\n",
      "1249/1249 [==============================] - 1s 794us/step - loss: 0.0080 - MSE: 0.0080 - val_loss: 0.0094 - val_MSE: 0.0094\n",
      "Epoch 9/100\n",
      "1249/1249 [==============================] - 1s 847us/step - loss: 0.0084 - MSE: 0.0084 - val_loss: 0.0113 - val_MSE: 0.0113\n",
      "Epoch 10/100\n",
      "1249/1249 [==============================] - 1s 811us/step - loss: 0.0083 - MSE: 0.0083 - val_loss: 0.0141 - val_MSE: 0.0141\n",
      "Epoch 11/100\n",
      "1249/1249 [==============================] - 1s 792us/step - loss: 0.0095 - MSE: 0.0095 - val_loss: 0.0090 - val_MSE: 0.0090\n",
      "Epoch 12/100\n",
      "1249/1249 [==============================] - 1s 792us/step - loss: 0.0078 - MSE: 0.0078 - val_loss: 0.0102 - val_MSE: 0.0102\n",
      "Epoch 13/100\n",
      "1249/1249 [==============================] - ETA: 0s - loss: 0.0083 - MSE: 0.008 - 1s 796us/step - loss: 0.0083 - MSE: 0.0083 - val_loss: 0.0089 - val_MSE: 0.0089\n",
      "Epoch 14/100\n",
      "1249/1249 [==============================] - 1s 791us/step - loss: 0.0082 - MSE: 0.0082 - val_loss: 0.0091 - val_MSE: 0.0091\n",
      "Epoch 15/100\n",
      "1249/1249 [==============================] - 1s 810us/step - loss: 0.0093 - MSE: 0.0093 - val_loss: 0.0094 - val_MSE: 0.0094\n",
      "Epoch 16/100\n",
      "1249/1249 [==============================] - 1s 845us/step - loss: 0.0076 - MSE: 0.0076 - val_loss: 0.0094 - val_MSE: 0.0094\n",
      "Epoch 17/100\n",
      "1249/1249 [==============================] - 1s 854us/step - loss: 0.0081 - MSE: 0.0081 - val_loss: 0.0094 - val_MSE: 0.0094\n",
      "Epoch 18/100\n",
      "1249/1249 [==============================] - 1s 786us/step - loss: 0.0078 - MSE: 0.0078 - val_loss: 0.0089 - val_MSE: 0.0089\n",
      "Epoch 19/100\n",
      "1249/1249 [==============================] - 1s 798us/step - loss: 0.0079 - MSE: 0.0079 - val_loss: 0.0100 - val_MSE: 0.0100\n",
      "Epoch 20/100\n",
      "1249/1249 [==============================] - 1s 777us/step - loss: 0.0080 - MSE: 0.0080 - val_loss: 0.0098 - val_MSE: 0.0098\n",
      "Epoch 21/100\n",
      "1249/1249 [==============================] - 1s 820us/step - loss: 0.0076 - MSE: 0.0076 - val_loss: 0.0088 - val_MSE: 0.0088\n",
      "Epoch 22/100\n",
      "1249/1249 [==============================] - 1s 808us/step - loss: 0.0074 - MSE: 0.0074 - val_loss: 0.0090 - val_MSE: 0.0090\n",
      "Epoch 23/100\n",
      "1249/1249 [==============================] - 1s 800us/step - loss: 0.0079 - MSE: 0.0079 - val_loss: 0.0112 - val_MSE: 0.0112\n",
      "Epoch 24/100\n",
      "1249/1249 [==============================] - 1s 781us/step - loss: 0.0081 - MSE: 0.0081 - val_loss: 0.0089 - val_MSE: 0.0089\n",
      "Epoch 25/100\n",
      "1249/1249 [==============================] - 1s 791us/step - loss: 0.0080 - MSE: 0.0080 - val_loss: 0.0089 - val_MSE: 0.0089\n",
      "Epoch 26/100\n",
      "1249/1249 [==============================] - 1s 792us/step - loss: 0.0077 - MSE: 0.0077 - val_loss: 0.0092 - val_MSE: 0.0092\n",
      "Epoch 27/100\n",
      "1249/1249 [==============================] - 1s 796us/step - loss: 0.0074 - MSE: 0.0074 - val_loss: 0.0094 - val_MSE: 0.0094\n",
      "Epoch 28/100\n",
      "1249/1249 [==============================] - 1s 792us/step - loss: 0.0076 - MSE: 0.0076 - val_loss: 0.0112 - val_MSE: 0.0112\n",
      "Epoch 29/100\n",
      "1249/1249 [==============================] - 1s 785us/step - loss: 0.0075 - MSE: 0.0075 - val_loss: 0.0089 - val_MSE: 0.0089\n",
      "Epoch 30/100\n",
      "1249/1249 [==============================] - 1s 780us/step - loss: 0.0076 - MSE: 0.0076 - val_loss: 0.0093 - val_MSE: 0.0093\n",
      "Epoch 31/100\n",
      "1249/1249 [==============================] - 1s 793us/step - loss: 0.0082 - MSE: 0.0082 - val_loss: 0.0095 - val_MSE: 0.0095\n",
      "QWK, Prompt 1, Fold 5: 0.7386773072910504\n",
      "Prompt: 2\n",
      "Fold 1\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1800, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1260 samples, validate on 270 samples\n",
      "Epoch 1/100\n",
      "1260/1260 [==============================] - 6s 5ms/step - loss: 0.0241 - MSE: 0.0241 - val_loss: 0.0144 - val_MSE: 0.0144\n",
      "Epoch 2/100\n",
      "1260/1260 [==============================] - 1s 805us/step - loss: 0.0126 - MSE: 0.0126 - val_loss: 0.0125 - val_MSE: 0.0125\n",
      "Epoch 3/100\n",
      "1260/1260 [==============================] - 1s 802us/step - loss: 0.0127 - MSE: 0.0127 - val_loss: 0.0138 - val_MSE: 0.0138\n",
      "Epoch 4/100\n",
      "1260/1260 [==============================] - 1s 798us/step - loss: 0.0117 - MSE: 0.0117 - val_loss: 0.0119 - val_MSE: 0.0119\n",
      "Epoch 5/100\n",
      "1260/1260 [==============================] - 1s 796us/step - loss: 0.0114 - MSE: 0.0114 - val_loss: 0.0124 - val_MSE: 0.0124\n",
      "Epoch 6/100\n",
      "1260/1260 [==============================] - 1s 785us/step - loss: 0.0119 - MSE: 0.0119 - val_loss: 0.0142 - val_MSE: 0.0142\n",
      "Epoch 7/100\n",
      "1260/1260 [==============================] - 1s 785us/step - loss: 0.0114 - MSE: 0.0114 - val_loss: 0.0121 - val_MSE: 0.0121\n",
      "Epoch 8/100\n",
      "1260/1260 [==============================] - 1s 790us/step - loss: 0.0112 - MSE: 0.0112 - val_loss: 0.0125 - val_MSE: 0.0125\n",
      "Epoch 9/100\n",
      "1260/1260 [==============================] - 1s 789us/step - loss: 0.0114 - MSE: 0.0114 - val_loss: 0.0116 - val_MSE: 0.0116\n",
      "Epoch 10/100\n",
      "1260/1260 [==============================] - 1s 790us/step - loss: 0.0111 - MSE: 0.0111 - val_loss: 0.0172 - val_MSE: 0.0172\n",
      "Epoch 11/100\n",
      "1260/1260 [==============================] - 1s 779us/step - loss: 0.0108 - MSE: 0.0108 - val_loss: 0.0135 - val_MSE: 0.0135\n",
      "Epoch 12/100\n",
      "1260/1260 [==============================] - 1s 787us/step - loss: 0.0111 - MSE: 0.0111 - val_loss: 0.0128 - val_MSE: 0.0128\n",
      "Epoch 13/100\n",
      "1260/1260 [==============================] - 1s 780us/step - loss: 0.0103 - MSE: 0.0103 - val_loss: 0.0121 - val_MSE: 0.0121\n",
      "Epoch 14/100\n",
      "1260/1260 [==============================] - 1s 786us/step - loss: 0.0103 - MSE: 0.0103 - val_loss: 0.0143 - val_MSE: 0.0143\n",
      "Epoch 15/100\n",
      "1260/1260 [==============================] - 1s 791us/step - loss: 0.0104 - MSE: 0.0104 - val_loss: 0.0125 - val_MSE: 0.0125\n",
      "Epoch 16/100\n",
      "1260/1260 [==============================] - 1s 788us/step - loss: 0.0101 - MSE: 0.0101 - val_loss: 0.0123 - val_MSE: 0.0123\n",
      "Epoch 17/100\n",
      "1260/1260 [==============================] - 1s 812us/step - loss: 0.0108 - MSE: 0.0108 - val_loss: 0.0141 - val_MSE: 0.0141\n",
      "Epoch 18/100\n",
      "1260/1260 [==============================] - 1s 923us/step - loss: 0.0102 - MSE: 0.0102 - val_loss: 0.0141 - val_MSE: 0.0141\n",
      "Epoch 19/100\n",
      "1260/1260 [==============================] - 1s 962us/step - loss: 0.0104 - MSE: 0.0104 - val_loss: 0.0120 - val_MSE: 0.0120\n",
      "QWK, Prompt 2, Fold 1: 0.6735905044510386\n",
      "Fold 2\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1800, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1260 samples, validate on 270 samples\n",
      "Epoch 1/100\n",
      "1260/1260 [==============================] - 8s 6ms/step - loss: 0.0244 - MSE: 0.0244 - val_loss: 0.0130 - val_MSE: 0.0130\n",
      "Epoch 2/100\n",
      "1260/1260 [==============================] - 1s 913us/step - loss: 0.0115 - MSE: 0.0115 - val_loss: 0.0127 - val_MSE: 0.0127\n",
      "Epoch 3/100\n",
      "1260/1260 [==============================] - 1s 934us/step - loss: 0.0121 - MSE: 0.0121 - val_loss: 0.0122 - val_MSE: 0.0122\n",
      "Epoch 4/100\n",
      "1260/1260 [==============================] - 1s 897us/step - loss: 0.0121 - MSE: 0.0121 - val_loss: 0.0119 - val_MSE: 0.0119\n",
      "Epoch 5/100\n",
      "1260/1260 [==============================] - 1s 884us/step - loss: 0.0109 - MSE: 0.0109 - val_loss: 0.0186 - val_MSE: 0.0186\n",
      "Epoch 6/100\n",
      "1260/1260 [==============================] - 1s 891us/step - loss: 0.0104 - MSE: 0.0104 - val_loss: 0.0114 - val_MSE: 0.0114\n",
      "Epoch 7/100\n",
      "1260/1260 [==============================] - 1s 885us/step - loss: 0.0130 - MSE: 0.0130 - val_loss: 0.0148 - val_MSE: 0.0148\n",
      "Epoch 8/100\n",
      "1260/1260 [==============================] - 1s 890us/step - loss: 0.0115 - MSE: 0.0115 - val_loss: 0.0131 - val_MSE: 0.0131\n",
      "Epoch 9/100\n",
      "1260/1260 [==============================] - 1s 894us/step - loss: 0.0110 - MSE: 0.0110 - val_loss: 0.0140 - val_MSE: 0.0140\n",
      "Epoch 10/100\n",
      "1260/1260 [==============================] - 1s 888us/step - loss: 0.0108 - MSE: 0.0108 - val_loss: 0.0129 - val_MSE: 0.0129\n",
      "Epoch 11/100\n",
      "1260/1260 [==============================] - 1s 897us/step - loss: 0.0104 - MSE: 0.0104 - val_loss: 0.0112 - val_MSE: 0.0112\n",
      "Epoch 12/100\n",
      "1260/1260 [==============================] - 1s 895us/step - loss: 0.0103 - MSE: 0.0103 - val_loss: 0.0140 - val_MSE: 0.0140\n",
      "Epoch 13/100\n",
      "1260/1260 [==============================] - 1s 918us/step - loss: 0.0101 - MSE: 0.0101 - val_loss: 0.0115 - val_MSE: 0.0115\n",
      "Epoch 14/100\n",
      "1260/1260 [==============================] - 1s 908us/step - loss: 0.0110 - MSE: 0.0110 - val_loss: 0.0125 - val_MSE: 0.0125\n",
      "Epoch 15/100\n",
      "1260/1260 [==============================] - 1s 900us/step - loss: 0.0101 - MSE: 0.0101 - val_loss: 0.0142 - val_MSE: 0.0142\n",
      "Epoch 16/100\n",
      "1260/1260 [==============================] - 1s 889us/step - loss: 0.0099 - MSE: 0.0099 - val_loss: 0.0114 - val_MSE: 0.0114\n",
      "Epoch 17/100\n",
      "1260/1260 [==============================] - 1s 890us/step - loss: 0.0106 - MSE: 0.0106 - val_loss: 0.0113 - val_MSE: 0.0113\n",
      "Epoch 18/100\n",
      "1260/1260 [==============================] - 1s 902us/step - loss: 0.0100 - MSE: 0.0100 - val_loss: 0.0113 - val_MSE: 0.0113\n",
      "Epoch 19/100\n",
      "1260/1260 [==============================] - 1s 953us/step - loss: 0.0101 - MSE: 0.0101 - val_loss: 0.0134 - val_MSE: 0.0134\n",
      "Epoch 20/100\n",
      "1260/1260 [==============================] - 1s 973us/step - loss: 0.0106 - MSE: 0.0106 - val_loss: 0.0127 - val_MSE: 0.0127\n",
      "Epoch 21/100\n",
      "1260/1260 [==============================] - 1s 1ms/step - loss: 0.0103 - MSE: 0.0103 - val_loss: 0.0120 - val_MSE: 0.0120\n",
      "QWK, Prompt 2, Fold 2: 0.6137841352405722\n",
      "Fold 3\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1800, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1260 samples, validate on 270 samples\n",
      "Epoch 1/100\n",
      "1260/1260 [==============================] - 6s 5ms/step - loss: 0.0209 - MSE: 0.0209 - val_loss: 0.0164 - val_MSE: 0.0164\n",
      "Epoch 2/100\n",
      "1260/1260 [==============================] - 1s 755us/step - loss: 0.0121 - MSE: 0.0121 - val_loss: 0.0101 - val_MSE: 0.0101\n",
      "Epoch 3/100\n",
      "1260/1260 [==============================] - 1s 733us/step - loss: 0.0123 - MSE: 0.0123 - val_loss: 0.0118 - val_MSE: 0.0118\n",
      "Epoch 4/100\n",
      "1260/1260 [==============================] - ETA: 0s - loss: 0.0125 - MSE: 0.012 - 1s 763us/step - loss: 0.0128 - MSE: 0.0128 - val_loss: 0.0112 - val_MSE: 0.0112\n",
      "Epoch 5/100\n",
      "1260/1260 [==============================] - 1s 781us/step - loss: 0.0126 - MSE: 0.0126 - val_loss: 0.0155 - val_MSE: 0.0155\n",
      "Epoch 6/100\n",
      "1260/1260 [==============================] - 1s 756us/step - loss: 0.0115 - MSE: 0.0115 - val_loss: 0.0136 - val_MSE: 0.0136\n",
      "Epoch 7/100\n",
      "1260/1260 [==============================] - 1s 743us/step - loss: 0.0111 - MSE: 0.0111 - val_loss: 0.0095 - val_MSE: 0.0095\n",
      "Epoch 8/100\n",
      "1260/1260 [==============================] - 1s 742us/step - loss: 0.0102 - MSE: 0.0102 - val_loss: 0.0098 - val_MSE: 0.0098\n",
      "Epoch 9/100\n",
      "1260/1260 [==============================] - 1s 744us/step - loss: 0.0102 - MSE: 0.0102 - val_loss: 0.0095 - val_MSE: 0.0095\n",
      "Epoch 10/100\n",
      "1260/1260 [==============================] - 1s 755us/step - loss: 0.0110 - MSE: 0.0110 - val_loss: 0.0153 - val_MSE: 0.0153\n",
      "Epoch 11/100\n",
      "1260/1260 [==============================] - 1s 737us/step - loss: 0.0111 - MSE: 0.0111 - val_loss: 0.0102 - val_MSE: 0.0102\n",
      "Epoch 12/100\n",
      "1260/1260 [==============================] - 1s 761us/step - loss: 0.0111 - MSE: 0.0111 - val_loss: 0.0095 - val_MSE: 0.0095\n",
      "Epoch 13/100\n",
      "1260/1260 [==============================] - 1s 772us/step - loss: 0.0102 - MSE: 0.0102 - val_loss: 0.0125 - val_MSE: 0.0125\n",
      "Epoch 14/100\n",
      "1260/1260 [==============================] - 1s 753us/step - loss: 0.0105 - MSE: 0.0105 - val_loss: 0.0108 - val_MSE: 0.0108\n",
      "Epoch 15/100\n",
      "1260/1260 [==============================] - 1s 754us/step - loss: 0.0118 - MSE: 0.0118 - val_loss: 0.0094 - val_MSE: 0.0094\n",
      "Epoch 16/100\n",
      "1260/1260 [==============================] - 1s 742us/step - loss: 0.0104 - MSE: 0.0104 - val_loss: 0.0106 - val_MSE: 0.0106\n",
      "Epoch 17/100\n",
      "1260/1260 [==============================] - 1s 741us/step - loss: 0.0109 - MSE: 0.0109 - val_loss: 0.0095 - val_MSE: 0.0095\n",
      "Epoch 18/100\n",
      "1260/1260 [==============================] - 1s 741us/step - loss: 0.0104 - MSE: 0.0104 - val_loss: 0.0095 - val_MSE: 0.0095\n",
      "Epoch 19/100\n",
      "1260/1260 [==============================] - 1s 735us/step - loss: 0.0102 - MSE: 0.0102 - val_loss: 0.0105 - val_MSE: 0.0105\n",
      "Epoch 20/100\n",
      "1260/1260 [==============================] - 1s 733us/step - loss: 0.0103 - MSE: 0.0103 - val_loss: 0.0135 - val_MSE: 0.0135\n",
      "Epoch 21/100\n",
      "1260/1260 [==============================] - 1s 743us/step - loss: 0.0100 - MSE: 0.0100 - val_loss: 0.0109 - val_MSE: 0.0109\n",
      "Epoch 22/100\n",
      "1260/1260 [==============================] - 1s 740us/step - loss: 0.0101 - MSE: 0.0101 - val_loss: 0.0096 - val_MSE: 0.0096\n",
      "Epoch 23/100\n",
      "1260/1260 [==============================] - 1s 741us/step - loss: 0.0107 - MSE: 0.0107 - val_loss: 0.0129 - val_MSE: 0.0129\n",
      "Epoch 24/100\n",
      "1260/1260 [==============================] - 1s 755us/step - loss: 0.0100 - MSE: 0.0100 - val_loss: 0.0122 - val_MSE: 0.0122\n",
      "Epoch 25/100\n",
      "1260/1260 [==============================] - 1s 732us/step - loss: 0.0101 - MSE: 0.0101 - val_loss: 0.0095 - val_MSE: 0.0095\n",
      "QWK, Prompt 2, Fold 3: 0.6716077537058154\n",
      "Fold 4\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1800, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1260 samples, validate on 270 samples\n",
      "Epoch 1/100\n",
      "1260/1260 [==============================] - 9s 7ms/step - loss: 0.0184 - MSE: 0.0184 - val_loss: 0.0107 - val_MSE: 0.0107\n",
      "Epoch 2/100\n",
      "1260/1260 [==============================] - 1s 924us/step - loss: 0.0125 - MSE: 0.0125 - val_loss: 0.0128 - val_MSE: 0.0128\n",
      "Epoch 3/100\n",
      "1260/1260 [==============================] - 1s 922us/step - loss: 0.0123 - MSE: 0.0123 - val_loss: 0.0118 - val_MSE: 0.0118\n",
      "Epoch 4/100\n",
      "1260/1260 [==============================] - 1s 913us/step - loss: 0.0117 - MSE: 0.0117 - val_loss: 0.0104 - val_MSE: 0.0104\n",
      "Epoch 5/100\n",
      "1260/1260 [==============================] - 1s 1ms/step - loss: 0.0125 - MSE: 0.0125 - val_loss: 0.0116 - val_MSE: 0.0116\n",
      "Epoch 6/100\n",
      "1260/1260 [==============================] - 1s 928us/step - loss: 0.0107 - MSE: 0.0107 - val_loss: 0.0105 - val_MSE: 0.0105\n",
      "Epoch 7/100\n",
      "1260/1260 [==============================] - 1s 896us/step - loss: 0.0110 - MSE: 0.0110 - val_loss: 0.0108 - val_MSE: 0.0108\n",
      "Epoch 8/100\n",
      "1260/1260 [==============================] - 1s 944us/step - loss: 0.0114 - MSE: 0.0114 - val_loss: 0.0105 - val_MSE: 0.0105\n",
      "Epoch 9/100\n",
      "1260/1260 [==============================] - 1s 994us/step - loss: 0.0113 - MSE: 0.0113 - val_loss: 0.0123 - val_MSE: 0.0123\n",
      "Epoch 10/100\n",
      "1260/1260 [==============================] - 1s 1ms/step - loss: 0.0134 - MSE: 0.0134 - val_loss: 0.0105 - val_MSE: 0.0105\n",
      "Epoch 11/100\n",
      "1260/1260 [==============================] - 1s 1ms/step - loss: 0.0112 - MSE: 0.0112 - val_loss: 0.0116 - val_MSE: 0.0116\n",
      "Epoch 12/100\n",
      "1260/1260 [==============================] - 1s 1ms/step - loss: 0.0105 - MSE: 0.0105 - val_loss: 0.0120 - val_MSE: 0.0120\n",
      "Epoch 13/100\n",
      "1260/1260 [==============================] - 1s 1ms/step - loss: 0.0115 - MSE: 0.0115 - val_loss: 0.0121 - val_MSE: 0.0121\n",
      "Epoch 14/100\n",
      "1260/1260 [==============================] - 1s 983us/step - loss: 0.0108 - MSE: 0.0108 - val_loss: 0.0103 - val_MSE: 0.0103\n",
      "Epoch 15/100\n",
      "1260/1260 [==============================] - 1s 997us/step - loss: 0.0103 - MSE: 0.0103 - val_loss: 0.0109 - val_MSE: 0.0109\n",
      "Epoch 16/100\n",
      "1260/1260 [==============================] - 1s 896us/step - loss: 0.0106 - MSE: 0.0106 - val_loss: 0.0103 - val_MSE: 0.0103\n",
      "Epoch 17/100\n",
      "1260/1260 [==============================] - 1s 978us/step - loss: 0.0102 - MSE: 0.0102 - val_loss: 0.0104 - val_MSE: 0.0104\n",
      "Epoch 18/100\n",
      "1260/1260 [==============================] - 1s 1ms/step - loss: 0.0100 - MSE: 0.0100 - val_loss: 0.0104 - val_MSE: 0.0104\n",
      "Epoch 19/100\n",
      "1260/1260 [==============================] - 1s 987us/step - loss: 0.0103 - MSE: 0.0103 - val_loss: 0.0131 - val_MSE: 0.0131\n",
      "Epoch 20/100\n",
      "1260/1260 [==============================] - 1s 1ms/step - loss: 0.0105 - MSE: 0.0105 - val_loss: 0.0192 - val_MSE: 0.0192\n",
      "Epoch 21/100\n",
      "1260/1260 [==============================] - 1s 988us/step - loss: 0.0104 - MSE: 0.0104 - val_loss: 0.0106 - val_MSE: 0.0106\n",
      "Epoch 22/100\n",
      "1260/1260 [==============================] - 1s 972us/step - loss: 0.0100 - MSE: 0.0100 - val_loss: 0.0111 - val_MSE: 0.0111\n",
      "Epoch 23/100\n",
      "1260/1260 [==============================] - 1s 881us/step - loss: 0.0104 - MSE: 0.0104 - val_loss: 0.0110 - val_MSE: 0.0110\n",
      "Epoch 24/100\n",
      "1260/1260 [==============================] - 1s 897us/step - loss: 0.0100 - MSE: 0.0100 - val_loss: 0.0103 - val_MSE: 0.0103\n",
      "Epoch 25/100\n",
      "1260/1260 [==============================] - 1s 879us/step - loss: 0.0105 - MSE: 0.0105 - val_loss: 0.0103 - val_MSE: 0.0103\n",
      "Epoch 26/100\n",
      "1260/1260 [==============================] - 1s 875us/step - loss: 0.0099 - MSE: 0.0099 - val_loss: 0.0104 - val_MSE: 0.0104\n",
      "QWK, Prompt 2, Fold 4: 0.6627108057464084\n",
      "Fold 5\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1800, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1260 samples, validate on 270 samples\n",
      "Epoch 1/100\n",
      "1260/1260 [==============================] - 8s 6ms/step - loss: 0.0244 - MSE: 0.0244 - val_loss: 0.0122 - val_MSE: 0.0122\n",
      "Epoch 2/100\n",
      "1260/1260 [==============================] - 1s 920us/step - loss: 0.0137 - MSE: 0.0137 - val_loss: 0.0121 - val_MSE: 0.0121\n",
      "Epoch 3/100\n",
      "1260/1260 [==============================] - 1s 909us/step - loss: 0.0126 - MSE: 0.0126 - val_loss: 0.0119 - val_MSE: 0.0119\n",
      "Epoch 4/100\n",
      "1260/1260 [==============================] - 1s 906us/step - loss: 0.0112 - MSE: 0.0112 - val_loss: 0.0120 - val_MSE: 0.0120\n",
      "Epoch 5/100\n",
      "1260/1260 [==============================] - 1s 906us/step - loss: 0.0127 - MSE: 0.0127 - val_loss: 0.0115 - val_MSE: 0.0115\n",
      "Epoch 6/100\n",
      "1260/1260 [==============================] - 1s 935us/step - loss: 0.0119 - MSE: 0.0119 - val_loss: 0.0190 - val_MSE: 0.0190\n",
      "Epoch 7/100\n",
      "1260/1260 [==============================] - 1s 925us/step - loss: 0.0107 - MSE: 0.0107 - val_loss: 0.0116 - val_MSE: 0.0116\n",
      "Epoch 8/100\n",
      "1260/1260 [==============================] - 1s 944us/step - loss: 0.0125 - MSE: 0.0125 - val_loss: 0.0109 - val_MSE: 0.0109\n",
      "Epoch 9/100\n",
      "1260/1260 [==============================] - 1s 919us/step - loss: 0.0109 - MSE: 0.0109 - val_loss: 0.0109 - val_MSE: 0.0109\n",
      "Epoch 10/100\n",
      "1260/1260 [==============================] - 1s 978us/step - loss: 0.0101 - MSE: 0.0101 - val_loss: 0.0109 - val_MSE: 0.0109\n",
      "Epoch 11/100\n",
      "1260/1260 [==============================] - 1s 1ms/step - loss: 0.0098 - MSE: 0.0098 - val_loss: 0.0108 - val_MSE: 0.0108\n",
      "Epoch 12/100\n",
      "1260/1260 [==============================] - 1s 1ms/step - loss: 0.0102 - MSE: 0.0102 - val_loss: 0.0108 - val_MSE: 0.0108\n",
      "Epoch 13/100\n",
      "1260/1260 [==============================] - 1s 1ms/step - loss: 0.0103 - MSE: 0.0103 - val_loss: 0.0108 - val_MSE: 0.0108\n",
      "Epoch 14/100\n",
      "1260/1260 [==============================] - 1s 996us/step - loss: 0.0111 - MSE: 0.0111 - val_loss: 0.0109 - val_MSE: 0.0109\n",
      "Epoch 15/100\n",
      "1260/1260 [==============================] - 1s 920us/step - loss: 0.0102 - MSE: 0.0102 - val_loss: 0.0118 - val_MSE: 0.0118\n",
      "Epoch 16/100\n",
      "1260/1260 [==============================] - 1s 959us/step - loss: 0.0110 - MSE: 0.0110 - val_loss: 0.0116 - val_MSE: 0.0116\n",
      "Epoch 17/100\n",
      "1260/1260 [==============================] - 1s 922us/step - loss: 0.0101 - MSE: 0.0101 - val_loss: 0.0106 - val_MSE: 0.0106\n",
      "Epoch 18/100\n",
      "1260/1260 [==============================] - 1s 923us/step - loss: 0.0111 - MSE: 0.0111 - val_loss: 0.0111 - val_MSE: 0.0111\n",
      "Epoch 19/100\n",
      "1260/1260 [==============================] - 1s 920us/step - loss: 0.0098 - MSE: 0.0098 - val_loss: 0.0114 - val_MSE: 0.0114\n",
      "Epoch 20/100\n",
      "1260/1260 [==============================] - 1s 936us/step - loss: 0.0103 - MSE: 0.0103 - val_loss: 0.0106 - val_MSE: 0.0106\n",
      "Epoch 21/100\n",
      "1260/1260 [==============================] - 1s 936us/step - loss: 0.0105 - MSE: 0.0105 - val_loss: 0.0113 - val_MSE: 0.0113\n",
      "Epoch 22/100\n",
      "1260/1260 [==============================] - 1s 923us/step - loss: 0.0104 - MSE: 0.0104 - val_loss: 0.0130 - val_MSE: 0.0130\n",
      "Epoch 23/100\n",
      "1260/1260 [==============================] - 1s 907us/step - loss: 0.0103 - MSE: 0.0103 - val_loss: 0.0112 - val_MSE: 0.0112\n",
      "Epoch 24/100\n",
      "1260/1260 [==============================] - 1s 913us/step - loss: 0.0100 - MSE: 0.0100 - val_loss: 0.0116 - val_MSE: 0.0116\n",
      "Epoch 25/100\n",
      "1260/1260 [==============================] - 1s 929us/step - loss: 0.0102 - MSE: 0.0102 - val_loss: 0.0130 - val_MSE: 0.0130\n",
      "Epoch 26/100\n",
      "1260/1260 [==============================] - 1s 991us/step - loss: 0.0097 - MSE: 0.0097 - val_loss: 0.0115 - val_MSE: 0.0115\n",
      "Epoch 27/100\n",
      "1260/1260 [==============================] - 1s 1ms/step - loss: 0.0095 - MSE: 0.0095 - val_loss: 0.0115 - val_MSE: 0.0115\n",
      "QWK, Prompt 2, Fold 5: 0.7315414715504522\n",
      "Prompt: 3\n",
      "Fold 1\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1726, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1209 samples, validate on 259 samples\n",
      "Epoch 1/100\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0589 - MSE: 0.0589 - val_loss: 0.0467 - val_MSE: 0.0467\n",
      "Epoch 2/100\n",
      "1209/1209 [==============================] - 1s 913us/step - loss: 0.0473 - MSE: 0.0473 - val_loss: 0.0449 - val_MSE: 0.0449\n",
      "Epoch 3/100\n",
      "1209/1209 [==============================] - 1s 901us/step - loss: 0.0456 - MSE: 0.0456 - val_loss: 0.0573 - val_MSE: 0.0573\n",
      "Epoch 4/100\n",
      "1209/1209 [==============================] - 1s 896us/step - loss: 0.0459 - MSE: 0.0459 - val_loss: 0.0454 - val_MSE: 0.0454\n",
      "Epoch 5/100\n",
      "1209/1209 [==============================] - 1s 908us/step - loss: 0.0448 - MSE: 0.0448 - val_loss: 0.0527 - val_MSE: 0.0527\n",
      "Epoch 6/100\n",
      "1209/1209 [==============================] - 1s 899us/step - loss: 0.0473 - MSE: 0.0473 - val_loss: 0.0451 - val_MSE: 0.0451\n",
      "Epoch 7/100\n",
      "1209/1209 [==============================] - 1s 895us/step - loss: 0.0511 - MSE: 0.0511 - val_loss: 0.0535 - val_MSE: 0.0535\n",
      "Epoch 8/100\n",
      "1209/1209 [==============================] - 1s 934us/step - loss: 0.0450 - MSE: 0.0450 - val_loss: 0.0613 - val_MSE: 0.0613\n",
      "Epoch 9/100\n",
      "1209/1209 [==============================] - 1s 914us/step - loss: 0.0457 - MSE: 0.0457 - val_loss: 0.0465 - val_MSE: 0.0465\n",
      "Epoch 10/100\n",
      "1209/1209 [==============================] - ETA: 0s - loss: 0.0428 - MSE: 0.042 - 1s 893us/step - loss: 0.0434 - MSE: 0.0434 - val_loss: 0.0466 - val_MSE: 0.0466\n",
      "Epoch 11/100\n",
      "1209/1209 [==============================] - 1s 897us/step - loss: 0.0426 - MSE: 0.0426 - val_loss: 0.0463 - val_MSE: 0.0463\n",
      "Epoch 12/100\n",
      "1209/1209 [==============================] - 1s 920us/step - loss: 0.0427 - MSE: 0.0427 - val_loss: 0.0533 - val_MSE: 0.0533\n",
      "QWK, Prompt 3, Fold 1: 0.5903735271997994\n",
      "Fold 2\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1726, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1209 samples, validate on 259 samples\n",
      "Epoch 1/100\n",
      "1209/1209 [==============================] - 7s 6ms/step - loss: 0.0609 - MSE: 0.0609 - val_loss: 0.0425 - val_MSE: 0.0425\n",
      "Epoch 2/100\n",
      "1209/1209 [==============================] - 1s 907us/step - loss: 0.0483 - MSE: 0.0483 - val_loss: 0.0432 - val_MSE: 0.0432\n",
      "Epoch 3/100\n",
      "1209/1209 [==============================] - 1s 905us/step - loss: 0.0463 - MSE: 0.0463 - val_loss: 0.0411 - val_MSE: 0.0411\n",
      "Epoch 4/100\n",
      "1209/1209 [==============================] - 1s 943us/step - loss: 0.0460 - MSE: 0.0460 - val_loss: 0.0424 - val_MSE: 0.0424\n",
      "Epoch 5/100\n",
      "1209/1209 [==============================] - 1s 913us/step - loss: 0.0440 - MSE: 0.0440 - val_loss: 0.0427 - val_MSE: 0.0427\n",
      "Epoch 6/100\n",
      "1209/1209 [==============================] - 1s 921us/step - loss: 0.0423 - MSE: 0.0423 - val_loss: 0.0504 - val_MSE: 0.0504\n",
      "Epoch 7/100\n",
      "1209/1209 [==============================] - 1s 930us/step - loss: 0.0432 - MSE: 0.0432 - val_loss: 0.0413 - val_MSE: 0.0413\n",
      "Epoch 8/100\n",
      "1209/1209 [==============================] - 1s 910us/step - loss: 0.0441 - MSE: 0.0441 - val_loss: 0.0472 - val_MSE: 0.0472\n",
      "Epoch 9/100\n",
      "1209/1209 [==============================] - 1s 916us/step - loss: 0.0438 - MSE: 0.0438 - val_loss: 0.0415 - val_MSE: 0.0415\n",
      "Epoch 10/100\n",
      "1209/1209 [==============================] - 1s 906us/step - loss: 0.0428 - MSE: 0.0428 - val_loss: 0.0441 - val_MSE: 0.0441\n",
      "Epoch 11/100\n",
      "1209/1209 [==============================] - 1s 905us/step - loss: 0.0427 - MSE: 0.0427 - val_loss: 0.0417 - val_MSE: 0.0417\n",
      "Epoch 12/100\n",
      "1209/1209 [==============================] - 1s 941us/step - loss: 0.0403 - MSE: 0.0403 - val_loss: 0.0419 - val_MSE: 0.0419\n",
      "Epoch 13/100\n",
      "1209/1209 [==============================] - 1s 907us/step - loss: 0.0410 - MSE: 0.0410 - val_loss: 0.0419 - val_MSE: 0.0419\n",
      "QWK, Prompt 3, Fold 2: 0.4631181205848529\n",
      "Fold 3\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1726, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1209 samples, validate on 259 samples\n",
      "Epoch 1/100\n",
      "1209/1209 [==============================] - 8s 7ms/step - loss: 0.0524 - MSE: 0.0524 - val_loss: 0.0536 - val_MSE: 0.0536\n",
      "Epoch 2/100\n",
      "1209/1209 [==============================] - 1s 1ms/step - loss: 0.0486 - MSE: 0.0486 - val_loss: 0.0522 - val_MSE: 0.0522\n",
      "Epoch 3/100\n",
      "1209/1209 [==============================] - 1s 1ms/step - loss: 0.0460 - MSE: 0.0460 - val_loss: 0.0527 - val_MSE: 0.0527\n",
      "Epoch 4/100\n",
      "1209/1209 [==============================] - 1s 997us/step - loss: 0.0464 - MSE: 0.0464 - val_loss: 0.0493 - val_MSE: 0.0493\n",
      "Epoch 5/100\n",
      "1209/1209 [==============================] - 1s 1ms/step - loss: 0.0428 - MSE: 0.0428 - val_loss: 0.0476 - val_MSE: 0.0476\n",
      "Epoch 6/100\n",
      "1209/1209 [==============================] - 1s 1ms/step - loss: 0.0425 - MSE: 0.0425 - val_loss: 0.0518 - val_MSE: 0.0518\n",
      "Epoch 7/100\n",
      "1209/1209 [==============================] - 1s 1ms/step - loss: 0.0428 - MSE: 0.0428 - val_loss: 0.0489 - val_MSE: 0.0489\n",
      "Epoch 8/100\n",
      "1209/1209 [==============================] - 1s 1ms/step - loss: 0.0431 - MSE: 0.0431 - val_loss: 0.0485 - val_MSE: 0.0485\n",
      "Epoch 9/100\n",
      "1209/1209 [==============================] - 1s 1ms/step - loss: 0.0404 - MSE: 0.0404 - val_loss: 0.0481 - val_MSE: 0.0481\n",
      "Epoch 10/100\n",
      "1209/1209 [==============================] - 1s 1ms/step - loss: 0.0421 - MSE: 0.0421 - val_loss: 0.0514 - val_MSE: 0.0514\n",
      "Epoch 11/100\n",
      "1209/1209 [==============================] - 1s 1ms/step - loss: 0.0407 - MSE: 0.0407 - val_loss: 0.0575 - val_MSE: 0.0575\n",
      "Epoch 12/100\n",
      "1209/1209 [==============================] - 1s 1ms/step - loss: 0.0416 - MSE: 0.0416 - val_loss: 0.0497 - val_MSE: 0.0497\n",
      "Epoch 13/100\n",
      "1209/1209 [==============================] - 1s 996us/step - loss: 0.0400 - MSE: 0.0400 - val_loss: 0.0486 - val_MSE: 0.0486\n",
      "Epoch 14/100\n",
      "1209/1209 [==============================] - 1s 974us/step - loss: 0.0414 - MSE: 0.0414 - val_loss: 0.0491 - val_MSE: 0.0491\n",
      "Epoch 15/100\n",
      "1209/1209 [==============================] - 1s 1000us/step - loss: 0.0403 - MSE: 0.0403 - val_loss: 0.0500 - val_MSE: 0.0500\n",
      "QWK, Prompt 3, Fold 3: 0.541105468462501\n",
      "Fold 4\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1726, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1209 samples, validate on 259 samples\n",
      "Epoch 1/100\n",
      "1209/1209 [==============================] - 7s 6ms/step - loss: 0.0634 - MSE: 0.0634 - val_loss: 0.0402 - val_MSE: 0.0402\n",
      "Epoch 2/100\n",
      "1209/1209 [==============================] - 1s 905us/step - loss: 0.0493 - MSE: 0.0493 - val_loss: 0.0396 - val_MSE: 0.0396\n",
      "Epoch 3/100\n",
      "1209/1209 [==============================] - 1s 901us/step - loss: 0.0446 - MSE: 0.0446 - val_loss: 0.0411 - val_MSE: 0.0411\n",
      "Epoch 4/100\n",
      "1209/1209 [==============================] - 1s 905us/step - loss: 0.0473 - MSE: 0.0473 - val_loss: 0.0441 - val_MSE: 0.0441\n",
      "Epoch 5/100\n",
      "1209/1209 [==============================] - 1s 911us/step - loss: 0.0439 - MSE: 0.0439 - val_loss: 0.0441 - val_MSE: 0.0441\n",
      "Epoch 6/100\n",
      "1209/1209 [==============================] - 1s 904us/step - loss: 0.0478 - MSE: 0.0478 - val_loss: 0.0427 - val_MSE: 0.0427\n",
      "Epoch 7/100\n",
      "1209/1209 [==============================] - 1s 897us/step - loss: 0.0433 - MSE: 0.0433 - val_loss: 0.0420 - val_MSE: 0.0420\n",
      "Epoch 8/100\n",
      "1209/1209 [==============================] - 1s 907us/step - loss: 0.0423 - MSE: 0.0423 - val_loss: 0.0429 - val_MSE: 0.0429\n",
      "Epoch 9/100\n",
      "1209/1209 [==============================] - 1s 923us/step - loss: 0.0449 - MSE: 0.0449 - val_loss: 0.0442 - val_MSE: 0.0442\n",
      "Epoch 10/100\n",
      "1209/1209 [==============================] - 1s 923us/step - loss: 0.0445 - MSE: 0.0445 - val_loss: 0.0436 - val_MSE: 0.0436\n",
      "Epoch 11/100\n",
      "1209/1209 [==============================] - 1s 913us/step - loss: 0.0440 - MSE: 0.0440 - val_loss: 0.0451 - val_MSE: 0.0451\n",
      "Epoch 12/100\n",
      "1209/1209 [==============================] - 1s 918us/step - loss: 0.0431 - MSE: 0.0431 - val_loss: 0.0483 - val_MSE: 0.0483\n",
      "QWK, Prompt 3, Fold 4: 0.48587339284251907\n",
      "Fold 5\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1726, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1209 samples, validate on 259 samples\n",
      "Epoch 1/100\n",
      "1209/1209 [==============================] - 8s 7ms/step - loss: 0.0686 - MSE: 0.0686 - val_loss: 0.0386 - val_MSE: 0.0386\n",
      "Epoch 2/100\n",
      "1209/1209 [==============================] - 1s 949us/step - loss: 0.0470 - MSE: 0.0470 - val_loss: 0.0373 - val_MSE: 0.0373\n",
      "Epoch 3/100\n",
      "1209/1209 [==============================] - 1s 916us/step - loss: 0.0489 - MSE: 0.0489 - val_loss: 0.0511 - val_MSE: 0.0511\n",
      "Epoch 4/100\n",
      "1209/1209 [==============================] - 1s 921us/step - loss: 0.0486 - MSE: 0.0486 - val_loss: 0.0367 - val_MSE: 0.0367\n",
      "Epoch 5/100\n",
      "1209/1209 [==============================] - 1s 922us/step - loss: 0.0479 - MSE: 0.0479 - val_loss: 0.0367 - val_MSE: 0.0367\n",
      "Epoch 6/100\n",
      "1209/1209 [==============================] - 1s 920us/step - loss: 0.0468 - MSE: 0.0468 - val_loss: 0.0375 - val_MSE: 0.0375\n",
      "Epoch 7/100\n",
      "1209/1209 [==============================] - 1s 927us/step - loss: 0.0463 - MSE: 0.0463 - val_loss: 0.0525 - val_MSE: 0.0525\n",
      "Epoch 8/100\n",
      "1209/1209 [==============================] - 1s 918us/step - loss: 0.0481 - MSE: 0.0481 - val_loss: 0.0368 - val_MSE: 0.0368\n",
      "Epoch 9/100\n",
      "1209/1209 [==============================] - 1s 921us/step - loss: 0.0437 - MSE: 0.0437 - val_loss: 0.0377 - val_MSE: 0.0377\n",
      "Epoch 10/100\n",
      "1209/1209 [==============================] - 1s 911us/step - loss: 0.0439 - MSE: 0.0439 - val_loss: 0.0426 - val_MSE: 0.0426\n",
      "Epoch 11/100\n",
      "1209/1209 [==============================] - 1s 922us/step - loss: 0.0435 - MSE: 0.0435 - val_loss: 0.0414 - val_MSE: 0.0414\n",
      "Epoch 12/100\n",
      "1209/1209 [==============================] - 1s 951us/step - loss: 0.0462 - MSE: 0.0462 - val_loss: 0.0379 - val_MSE: 0.0379\n",
      "Epoch 13/100\n",
      "1209/1209 [==============================] - 1s 930us/step - loss: 0.0432 - MSE: 0.0432 - val_loss: 0.0418 - val_MSE: 0.0418\n",
      "Epoch 14/100\n",
      "1209/1209 [==============================] - 1s 1ms/step - loss: 0.0439 - MSE: 0.0439 - val_loss: 0.0402 - val_MSE: 0.0402\n",
      "Epoch 15/100\n",
      "1209/1209 [==============================] - 1s 917us/step - loss: 0.0427 - MSE: 0.0427 - val_loss: 0.0375 - val_MSE: 0.0375\n",
      "QWK, Prompt 3, Fold 5: 0.5013965298349556\n",
      "Prompt: 4\n",
      "Fold 1\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1772, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1241 samples, validate on 266 samples\n",
      "Epoch 1/100\n",
      "1241/1241 [==============================] - 8s 7ms/step - loss: 0.0663 - MSE: 0.0663 - val_loss: 0.0473 - val_MSE: 0.0473\n",
      "Epoch 2/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0403 - MSE: 0.0403 - val_loss: 0.0412 - val_MSE: 0.0412\n",
      "Epoch 3/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0408 - MSE: 0.0408 - val_loss: 0.0423 - val_MSE: 0.0423\n",
      "Epoch 4/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0378 - MSE: 0.0378 - val_loss: 0.0552 - val_MSE: 0.0552\n",
      "Epoch 5/100\n",
      "1241/1241 [==============================] - 1s 922us/step - loss: 0.0416 - MSE: 0.0416 - val_loss: 0.0544 - val_MSE: 0.0544\n",
      "Epoch 6/100\n",
      "1241/1241 [==============================] - 1s 952us/step - loss: 0.0413 - MSE: 0.0413 - val_loss: 0.0439 - val_MSE: 0.0439\n",
      "Epoch 7/100\n",
      "1241/1241 [==============================] - 1s 888us/step - loss: 0.0363 - MSE: 0.0363 - val_loss: 0.0442 - val_MSE: 0.0442\n",
      "Epoch 8/100\n",
      "1241/1241 [==============================] - 1s 946us/step - loss: 0.0349 - MSE: 0.0349 - val_loss: 0.0399 - val_MSE: 0.0399\n",
      "Epoch 9/100\n",
      "1241/1241 [==============================] - 1s 965us/step - loss: 0.0345 - MSE: 0.0345 - val_loss: 0.0399 - val_MSE: 0.0399\n",
      "Epoch 10/100\n",
      "1241/1241 [==============================] - 1s 995us/step - loss: 0.0340 - MSE: 0.0340 - val_loss: 0.0407 - val_MSE: 0.0407\n",
      "Epoch 11/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0360 - MSE: 0.0360 - val_loss: 0.0434 - val_MSE: 0.0434\n",
      "Epoch 12/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0370 - MSE: 0.0370 - val_loss: 0.0409 - val_MSE: 0.0409\n",
      "Epoch 13/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0347 - MSE: 0.0347 - val_loss: 0.0398 - val_MSE: 0.0398\n",
      "Epoch 14/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0353 - MSE: 0.0353 - val_loss: 0.0398 - val_MSE: 0.0398\n",
      "Epoch 15/100\n",
      "1241/1241 [==============================] - 1s 964us/step - loss: 0.0335 - MSE: 0.0335 - val_loss: 0.0513 - val_MSE: 0.0513\n",
      "Epoch 16/100\n",
      "1241/1241 [==============================] - 1s 851us/step - loss: 0.0352 - MSE: 0.0352 - val_loss: 0.0394 - val_MSE: 0.0394\n",
      "Epoch 17/100\n",
      "1241/1241 [==============================] - 1s 938us/step - loss: 0.0329 - MSE: 0.0329 - val_loss: 0.0450 - val_MSE: 0.0450\n",
      "Epoch 18/100\n",
      "1241/1241 [==============================] - 1s 846us/step - loss: 0.0347 - MSE: 0.0347 - val_loss: 0.0394 - val_MSE: 0.0394\n",
      "Epoch 19/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0333 - MSE: 0.0333 - val_loss: 0.0410 - val_MSE: 0.0410\n",
      "Epoch 20/100\n",
      "1241/1241 [==============================] - 1s 982us/step - loss: 0.0332 - MSE: 0.0332 - val_loss: 0.0671 - val_MSE: 0.0671\n",
      "Epoch 21/100\n",
      "1241/1241 [==============================] - 1s 863us/step - loss: 0.0418 - MSE: 0.0418 - val_loss: 0.0410 - val_MSE: 0.0410\n",
      "Epoch 22/100\n",
      "1241/1241 [==============================] - 1s 809us/step - loss: 0.0331 - MSE: 0.0331 - val_loss: 0.0396 - val_MSE: 0.0396\n",
      "Epoch 23/100\n",
      "1241/1241 [==============================] - 1s 842us/step - loss: 0.0329 - MSE: 0.0329 - val_loss: 0.0403 - val_MSE: 0.0403\n",
      "Epoch 24/100\n",
      "1241/1241 [==============================] - 1s 841us/step - loss: 0.0325 - MSE: 0.0325 - val_loss: 0.0391 - val_MSE: 0.0391\n",
      "Epoch 25/100\n",
      "1241/1241 [==============================] - 1s 857us/step - loss: 0.0328 - MSE: 0.0328 - val_loss: 0.0392 - val_MSE: 0.0392\n",
      "Epoch 26/100\n",
      "1241/1241 [==============================] - 1s 825us/step - loss: 0.0321 - MSE: 0.0321 - val_loss: 0.0407 - val_MSE: 0.0407\n",
      "Epoch 27/100\n",
      "1241/1241 [==============================] - 1s 828us/step - loss: 0.0330 - MSE: 0.0330 - val_loss: 0.0399 - val_MSE: 0.0399\n",
      "Epoch 28/100\n",
      "1241/1241 [==============================] - 1s 932us/step - loss: 0.0319 - MSE: 0.0319 - val_loss: 0.0392 - val_MSE: 0.0392\n",
      "Epoch 29/100\n",
      "1241/1241 [==============================] - 1s 908us/step - loss: 0.0332 - MSE: 0.0332 - val_loss: 0.0392 - val_MSE: 0.0392\n",
      "Epoch 30/100\n",
      "1241/1241 [==============================] - 1s 848us/step - loss: 0.0325 - MSE: 0.0325 - val_loss: 0.0404 - val_MSE: 0.0404\n",
      "Epoch 31/100\n",
      "1241/1241 [==============================] - 1s 904us/step - loss: 0.0335 - MSE: 0.0335 - val_loss: 0.0392 - val_MSE: 0.0392\n",
      "Epoch 32/100\n",
      "1241/1241 [==============================] - 1s 995us/step - loss: 0.0340 - MSE: 0.0340 - val_loss: 0.0398 - val_MSE: 0.0398\n",
      "Epoch 33/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0322 - MSE: 0.0322 - val_loss: 0.0389 - val_MSE: 0.0389\n",
      "Epoch 34/100\n",
      "1241/1241 [==============================] - 1s 990us/step - loss: 0.0321 - MSE: 0.0321 - val_loss: 0.0400 - val_MSE: 0.0400\n",
      "Epoch 35/100\n",
      "1241/1241 [==============================] - 1s 997us/step - loss: 0.0317 - MSE: 0.0317 - val_loss: 0.0436 - val_MSE: 0.0436\n",
      "Epoch 36/100\n",
      "1241/1241 [==============================] - 1s 978us/step - loss: 0.0321 - MSE: 0.0321 - val_loss: 0.0413 - val_MSE: 0.0413\n",
      "Epoch 37/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0335 - MSE: 0.0335 - val_loss: 0.0440 - val_MSE: 0.0440\n",
      "Epoch 38/100\n",
      "1241/1241 [==============================] - 1s 984us/step - loss: 0.0320 - MSE: 0.0320 - val_loss: 0.0393 - val_MSE: 0.0393\n",
      "Epoch 39/100\n",
      "1241/1241 [==============================] - 1s 989us/step - loss: 0.0316 - MSE: 0.0316 - val_loss: 0.0451 - val_MSE: 0.0451\n",
      "Epoch 40/100\n",
      "1241/1241 [==============================] - 1s 952us/step - loss: 0.0329 - MSE: 0.0329 - val_loss: 0.0389 - val_MSE: 0.0389\n",
      "Epoch 41/100\n",
      "1241/1241 [==============================] - 1s 952us/step - loss: 0.0340 - MSE: 0.0340 - val_loss: 0.0483 - val_MSE: 0.0483\n",
      "Epoch 42/100\n",
      "1241/1241 [==============================] - 1s 953us/step - loss: 0.0330 - MSE: 0.0330 - val_loss: 0.0412 - val_MSE: 0.0412\n",
      "Epoch 43/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0313 - MSE: 0.0313 - val_loss: 0.0387 - val_MSE: 0.0387\n",
      "Epoch 44/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0319 - MSE: 0.0319 - val_loss: 0.0436 - val_MSE: 0.0436\n",
      "Epoch 45/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0378 - MSE: 0.0378 - val_loss: 0.0407 - val_MSE: 0.0407\n",
      "Epoch 46/100\n",
      "1241/1241 [==============================] - 1s 987us/step - loss: 0.0339 - MSE: 0.0339 - val_loss: 0.0397 - val_MSE: 0.0397\n",
      "Epoch 47/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0318 - MSE: 0.0318 - val_loss: 0.0385 - val_MSE: 0.0385\n",
      "Epoch 48/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0310 - MSE: 0.0310 - val_loss: 0.0506 - val_MSE: 0.0506\n",
      "Epoch 49/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0353 - MSE: 0.0353 - val_loss: 0.0431 - val_MSE: 0.0431\n",
      "Epoch 50/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0335 - MSE: 0.0335 - val_loss: 0.0547 - val_MSE: 0.0547\n",
      "Epoch 51/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0351 - MSE: 0.0351 - val_loss: 0.0391 - val_MSE: 0.0391\n",
      "Epoch 52/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0312 - MSE: 0.0312 - val_loss: 0.0428 - val_MSE: 0.0428\n",
      "Epoch 53/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0327 - MSE: 0.0327 - val_loss: 0.0383 - val_MSE: 0.0383\n",
      "Epoch 54/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0326 - MSE: 0.0326 - val_loss: 0.0393 - val_MSE: 0.0393\n",
      "Epoch 55/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0317 - MSE: 0.0317 - val_loss: 0.0388 - val_MSE: 0.0388\n",
      "Epoch 56/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0317 - MSE: 0.0317 - val_loss: 0.0398 - val_MSE: 0.0398\n",
      "Epoch 57/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0318 - MSE: 0.0318 - val_loss: 0.0384 - val_MSE: 0.0384\n",
      "Epoch 58/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0312 - MSE: 0.0312 - val_loss: 0.0393 - val_MSE: 0.0393\n",
      "Epoch 59/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0323 - MSE: 0.0323 - val_loss: 0.0474 - val_MSE: 0.0474\n",
      "Epoch 60/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0351 - MSE: 0.0351 - val_loss: 0.0418 - val_MSE: 0.0418\n",
      "Epoch 61/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0332 - MSE: 0.0332 - val_loss: 0.0410 - val_MSE: 0.0410\n",
      "Epoch 62/100\n",
      "1241/1241 [==============================] - 1s 978us/step - loss: 0.0334 - MSE: 0.0334 - val_loss: 0.0387 - val_MSE: 0.0387\n",
      "Epoch 63/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0309 - MSE: 0.0309 - val_loss: 0.0387 - val_MSE: 0.0387\n",
      "QWK, Prompt 4, Fold 1: 0.760618641361376\n",
      "Fold 2\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1772, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1241 samples, validate on 266 samples\n",
      "Epoch 1/100\n",
      "1241/1241 [==============================] - 8s 6ms/step - loss: 0.0519 - MSE: 0.0519 - val_loss: 0.0686 - val_MSE: 0.0686\n",
      "Epoch 2/100\n",
      "1241/1241 [==============================] - 1s 920us/step - loss: 0.0507 - MSE: 0.0507 - val_loss: 0.0459 - val_MSE: 0.0459\n",
      "Epoch 3/100\n",
      "1241/1241 [==============================] - 1s 947us/step - loss: 0.0367 - MSE: 0.0367 - val_loss: 0.0509 - val_MSE: 0.0509\n",
      "Epoch 4/100\n",
      "1241/1241 [==============================] - 1s 930us/step - loss: 0.0346 - MSE: 0.0346 - val_loss: 0.0431 - val_MSE: 0.0431\n",
      "Epoch 5/100\n",
      "1241/1241 [==============================] - ETA: 0s - loss: 0.0344 - MSE: 0.034 - 1s 932us/step - loss: 0.0349 - MSE: 0.0349 - val_loss: 0.0431 - val_MSE: 0.0431\n",
      "Epoch 6/100\n",
      "1241/1241 [==============================] - 1s 928us/step - loss: 0.0374 - MSE: 0.0374 - val_loss: 0.0440 - val_MSE: 0.0440\n",
      "Epoch 7/100\n",
      "1241/1241 [==============================] - 1s 928us/step - loss: 0.0409 - MSE: 0.0409 - val_loss: 0.0451 - val_MSE: 0.0451\n",
      "Epoch 8/100\n",
      "1241/1241 [==============================] - 1s 951us/step - loss: 0.0333 - MSE: 0.0333 - val_loss: 0.0429 - val_MSE: 0.0429\n",
      "Epoch 9/100\n",
      "1241/1241 [==============================] - 1s 908us/step - loss: 0.0348 - MSE: 0.0348 - val_loss: 0.0434 - val_MSE: 0.0434\n",
      "Epoch 10/100\n",
      "1241/1241 [==============================] - 1s 924us/step - loss: 0.0326 - MSE: 0.0326 - val_loss: 0.0427 - val_MSE: 0.0427\n",
      "Epoch 11/100\n",
      "1241/1241 [==============================] - 1s 940us/step - loss: 0.0322 - MSE: 0.0322 - val_loss: 0.0475 - val_MSE: 0.0475\n",
      "Epoch 12/100\n",
      "1241/1241 [==============================] - 1s 943us/step - loss: 0.0326 - MSE: 0.0326 - val_loss: 0.0427 - val_MSE: 0.0427\n",
      "Epoch 13/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0352 - MSE: 0.0352 - val_loss: 0.0612 - val_MSE: 0.0612\n",
      "Epoch 14/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0349 - MSE: 0.0349 - val_loss: 0.0703 - val_MSE: 0.0703\n",
      "Epoch 15/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0397 - MSE: 0.0397 - val_loss: 0.0555 - val_MSE: 0.0555\n",
      "Epoch 16/100\n",
      "1241/1241 [==============================] - 1s 926us/step - loss: 0.0345 - MSE: 0.0345 - val_loss: 0.0442 - val_MSE: 0.0442\n",
      "Epoch 17/100\n",
      "1241/1241 [==============================] - 1s 927us/step - loss: 0.0316 - MSE: 0.0316 - val_loss: 0.0462 - val_MSE: 0.0462\n",
      "Epoch 18/100\n",
      "1241/1241 [==============================] - 1s 965us/step - loss: 0.0316 - MSE: 0.0316 - val_loss: 0.0465 - val_MSE: 0.0465\n",
      "Epoch 19/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0310 - MSE: 0.0310 - val_loss: 0.0512 - val_MSE: 0.0512\n",
      "Epoch 20/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0330 - MSE: 0.0330 - val_loss: 0.0467 - val_MSE: 0.0467\n",
      "Epoch 21/100\n",
      "1241/1241 [==============================] - 1s 933us/step - loss: 0.0313 - MSE: 0.0313 - val_loss: 0.0439 - val_MSE: 0.0439\n",
      "Epoch 22/100\n",
      "1241/1241 [==============================] - 1s 948us/step - loss: 0.0311 - MSE: 0.0311 - val_loss: 0.0499 - val_MSE: 0.0499\n",
      "QWK, Prompt 4, Fold 2: 0.7842762070209891\n",
      "Fold 3\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1772, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1241 samples, validate on 266 samples\n",
      "Epoch 1/100\n",
      "1241/1241 [==============================] - 8s 7ms/step - loss: 0.0552 - MSE: 0.0552 - val_loss: 0.0362 - val_MSE: 0.0362\n",
      "Epoch 2/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0407 - MSE: 0.0407 - val_loss: 0.0411 - val_MSE: 0.0411\n",
      "Epoch 3/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0369 - MSE: 0.0369 - val_loss: 0.0343 - val_MSE: 0.0343\n",
      "Epoch 4/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0385 - MSE: 0.0385 - val_loss: 0.0344 - val_MSE: 0.0344\n",
      "Epoch 5/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0362 - MSE: 0.0362 - val_loss: 0.0571 - val_MSE: 0.0571\n",
      "Epoch 6/100\n",
      "1241/1241 [==============================] - 1s 974us/step - loss: 0.0379 - MSE: 0.0379 - val_loss: 0.0357 - val_MSE: 0.0357\n",
      "Epoch 7/100\n",
      "1241/1241 [==============================] - 1s 932us/step - loss: 0.0355 - MSE: 0.0355 - val_loss: 0.0625 - val_MSE: 0.0625\n",
      "Epoch 8/100\n",
      "1241/1241 [==============================] - 1s 929us/step - loss: 0.0404 - MSE: 0.0404 - val_loss: 0.0349 - val_MSE: 0.0349\n",
      "Epoch 9/100\n",
      "1241/1241 [==============================] - 1s 921us/step - loss: 0.0339 - MSE: 0.0339 - val_loss: 0.0451 - val_MSE: 0.0451\n",
      "Epoch 10/100\n",
      "1241/1241 [==============================] - 1s 932us/step - loss: 0.0364 - MSE: 0.0364 - val_loss: 0.0341 - val_MSE: 0.0341\n",
      "Epoch 11/100\n",
      "1241/1241 [==============================] - 1s 923us/step - loss: 0.0330 - MSE: 0.0330 - val_loss: 0.0352 - val_MSE: 0.0352\n",
      "Epoch 12/100\n",
      "1241/1241 [==============================] - 1s 920us/step - loss: 0.0345 - MSE: 0.0345 - val_loss: 0.0356 - val_MSE: 0.0356\n",
      "Epoch 13/100\n",
      "1241/1241 [==============================] - 1s 929us/step - loss: 0.0330 - MSE: 0.0330 - val_loss: 0.0365 - val_MSE: 0.0365\n",
      "Epoch 14/100\n",
      "1241/1241 [==============================] - 1s 948us/step - loss: 0.0339 - MSE: 0.0339 - val_loss: 0.0337 - val_MSE: 0.0337\n",
      "Epoch 15/100\n",
      "1241/1241 [==============================] - 1s 979us/step - loss: 0.0346 - MSE: 0.0346 - val_loss: 0.0364 - val_MSE: 0.0364\n",
      "Epoch 16/100\n",
      "1241/1241 [==============================] - 1s 961us/step - loss: 0.0364 - MSE: 0.0364 - val_loss: 0.0339 - val_MSE: 0.0339\n",
      "Epoch 17/100\n",
      "1241/1241 [==============================] - 1s 930us/step - loss: 0.0328 - MSE: 0.0328 - val_loss: 0.0393 - val_MSE: 0.0393\n",
      "Epoch 18/100\n",
      "1241/1241 [==============================] - 1s 944us/step - loss: 0.0331 - MSE: 0.0331 - val_loss: 0.0357 - val_MSE: 0.0357\n",
      "Epoch 19/100\n",
      "1241/1241 [==============================] - 1s 922us/step - loss: 0.0327 - MSE: 0.0327 - val_loss: 0.0388 - val_MSE: 0.0388\n",
      "Epoch 20/100\n",
      "1241/1241 [==============================] - 1s 924us/step - loss: 0.0326 - MSE: 0.0326 - val_loss: 0.0430 - val_MSE: 0.0430\n",
      "Epoch 21/100\n",
      "1241/1241 [==============================] - 1s 922us/step - loss: 0.0354 - MSE: 0.0354 - val_loss: 0.0362 - val_MSE: 0.0362\n",
      "Epoch 22/100\n",
      "1241/1241 [==============================] - 1s 924us/step - loss: 0.0354 - MSE: 0.0354 - val_loss: 0.0346 - val_MSE: 0.0346\n",
      "Epoch 23/100\n",
      "1241/1241 [==============================] - 1s 935us/step - loss: 0.0324 - MSE: 0.0324 - val_loss: 0.0341 - val_MSE: 0.0341\n",
      "Epoch 24/100\n",
      "1241/1241 [==============================] - 1s 929us/step - loss: 0.0320 - MSE: 0.0320 - val_loss: 0.0357 - val_MSE: 0.0357\n",
      "QWK, Prompt 4, Fold 3: 0.7313095248411949\n",
      "Fold 4\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1772, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1241 samples, validate on 266 samples\n",
      "Epoch 1/100\n",
      "1241/1241 [==============================] - 8s 6ms/step - loss: 0.0499 - MSE: 0.0499 - val_loss: 0.0443 - val_MSE: 0.0443\n",
      "Epoch 2/100\n",
      "1241/1241 [==============================] - 1s 904us/step - loss: 0.0396 - MSE: 0.0396 - val_loss: 0.0346 - val_MSE: 0.0346\n",
      "Epoch 3/100\n",
      "1241/1241 [==============================] - 1s 857us/step - loss: 0.0359 - MSE: 0.0359 - val_loss: 0.0720 - val_MSE: 0.0720\n",
      "Epoch 4/100\n",
      "1241/1241 [==============================] - 1s 864us/step - loss: 0.0420 - MSE: 0.0420 - val_loss: 0.0344 - val_MSE: 0.0344\n",
      "Epoch 5/100\n",
      "1241/1241 [==============================] - 1s 912us/step - loss: 0.0355 - MSE: 0.0355 - val_loss: 0.0350 - val_MSE: 0.0350\n",
      "Epoch 6/100\n",
      "1241/1241 [==============================] - 1s 860us/step - loss: 0.0356 - MSE: 0.0356 - val_loss: 0.0385 - val_MSE: 0.0385\n",
      "Epoch 7/100\n",
      "1241/1241 [==============================] - 1s 863us/step - loss: 0.0360 - MSE: 0.0360 - val_loss: 0.0343 - val_MSE: 0.0343\n",
      "Epoch 8/100\n",
      "1241/1241 [==============================] - 1s 885us/step - loss: 0.0337 - MSE: 0.0337 - val_loss: 0.0349 - val_MSE: 0.0349\n",
      "Epoch 9/100\n",
      "1241/1241 [==============================] - 1s 947us/step - loss: 0.0338 - MSE: 0.0338 - val_loss: 0.0346 - val_MSE: 0.0346\n",
      "Epoch 10/100\n",
      "1241/1241 [==============================] - 1s 907us/step - loss: 0.0348 - MSE: 0.0348 - val_loss: 0.0342 - val_MSE: 0.0342\n",
      "Epoch 11/100\n",
      "1241/1241 [==============================] - 1s 929us/step - loss: 0.0350 - MSE: 0.0350 - val_loss: 0.0339 - val_MSE: 0.0339\n",
      "Epoch 12/100\n",
      "1241/1241 [==============================] - 1s 916us/step - loss: 0.0347 - MSE: 0.0347 - val_loss: 0.0345 - val_MSE: 0.0345\n",
      "Epoch 13/100\n",
      "1241/1241 [==============================] - 1s 979us/step - loss: 0.0331 - MSE: 0.0331 - val_loss: 0.0339 - val_MSE: 0.0339\n",
      "Epoch 14/100\n",
      "1241/1241 [==============================] - 1s 982us/step - loss: 0.0345 - MSE: 0.0345 - val_loss: 0.0371 - val_MSE: 0.0371\n",
      "Epoch 15/100\n",
      "1241/1241 [==============================] - 1s 974us/step - loss: 0.0328 - MSE: 0.0328 - val_loss: 0.0497 - val_MSE: 0.0497\n",
      "Epoch 16/100\n",
      "1241/1241 [==============================] - 1s 988us/step - loss: 0.0371 - MSE: 0.0371 - val_loss: 0.0394 - val_MSE: 0.0394\n",
      "Epoch 17/100\n",
      "1241/1241 [==============================] - 1s 998us/step - loss: 0.0358 - MSE: 0.0358 - val_loss: 0.0371 - val_MSE: 0.0371\n",
      "Epoch 18/100\n",
      "1241/1241 [==============================] - 1s 966us/step - loss: 0.0346 - MSE: 0.0346 - val_loss: 0.0341 - val_MSE: 0.0341\n",
      "Epoch 19/100\n",
      "1241/1241 [==============================] - 1s 1ms/step - loss: 0.0334 - MSE: 0.0334 - val_loss: 0.0378 - val_MSE: 0.0378\n",
      "Epoch 20/100\n",
      "1241/1241 [==============================] - 1s 958us/step - loss: 0.0318 - MSE: 0.0318 - val_loss: 0.0355 - val_MSE: 0.0355\n",
      "Epoch 21/100\n",
      "1241/1241 [==============================] - 1s 877us/step - loss: 0.0322 - MSE: 0.0322 - val_loss: 0.0340 - val_MSE: 0.0340\n",
      "QWK, Prompt 4, Fold 4: 0.7623955688512365\n",
      "Fold 5\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1772, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1241 samples, validate on 266 samples\n",
      "Epoch 1/100\n",
      "1241/1241 [==============================] - 7s 6ms/step - loss: 0.0527 - MSE: 0.0527 - val_loss: 0.0426 - val_MSE: 0.0426\n",
      "Epoch 2/100\n",
      "1241/1241 [==============================] - 1s 803us/step - loss: 0.0391 - MSE: 0.0391 - val_loss: 0.0434 - val_MSE: 0.0434\n",
      "Epoch 3/100\n",
      "1241/1241 [==============================] - 1s 817us/step - loss: 0.0359 - MSE: 0.0359 - val_loss: 0.0600 - val_MSE: 0.0600\n",
      "Epoch 4/100\n",
      "1241/1241 [==============================] - 1s 832us/step - loss: 0.0366 - MSE: 0.0366 - val_loss: 0.0366 - val_MSE: 0.0366\n",
      "Epoch 5/100\n",
      "1241/1241 [==============================] - 1s 817us/step - loss: 0.0349 - MSE: 0.0349 - val_loss: 0.0513 - val_MSE: 0.0513\n",
      "Epoch 6/100\n",
      "1241/1241 [==============================] - 1s 795us/step - loss: 0.0352 - MSE: 0.0352 - val_loss: 0.0392 - val_MSE: 0.0392\n",
      "Epoch 7/100\n",
      "1241/1241 [==============================] - 1s 809us/step - loss: 0.0354 - MSE: 0.0354 - val_loss: 0.0375 - val_MSE: 0.0375\n",
      "Epoch 8/100\n",
      "1241/1241 [==============================] - 1s 785us/step - loss: 0.0330 - MSE: 0.0330 - val_loss: 0.0420 - val_MSE: 0.0420\n",
      "Epoch 9/100\n",
      "1241/1241 [==============================] - 1s 786us/step - loss: 0.0367 - MSE: 0.0367 - val_loss: 0.0454 - val_MSE: 0.0454\n",
      "Epoch 10/100\n",
      "1241/1241 [==============================] - 1s 787us/step - loss: 0.0361 - MSE: 0.0361 - val_loss: 0.0384 - val_MSE: 0.0384\n",
      "Epoch 11/100\n",
      "1241/1241 [==============================] - 1s 773us/step - loss: 0.0319 - MSE: 0.0319 - val_loss: 0.0420 - val_MSE: 0.0420\n",
      "Epoch 12/100\n",
      "1241/1241 [==============================] - 1s 781us/step - loss: 0.0365 - MSE: 0.0365 - val_loss: 0.0385 - val_MSE: 0.0385\n",
      "Epoch 13/100\n",
      "1241/1241 [==============================] - 1s 784us/step - loss: 0.0317 - MSE: 0.0317 - val_loss: 0.0373 - val_MSE: 0.0373\n",
      "Epoch 14/100\n",
      "1241/1241 [==============================] - 1s 783us/step - loss: 0.0327 - MSE: 0.0327 - val_loss: 0.0371 - val_MSE: 0.0371\n",
      "QWK, Prompt 4, Fold 5: 0.7358825388336534\n",
      "Prompt: 5\n",
      "Fold 1\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1805, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1264 samples, validate on 271 samples\n",
      "Epoch 1/100\n",
      "1264/1264 [==============================] - 7s 6ms/step - loss: 0.0381 - MSE: 0.0381 - val_loss: 0.0220 - val_MSE: 0.0220\n",
      "Epoch 2/100\n",
      "1264/1264 [==============================] - 1s 809us/step - loss: 0.0247 - MSE: 0.0247 - val_loss: 0.0280 - val_MSE: 0.0280\n",
      "Epoch 3/100\n",
      "1264/1264 [==============================] - 1s 776us/step - loss: 0.0248 - MSE: 0.0248 - val_loss: 0.0297 - val_MSE: 0.0297\n",
      "Epoch 4/100\n",
      "1264/1264 [==============================] - 1s 796us/step - loss: 0.0267 - MSE: 0.0267 - val_loss: 0.0242 - val_MSE: 0.0242\n",
      "Epoch 5/100\n",
      "1264/1264 [==============================] - 1s 793us/step - loss: 0.0247 - MSE: 0.0247 - val_loss: 0.0211 - val_MSE: 0.0211\n",
      "Epoch 6/100\n",
      "1264/1264 [==============================] - 1s 795us/step - loss: 0.0235 - MSE: 0.0235 - val_loss: 0.0221 - val_MSE: 0.0221\n",
      "Epoch 7/100\n",
      "1264/1264 [==============================] - 1s 795us/step - loss: 0.0225 - MSE: 0.0225 - val_loss: 0.0210 - val_MSE: 0.0210\n",
      "Epoch 8/100\n",
      "1264/1264 [==============================] - 1s 785us/step - loss: 0.0238 - MSE: 0.0238 - val_loss: 0.0224 - val_MSE: 0.0224\n",
      "Epoch 9/100\n",
      "1264/1264 [==============================] - 1s 786us/step - loss: 0.0229 - MSE: 0.0229 - val_loss: 0.0215 - val_MSE: 0.0215\n",
      "Epoch 10/100\n",
      "1264/1264 [==============================] - 1s 852us/step - loss: 0.0227 - MSE: 0.0227 - val_loss: 0.0211 - val_MSE: 0.0211\n",
      "Epoch 11/100\n",
      "1264/1264 [==============================] - 1s 830us/step - loss: 0.0220 - MSE: 0.0220 - val_loss: 0.0234 - val_MSE: 0.0234\n",
      "Epoch 12/100\n",
      "1264/1264 [==============================] - 1s 813us/step - loss: 0.0232 - MSE: 0.0232 - val_loss: 0.0266 - val_MSE: 0.0266\n",
      "Epoch 13/100\n",
      "1264/1264 [==============================] - 1s 850us/step - loss: 0.0227 - MSE: 0.0227 - val_loss: 0.0253 - val_MSE: 0.0253\n",
      "Epoch 14/100\n",
      "1264/1264 [==============================] - 1s 818us/step - loss: 0.0225 - MSE: 0.0225 - val_loss: 0.0218 - val_MSE: 0.0218\n",
      "Epoch 15/100\n",
      "1264/1264 [==============================] - 1s 889us/step - loss: 0.0220 - MSE: 0.0220 - val_loss: 0.0213 - val_MSE: 0.0213\n",
      "Epoch 16/100\n",
      "1264/1264 [==============================] - 1s 801us/step - loss: 0.0216 - MSE: 0.0216 - val_loss: 0.0223 - val_MSE: 0.0223\n",
      "Epoch 17/100\n",
      "1264/1264 [==============================] - 1s 803us/step - loss: 0.0221 - MSE: 0.0221 - val_loss: 0.0214 - val_MSE: 0.0214\n",
      "QWK, Prompt 5, Fold 1: 0.7306055415261271\n",
      "Fold 2\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1805, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1264 samples, validate on 271 samples\n",
      "Epoch 1/100\n",
      "1264/1264 [==============================] - 7s 6ms/step - loss: 0.0443 - MSE: 0.0443 - val_loss: 0.0296 - val_MSE: 0.0296\n",
      "Epoch 2/100\n",
      "1264/1264 [==============================] - 1s 852us/step - loss: 0.0256 - MSE: 0.0256 - val_loss: 0.0401 - val_MSE: 0.0401\n",
      "Epoch 3/100\n",
      "1264/1264 [==============================] - 1s 830us/step - loss: 0.0266 - MSE: 0.0266 - val_loss: 0.0234 - val_MSE: 0.0234\n",
      "Epoch 4/100\n",
      "1264/1264 [==============================] - 1s 813us/step - loss: 0.0231 - MSE: 0.0231 - val_loss: 0.0216 - val_MSE: 0.0216\n",
      "Epoch 5/100\n",
      "1264/1264 [==============================] - 1s 799us/step - loss: 0.0270 - MSE: 0.0270 - val_loss: 0.0257 - val_MSE: 0.0257\n",
      "Epoch 6/100\n",
      "1264/1264 [==============================] - 1s 797us/step - loss: 0.0249 - MSE: 0.0249 - val_loss: 0.0336 - val_MSE: 0.0336\n",
      "Epoch 7/100\n",
      "1264/1264 [==============================] - 1s 800us/step - loss: 0.0247 - MSE: 0.0247 - val_loss: 0.0220 - val_MSE: 0.0220\n",
      "Epoch 8/100\n",
      "1264/1264 [==============================] - 1s 789us/step - loss: 0.0242 - MSE: 0.0242 - val_loss: 0.0215 - val_MSE: 0.0215\n",
      "Epoch 9/100\n",
      "1264/1264 [==============================] - 1s 802us/step - loss: 0.0255 - MSE: 0.0255 - val_loss: 0.0218 - val_MSE: 0.0218\n",
      "Epoch 10/100\n",
      "1264/1264 [==============================] - 1s 791us/step - loss: 0.0231 - MSE: 0.0231 - val_loss: 0.0219 - val_MSE: 0.0219\n",
      "Epoch 11/100\n",
      "1264/1264 [==============================] - 1s 789us/step - loss: 0.0222 - MSE: 0.0222 - val_loss: 0.0212 - val_MSE: 0.0212\n",
      "Epoch 12/100\n",
      "1264/1264 [==============================] - 1s 809us/step - loss: 0.0239 - MSE: 0.0239 - val_loss: 0.0222 - val_MSE: 0.0222\n",
      "Epoch 13/100\n",
      "1264/1264 [==============================] - 1s 802us/step - loss: 0.0223 - MSE: 0.0223 - val_loss: 0.0216 - val_MSE: 0.0216\n",
      "Epoch 14/100\n",
      "1264/1264 [==============================] - 1s 800us/step - loss: 0.0217 - MSE: 0.0217 - val_loss: 0.0241 - val_MSE: 0.0241\n",
      "Epoch 15/100\n",
      "1264/1264 [==============================] - 1s 812us/step - loss: 0.0235 - MSE: 0.0235 - val_loss: 0.0217 - val_MSE: 0.0217\n",
      "Epoch 16/100\n",
      "1264/1264 [==============================] - 1s 807us/step - loss: 0.0215 - MSE: 0.0215 - val_loss: 0.0215 - val_MSE: 0.0215\n",
      "Epoch 17/100\n",
      "1264/1264 [==============================] - 1s 794us/step - loss: 0.0222 - MSE: 0.0222 - val_loss: 0.0213 - val_MSE: 0.0213\n",
      "Epoch 18/100\n",
      "1264/1264 [==============================] - 1s 834us/step - loss: 0.0212 - MSE: 0.0212 - val_loss: 0.0226 - val_MSE: 0.0226\n",
      "Epoch 19/100\n",
      "1264/1264 [==============================] - 1s 858us/step - loss: 0.0217 - MSE: 0.0217 - val_loss: 0.0214 - val_MSE: 0.0214\n",
      "Epoch 20/100\n",
      "1264/1264 [==============================] - 1s 819us/step - loss: 0.0209 - MSE: 0.0209 - val_loss: 0.0231 - val_MSE: 0.0231\n",
      "Epoch 21/100\n",
      "1264/1264 [==============================] - 1s 836us/step - loss: 0.0222 - MSE: 0.0222 - val_loss: 0.0220 - val_MSE: 0.0220\n",
      "QWK, Prompt 5, Fold 2: 0.7573423206547906\n",
      "Fold 3\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1805, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1264 samples, validate on 271 samples\n",
      "Epoch 1/100\n",
      "1264/1264 [==============================] - 8s 6ms/step - loss: 0.0359 - MSE: 0.0359 - val_loss: 0.0359 - val_MSE: 0.0359\n",
      "Epoch 2/100\n",
      "1264/1264 [==============================] - 1s 880us/step - loss: 0.0237 - MSE: 0.0237 - val_loss: 0.0239 - val_MSE: 0.0239\n",
      "Epoch 3/100\n",
      "1264/1264 [==============================] - 1s 821us/step - loss: 0.0233 - MSE: 0.0233 - val_loss: 0.0448 - val_MSE: 0.0448\n",
      "Epoch 4/100\n",
      "1264/1264 [==============================] - 1s 799us/step - loss: 0.0248 - MSE: 0.0248 - val_loss: 0.0417 - val_MSE: 0.0417\n",
      "Epoch 5/100\n",
      "1264/1264 [==============================] - 1s 790us/step - loss: 0.0239 - MSE: 0.0239 - val_loss: 0.0264 - val_MSE: 0.0264\n",
      "Epoch 6/100\n",
      "1264/1264 [==============================] - 1s 792us/step - loss: 0.0231 - MSE: 0.0231 - val_loss: 0.0292 - val_MSE: 0.0292\n",
      "Epoch 7/100\n",
      "1264/1264 [==============================] - 1s 779us/step - loss: 0.0242 - MSE: 0.0242 - val_loss: 0.0288 - val_MSE: 0.0288\n",
      "Epoch 8/100\n",
      "1264/1264 [==============================] - 1s 792us/step - loss: 0.0276 - MSE: 0.0276 - val_loss: 0.0238 - val_MSE: 0.0238\n",
      "Epoch 9/100\n",
      "1264/1264 [==============================] - 1s 784us/step - loss: 0.0218 - MSE: 0.0218 - val_loss: 0.0239 - val_MSE: 0.0239\n",
      "Epoch 10/100\n",
      "1264/1264 [==============================] - 1s 788us/step - loss: 0.0221 - MSE: 0.0221 - val_loss: 0.0239 - val_MSE: 0.0239\n",
      "Epoch 11/100\n",
      "1264/1264 [==============================] - 1s 839us/step - loss: 0.0215 - MSE: 0.0215 - val_loss: 0.0240 - val_MSE: 0.0240\n",
      "Epoch 12/100\n",
      "1264/1264 [==============================] - 1s 826us/step - loss: 0.0213 - MSE: 0.0213 - val_loss: 0.0253 - val_MSE: 0.0253\n",
      "Epoch 13/100\n",
      "1264/1264 [==============================] - 1s 839us/step - loss: 0.0216 - MSE: 0.0216 - val_loss: 0.0239 - val_MSE: 0.0239\n",
      "Epoch 14/100\n",
      "1264/1264 [==============================] - 1s 777us/step - loss: 0.0216 - MSE: 0.0216 - val_loss: 0.0243 - val_MSE: 0.0243\n",
      "Epoch 15/100\n",
      "1264/1264 [==============================] - 1s 795us/step - loss: 0.0215 - MSE: 0.0215 - val_loss: 0.0241 - val_MSE: 0.0241\n",
      "Epoch 16/100\n",
      "1264/1264 [==============================] - 1s 820us/step - loss: 0.0214 - MSE: 0.0214 - val_loss: 0.0282 - val_MSE: 0.0282\n",
      "Epoch 17/100\n",
      "1264/1264 [==============================] - 1s 865us/step - loss: 0.0219 - MSE: 0.0219 - val_loss: 0.0245 - val_MSE: 0.0245\n",
      "Epoch 18/100\n",
      "1264/1264 [==============================] - 1s 807us/step - loss: 0.0207 - MSE: 0.0207 - val_loss: 0.0256 - val_MSE: 0.0256\n",
      "QWK, Prompt 5, Fold 3: 0.6716833497814747\n",
      "Fold 4\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1805, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1264 samples, validate on 271 samples\n",
      "Epoch 1/100\n",
      "1264/1264 [==============================] - 8s 6ms/step - loss: 0.0379 - MSE: 0.0379 - val_loss: 0.0275 - val_MSE: 0.0275\n",
      "Epoch 2/100\n",
      "1264/1264 [==============================] - 1s 857us/step - loss: 0.0227 - MSE: 0.0227 - val_loss: 0.0276 - val_MSE: 0.0276\n",
      "Epoch 3/100\n",
      "1264/1264 [==============================] - 1s 829us/step - loss: 0.0233 - MSE: 0.0233 - val_loss: 0.0269 - val_MSE: 0.0269\n",
      "Epoch 4/100\n",
      "1264/1264 [==============================] - 1s 821us/step - loss: 0.0223 - MSE: 0.0223 - val_loss: 0.0317 - val_MSE: 0.0317\n",
      "Epoch 5/100\n",
      "1264/1264 [==============================] - 1s 810us/step - loss: 0.0236 - MSE: 0.0236 - val_loss: 0.0289 - val_MSE: 0.0289\n",
      "Epoch 6/100\n",
      "1264/1264 [==============================] - 1s 814us/step - loss: 0.0224 - MSE: 0.0224 - val_loss: 0.0327 - val_MSE: 0.0327\n",
      "Epoch 7/100\n",
      "1264/1264 [==============================] - 1s 804us/step - loss: 0.0213 - MSE: 0.0213 - val_loss: 0.0371 - val_MSE: 0.0371\n",
      "Epoch 8/100\n",
      "1264/1264 [==============================] - 1s 826us/step - loss: 0.0217 - MSE: 0.0217 - val_loss: 0.0278 - val_MSE: 0.0278\n",
      "Epoch 9/100\n",
      "1264/1264 [==============================] - 1s 793us/step - loss: 0.0208 - MSE: 0.0208 - val_loss: 0.0275 - val_MSE: 0.0275\n",
      "Epoch 10/100\n",
      "1264/1264 [==============================] - 1s 830us/step - loss: 0.0222 - MSE: 0.0222 - val_loss: 0.0306 - val_MSE: 0.0306\n",
      "Epoch 11/100\n",
      "1264/1264 [==============================] - 1s 818us/step - loss: 0.0225 - MSE: 0.0225 - val_loss: 0.0279 - val_MSE: 0.0279\n",
      "Epoch 12/100\n",
      "1264/1264 [==============================] - 1s 827us/step - loss: 0.0228 - MSE: 0.0228 - val_loss: 0.0275 - val_MSE: 0.0275\n",
      "Epoch 13/100\n",
      "1264/1264 [==============================] - 1s 824us/step - loss: 0.0201 - MSE: 0.0201 - val_loss: 0.0338 - val_MSE: 0.0338\n",
      "QWK, Prompt 5, Fold 4: 0.6857865879375791\n",
      "Fold 5\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1805, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1264 samples, validate on 271 samples\n",
      "Epoch 1/100\n",
      "1264/1264 [==============================] - 8s 6ms/step - loss: 0.0336 - MSE: 0.0336 - val_loss: 0.0482 - val_MSE: 0.0482\n",
      "Epoch 2/100\n",
      "1264/1264 [==============================] - 1s 926us/step - loss: 0.0282 - MSE: 0.0282 - val_loss: 0.0250 - val_MSE: 0.0250\n",
      "Epoch 3/100\n",
      "1264/1264 [==============================] - 1s 834us/step - loss: 0.0245 - MSE: 0.0245 - val_loss: 0.0388 - val_MSE: 0.0388\n",
      "Epoch 4/100\n",
      "1264/1264 [==============================] - 1s 828us/step - loss: 0.0258 - MSE: 0.0258 - val_loss: 0.0231 - val_MSE: 0.0231\n",
      "Epoch 5/100\n",
      "1264/1264 [==============================] - 1s 827us/step - loss: 0.0238 - MSE: 0.0238 - val_loss: 0.0230 - val_MSE: 0.0230\n",
      "Epoch 6/100\n",
      "1264/1264 [==============================] - 1s 808us/step - loss: 0.0239 - MSE: 0.0239 - val_loss: 0.0355 - val_MSE: 0.0355\n",
      "Epoch 7/100\n",
      "1264/1264 [==============================] - 1s 869us/step - loss: 0.0257 - MSE: 0.0257 - val_loss: 0.0234 - val_MSE: 0.0234\n",
      "Epoch 8/100\n",
      "1264/1264 [==============================] - 1s 890us/step - loss: 0.0233 - MSE: 0.0233 - val_loss: 0.0228 - val_MSE: 0.0228\n",
      "Epoch 9/100\n",
      "1264/1264 [==============================] - 1s 841us/step - loss: 0.0232 - MSE: 0.0232 - val_loss: 0.0374 - val_MSE: 0.0374\n",
      "Epoch 10/100\n",
      "1264/1264 [==============================] - 1s 802us/step - loss: 0.0257 - MSE: 0.0257 - val_loss: 0.0231 - val_MSE: 0.0231\n",
      "Epoch 11/100\n",
      "1264/1264 [==============================] - 1s 824us/step - loss: 0.0226 - MSE: 0.0226 - val_loss: 0.0219 - val_MSE: 0.0219\n",
      "Epoch 12/100\n",
      "1264/1264 [==============================] - 1s 817us/step - loss: 0.0219 - MSE: 0.0219 - val_loss: 0.0265 - val_MSE: 0.0265\n",
      "Epoch 13/100\n",
      "1264/1264 [==============================] - 1s 823us/step - loss: 0.0231 - MSE: 0.0231 - val_loss: 0.0218 - val_MSE: 0.0218\n",
      "Epoch 14/100\n",
      "1264/1264 [==============================] - 1s 808us/step - loss: 0.0223 - MSE: 0.0223 - val_loss: 0.0230 - val_MSE: 0.0230\n",
      "Epoch 15/100\n",
      "1264/1264 [==============================] - 1s 803us/step - loss: 0.0222 - MSE: 0.0222 - val_loss: 0.0215 - val_MSE: 0.0215\n",
      "Epoch 16/100\n",
      "1264/1264 [==============================] - 1s 803us/step - loss: 0.0222 - MSE: 0.0222 - val_loss: 0.0239 - val_MSE: 0.0239\n",
      "Epoch 17/100\n",
      "1264/1264 [==============================] - 1s 793us/step - loss: 0.0217 - MSE: 0.0217 - val_loss: 0.0216 - val_MSE: 0.0216\n",
      "Epoch 18/100\n",
      "1264/1264 [==============================] - 1s 817us/step - loss: 0.0226 - MSE: 0.0226 - val_loss: 0.0216 - val_MSE: 0.0216\n",
      "Epoch 19/100\n",
      "1264/1264 [==============================] - 1s 808us/step - loss: 0.0223 - MSE: 0.0223 - val_loss: 0.0221 - val_MSE: 0.0221\n",
      "Epoch 20/100\n",
      "1264/1264 [==============================] - 1s 798us/step - loss: 0.0226 - MSE: 0.0226 - val_loss: 0.0218 - val_MSE: 0.0218\n",
      "Epoch 21/100\n",
      "1264/1264 [==============================] - 1s 802us/step - loss: 0.0221 - MSE: 0.0221 - val_loss: 0.0213 - val_MSE: 0.0213\n",
      "Epoch 22/100\n",
      "1264/1264 [==============================] - 1s 870us/step - loss: 0.0216 - MSE: 0.0216 - val_loss: 0.0216 - val_MSE: 0.0216\n",
      "Epoch 23/100\n",
      "1264/1264 [==============================] - 1s 834us/step - loss: 0.0228 - MSE: 0.0228 - val_loss: 0.0260 - val_MSE: 0.0260\n",
      "Epoch 24/100\n",
      "1264/1264 [==============================] - 1s 817us/step - loss: 0.0224 - MSE: 0.0224 - val_loss: 0.0213 - val_MSE: 0.0213\n",
      "Epoch 25/100\n",
      "1264/1264 [==============================] - 1s 830us/step - loss: 0.0215 - MSE: 0.0215 - val_loss: 0.0250 - val_MSE: 0.0250\n",
      "Epoch 26/100\n",
      "1264/1264 [==============================] - 1s 839us/step - loss: 0.0221 - MSE: 0.0221 - val_loss: 0.0232 - val_MSE: 0.0232\n",
      "Epoch 27/100\n",
      "1264/1264 [==============================] - 1s 848us/step - loss: 0.0222 - MSE: 0.0222 - val_loss: 0.0216 - val_MSE: 0.0216\n",
      "Epoch 28/100\n",
      "1264/1264 [==============================] - 1s 839us/step - loss: 0.0216 - MSE: 0.0216 - val_loss: 0.0237 - val_MSE: 0.0237\n",
      "Epoch 29/100\n",
      "1264/1264 [==============================] - 1s 830us/step - loss: 0.0223 - MSE: 0.0223 - val_loss: 0.0240 - val_MSE: 0.0240\n",
      "Epoch 30/100\n",
      "1264/1264 [==============================] - 1s 832us/step - loss: 0.0214 - MSE: 0.0214 - val_loss: 0.0217 - val_MSE: 0.0217\n",
      "Epoch 31/100\n",
      "1264/1264 [==============================] - 1s 838us/step - loss: 0.0217 - MSE: 0.0217 - val_loss: 0.0215 - val_MSE: 0.0215\n",
      "Epoch 32/100\n",
      "1264/1264 [==============================] - 1s 892us/step - loss: 0.0214 - MSE: 0.0214 - val_loss: 0.0248 - val_MSE: 0.0248\n",
      "Epoch 33/100\n",
      "1264/1264 [==============================] - 1s 875us/step - loss: 0.0222 - MSE: 0.0222 - val_loss: 0.0214 - val_MSE: 0.0214\n",
      "Epoch 34/100\n",
      "1264/1264 [==============================] - 1s 831us/step - loss: 0.0212 - MSE: 0.0212 - val_loss: 0.0216 - val_MSE: 0.0216\n",
      "QWK, Prompt 5, Fold 5: 0.7787944259965489\n",
      "Prompt: 6\n",
      "Fold 1\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1800, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1260 samples, validate on 270 samples\n",
      "Epoch 1/100\n",
      "1260/1260 [==============================] - 7s 6ms/step - loss: 0.0474 - MSE: 0.0474 - val_loss: 0.0234 - val_MSE: 0.0234\n",
      "Epoch 2/100\n",
      "1260/1260 [==============================] - 1s 805us/step - loss: 0.0217 - MSE: 0.0217 - val_loss: 0.0209 - val_MSE: 0.0209\n",
      "Epoch 3/100\n",
      "1260/1260 [==============================] - 1s 796us/step - loss: 0.0199 - MSE: 0.0199 - val_loss: 0.0216 - val_MSE: 0.0216\n",
      "Epoch 4/100\n",
      "1260/1260 [==============================] - 1s 813us/step - loss: 0.0212 - MSE: 0.0212 - val_loss: 0.0217 - val_MSE: 0.0217\n",
      "Epoch 5/100\n",
      "1260/1260 [==============================] - 1s 835us/step - loss: 0.0234 - MSE: 0.0234 - val_loss: 0.0217 - val_MSE: 0.0217\n",
      "Epoch 6/100\n",
      "1260/1260 [==============================] - 1s 812us/step - loss: 0.0207 - MSE: 0.0207 - val_loss: 0.0237 - val_MSE: 0.0237\n",
      "Epoch 7/100\n",
      "1260/1260 [==============================] - 1s 849us/step - loss: 0.0197 - MSE: 0.0197 - val_loss: 0.0201 - val_MSE: 0.0201\n",
      "Epoch 8/100\n",
      "1260/1260 [==============================] - 1s 804us/step - loss: 0.0189 - MSE: 0.0189 - val_loss: 0.0209 - val_MSE: 0.0209\n",
      "Epoch 9/100\n",
      "1260/1260 [==============================] - 1s 829us/step - loss: 0.0184 - MSE: 0.0184 - val_loss: 0.0212 - val_MSE: 0.0212\n",
      "Epoch 10/100\n",
      "1260/1260 [==============================] - 1s 805us/step - loss: 0.0182 - MSE: 0.0182 - val_loss: 0.0215 - val_MSE: 0.0215\n",
      "Epoch 11/100\n",
      "1260/1260 [==============================] - 1s 826us/step - loss: 0.0187 - MSE: 0.0187 - val_loss: 0.0204 - val_MSE: 0.0204\n",
      "Epoch 12/100\n",
      "1260/1260 [==============================] - 1s 824us/step - loss: 0.0200 - MSE: 0.0200 - val_loss: 0.0222 - val_MSE: 0.0222\n",
      "Epoch 13/100\n",
      "1260/1260 [==============================] - 1s 813us/step - loss: 0.0179 - MSE: 0.0179 - val_loss: 0.0235 - val_MSE: 0.0235\n",
      "Epoch 14/100\n",
      "1260/1260 [==============================] - 1s 815us/step - loss: 0.0176 - MSE: 0.0176 - val_loss: 0.0212 - val_MSE: 0.0212\n",
      "Epoch 15/100\n",
      "1260/1260 [==============================] - 1s 805us/step - loss: 0.0176 - MSE: 0.0176 - val_loss: 0.0220 - val_MSE: 0.0220\n",
      "Epoch 16/100\n",
      "1260/1260 [==============================] - 1s 847us/step - loss: 0.0177 - MSE: 0.0177 - val_loss: 0.0214 - val_MSE: 0.0214\n",
      "Epoch 17/100\n",
      "1260/1260 [==============================] - 1s 852us/step - loss: 0.0184 - MSE: 0.0184 - val_loss: 0.0248 - val_MSE: 0.0248\n",
      "QWK, Prompt 6, Fold 1: 0.665853233397246\n",
      "Fold 2\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1800, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1260 samples, validate on 270 samples\n",
      "Epoch 1/100\n",
      "1260/1260 [==============================] - 8s 6ms/step - loss: 0.0324 - MSE: 0.0324 - val_loss: 0.0220 - val_MSE: 0.0220\n",
      "Epoch 2/100\n",
      "1260/1260 [==============================] - 1s 817us/step - loss: 0.0202 - MSE: 0.0202 - val_loss: 0.0196 - val_MSE: 0.0196\n",
      "Epoch 3/100\n",
      "1260/1260 [==============================] - 1s 789us/step - loss: 0.0210 - MSE: 0.0210 - val_loss: 0.0189 - val_MSE: 0.0189\n",
      "Epoch 4/100\n",
      "1260/1260 [==============================] - 1s 803us/step - loss: 0.0212 - MSE: 0.0212 - val_loss: 0.0212 - val_MSE: 0.0212\n",
      "Epoch 5/100\n",
      "1260/1260 [==============================] - 1s 808us/step - loss: 0.0196 - MSE: 0.0196 - val_loss: 0.0250 - val_MSE: 0.0250\n",
      "Epoch 6/100\n",
      "1260/1260 [==============================] - 1s 792us/step - loss: 0.0204 - MSE: 0.0204 - val_loss: 0.0182 - val_MSE: 0.0182\n",
      "Epoch 7/100\n",
      "1260/1260 [==============================] - 1s 822us/step - loss: 0.0188 - MSE: 0.0188 - val_loss: 0.0187 - val_MSE: 0.0187\n",
      "Epoch 8/100\n",
      "1260/1260 [==============================] - 1s 812us/step - loss: 0.0178 - MSE: 0.0178 - val_loss: 0.0194 - val_MSE: 0.0194\n",
      "Epoch 9/100\n",
      "1260/1260 [==============================] - 1s 791us/step - loss: 0.0182 - MSE: 0.0182 - val_loss: 0.0206 - val_MSE: 0.0206\n",
      "Epoch 10/100\n",
      "1260/1260 [==============================] - 1s 796us/step - loss: 0.0193 - MSE: 0.0193 - val_loss: 0.0183 - val_MSE: 0.0183\n",
      "Epoch 11/100\n",
      "1260/1260 [==============================] - 1s 792us/step - loss: 0.0182 - MSE: 0.0182 - val_loss: 0.0221 - val_MSE: 0.0221\n",
      "Epoch 12/100\n",
      "1260/1260 [==============================] - 1s 840us/step - loss: 0.0185 - MSE: 0.0185 - val_loss: 0.0188 - val_MSE: 0.0188\n",
      "Epoch 13/100\n",
      "1260/1260 [==============================] - 1s 834us/step - loss: 0.0182 - MSE: 0.0182 - val_loss: 0.0198 - val_MSE: 0.0198\n",
      "Epoch 14/100\n",
      "1260/1260 [==============================] - 1s 797us/step - loss: 0.0189 - MSE: 0.0189 - val_loss: 0.0188 - val_MSE: 0.0188\n",
      "Epoch 15/100\n",
      "1260/1260 [==============================] - 1s 807us/step - loss: 0.0186 - MSE: 0.0186 - val_loss: 0.0200 - val_MSE: 0.0200\n",
      "Epoch 16/100\n",
      "1260/1260 [==============================] - 1s 798us/step - loss: 0.0186 - MSE: 0.0186 - val_loss: 0.0186 - val_MSE: 0.0186\n",
      "QWK, Prompt 6, Fold 2: 0.7325303478206178\n",
      "Fold 3\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1800, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1260 samples, validate on 270 samples\n",
      "Epoch 1/100\n",
      "1260/1260 [==============================] - 7s 6ms/step - loss: 0.0395 - MSE: 0.0395 - val_loss: 0.0200 - val_MSE: 0.0200\n",
      "Epoch 2/100\n",
      "1260/1260 [==============================] - 1s 834us/step - loss: 0.0230 - MSE: 0.0230 - val_loss: 0.0186 - val_MSE: 0.0186\n",
      "Epoch 3/100\n",
      "1260/1260 [==============================] - 1s 801us/step - loss: 0.0227 - MSE: 0.0227 - val_loss: 0.0184 - val_MSE: 0.0184\n",
      "Epoch 4/100\n",
      "1260/1260 [==============================] - 1s 829us/step - loss: 0.0218 - MSE: 0.0218 - val_loss: 0.0174 - val_MSE: 0.0174\n",
      "Epoch 5/100\n",
      "1260/1260 [==============================] - 1s 796us/step - loss: 0.0201 - MSE: 0.0201 - val_loss: 0.0183 - val_MSE: 0.0183\n",
      "Epoch 6/100\n",
      "1260/1260 [==============================] - 1s 790us/step - loss: 0.0219 - MSE: 0.0219 - val_loss: 0.0174 - val_MSE: 0.0174\n",
      "Epoch 7/100\n",
      "1260/1260 [==============================] - 1s 790us/step - loss: 0.0192 - MSE: 0.0192 - val_loss: 0.0208 - val_MSE: 0.0208\n",
      "Epoch 8/100\n",
      "1260/1260 [==============================] - 1s 789us/step - loss: 0.0218 - MSE: 0.0218 - val_loss: 0.0193 - val_MSE: 0.0193\n",
      "Epoch 9/100\n",
      "1260/1260 [==============================] - 1s 803us/step - loss: 0.0199 - MSE: 0.0199 - val_loss: 0.0175 - val_MSE: 0.0175\n",
      "Epoch 10/100\n",
      "1260/1260 [==============================] - 1s 832us/step - loss: 0.0201 - MSE: 0.0201 - val_loss: 0.0174 - val_MSE: 0.0174\n",
      "Epoch 11/100\n",
      "1260/1260 [==============================] - 1s 800us/step - loss: 0.0193 - MSE: 0.0193 - val_loss: 0.0198 - val_MSE: 0.0198\n",
      "Epoch 12/100\n",
      "1260/1260 [==============================] - 1s 820us/step - loss: 0.0195 - MSE: 0.0195 - val_loss: 0.0171 - val_MSE: 0.0171\n",
      "Epoch 13/100\n",
      "1260/1260 [==============================] - 1s 789us/step - loss: 0.0190 - MSE: 0.0190 - val_loss: 0.0171 - val_MSE: 0.0171\n",
      "Epoch 14/100\n",
      "1260/1260 [==============================] - 1s 787us/step - loss: 0.0190 - MSE: 0.0190 - val_loss: 0.0176 - val_MSE: 0.0176\n",
      "Epoch 15/100\n",
      "1260/1260 [==============================] - 1s 792us/step - loss: 0.0191 - MSE: 0.0191 - val_loss: 0.0214 - val_MSE: 0.0214\n",
      "Epoch 16/100\n",
      "1260/1260 [==============================] - 1s 794us/step - loss: 0.0191 - MSE: 0.0191 - val_loss: 0.0198 - val_MSE: 0.0198\n",
      "Epoch 17/100\n",
      "1260/1260 [==============================] - 1s 813us/step - loss: 0.0203 - MSE: 0.0203 - val_loss: 0.0186 - val_MSE: 0.0186\n",
      "Epoch 18/100\n",
      "1260/1260 [==============================] - 1s 848us/step - loss: 0.0204 - MSE: 0.0204 - val_loss: 0.0179 - val_MSE: 0.0179\n",
      "Epoch 19/100\n",
      "1260/1260 [==============================] - 1s 796us/step - loss: 0.0185 - MSE: 0.0185 - val_loss: 0.0175 - val_MSE: 0.0175\n",
      "Epoch 20/100\n",
      "1260/1260 [==============================] - 1s 784us/step - loss: 0.0196 - MSE: 0.0196 - val_loss: 0.0175 - val_MSE: 0.0175\n",
      "Epoch 21/100\n",
      "1260/1260 [==============================] - 1s 799us/step - loss: 0.0180 - MSE: 0.0180 - val_loss: 0.0171 - val_MSE: 0.0171\n",
      "Epoch 22/100\n",
      "1260/1260 [==============================] - 1s 799us/step - loss: 0.0182 - MSE: 0.0182 - val_loss: 0.0171 - val_MSE: 0.0171\n",
      "QWK, Prompt 6, Fold 3: 0.7241198108250131\n",
      "Fold 4\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1800, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1260 samples, validate on 270 samples\n",
      "Epoch 1/100\n",
      "1260/1260 [==============================] - 8s 6ms/step - loss: 0.0380 - MSE: 0.0380 - val_loss: 0.0211 - val_MSE: 0.0211\n",
      "Epoch 2/100\n",
      "1260/1260 [==============================] - 1s 841us/step - loss: 0.0210 - MSE: 0.0210 - val_loss: 0.0169 - val_MSE: 0.0169\n",
      "Epoch 3/100\n",
      "1260/1260 [==============================] - 1s 807us/step - loss: 0.0203 - MSE: 0.0203 - val_loss: 0.0180 - val_MSE: 0.0180\n",
      "Epoch 4/100\n",
      "1260/1260 [==============================] - 1s 788us/step - loss: 0.0214 - MSE: 0.0214 - val_loss: 0.0165 - val_MSE: 0.0165\n",
      "Epoch 5/100\n",
      "1260/1260 [==============================] - 1s 802us/step - loss: 0.0196 - MSE: 0.0196 - val_loss: 0.0182 - val_MSE: 0.0182\n",
      "Epoch 6/100\n",
      "1260/1260 [==============================] - 1s 812us/step - loss: 0.0197 - MSE: 0.0197 - val_loss: 0.0174 - val_MSE: 0.0174\n",
      "Epoch 7/100\n",
      "1260/1260 [==============================] - 1s 844us/step - loss: 0.0214 - MSE: 0.0214 - val_loss: 0.0167 - val_MSE: 0.0167\n",
      "Epoch 8/100\n",
      "1260/1260 [==============================] - 1s 805us/step - loss: 0.0208 - MSE: 0.0208 - val_loss: 0.0169 - val_MSE: 0.0169\n",
      "Epoch 9/100\n",
      "1260/1260 [==============================] - 1s 807us/step - loss: 0.0189 - MSE: 0.0189 - val_loss: 0.0168 - val_MSE: 0.0168\n",
      "Epoch 10/100\n",
      "1260/1260 [==============================] - 1s 809us/step - loss: 0.0193 - MSE: 0.0193 - val_loss: 0.0179 - val_MSE: 0.0179\n",
      "Epoch 11/100\n",
      "1260/1260 [==============================] - 1s 789us/step - loss: 0.0190 - MSE: 0.0190 - val_loss: 0.0171 - val_MSE: 0.0171\n",
      "Epoch 12/100\n",
      "1260/1260 [==============================] - 1s 802us/step - loss: 0.0192 - MSE: 0.0192 - val_loss: 0.0178 - val_MSE: 0.0178\n",
      "Epoch 13/100\n",
      "1260/1260 [==============================] - 1s 803us/step - loss: 0.0185 - MSE: 0.0185 - val_loss: 0.0170 - val_MSE: 0.0170\n",
      "Epoch 14/100\n",
      "1260/1260 [==============================] - 1s 801us/step - loss: 0.0186 - MSE: 0.0186 - val_loss: 0.0169 - val_MSE: 0.0169\n",
      "QWK, Prompt 6, Fold 4: 0.7415797883279809\n",
      "Fold 5\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1800, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1260 samples, validate on 270 samples\n",
      "Epoch 1/100\n",
      "1260/1260 [==============================] - 7s 6ms/step - loss: 0.0455 - MSE: 0.0455 - val_loss: 0.0289 - val_MSE: 0.0289\n",
      "Epoch 2/100\n",
      "1260/1260 [==============================] - 1s 872us/step - loss: 0.0210 - MSE: 0.0210 - val_loss: 0.0195 - val_MSE: 0.0195\n",
      "Epoch 3/100\n",
      "1260/1260 [==============================] - 1s 806us/step - loss: 0.0219 - MSE: 0.0219 - val_loss: 0.0182 - val_MSE: 0.0182\n",
      "Epoch 4/100\n",
      "1260/1260 [==============================] - 1s 848us/step - loss: 0.0212 - MSE: 0.0212 - val_loss: 0.0188 - val_MSE: 0.0188\n",
      "Epoch 5/100\n",
      "1260/1260 [==============================] - 1s 796us/step - loss: 0.0227 - MSE: 0.0227 - val_loss: 0.0219 - val_MSE: 0.0219\n",
      "Epoch 6/100\n",
      "1260/1260 [==============================] - 1s 782us/step - loss: 0.0195 - MSE: 0.0195 - val_loss: 0.0183 - val_MSE: 0.0183\n",
      "Epoch 7/100\n",
      "1260/1260 [==============================] - 1s 798us/step - loss: 0.0196 - MSE: 0.0196 - val_loss: 0.0241 - val_MSE: 0.0241\n",
      "Epoch 8/100\n",
      "1260/1260 [==============================] - 1s 821us/step - loss: 0.0205 - MSE: 0.0205 - val_loss: 0.0181 - val_MSE: 0.0181\n",
      "Epoch 9/100\n",
      "1260/1260 [==============================] - 1s 797us/step - loss: 0.0192 - MSE: 0.0192 - val_loss: 0.0195 - val_MSE: 0.0195\n",
      "Epoch 10/100\n",
      "1260/1260 [==============================] - 1s 794us/step - loss: 0.0190 - MSE: 0.0190 - val_loss: 0.0191 - val_MSE: 0.0191\n",
      "Epoch 11/100\n",
      "1260/1260 [==============================] - 1s 813us/step - loss: 0.0198 - MSE: 0.0198 - val_loss: 0.0209 - val_MSE: 0.0209\n",
      "Epoch 12/100\n",
      "1260/1260 [==============================] - 1s 796us/step - loss: 0.0191 - MSE: 0.0191 - val_loss: 0.0181 - val_MSE: 0.0181\n",
      "Epoch 13/100\n",
      "1260/1260 [==============================] - 1s 823us/step - loss: 0.0186 - MSE: 0.0186 - val_loss: 0.0201 - val_MSE: 0.0201\n",
      "Epoch 14/100\n",
      "1260/1260 [==============================] - 1s 801us/step - loss: 0.0186 - MSE: 0.0186 - val_loss: 0.0185 - val_MSE: 0.0185\n",
      "Epoch 15/100\n",
      "1260/1260 [==============================] - 1s 822us/step - loss: 0.0188 - MSE: 0.0188 - val_loss: 0.0183 - val_MSE: 0.0183\n",
      "Epoch 16/100\n",
      "1260/1260 [==============================] - 1s 801us/step - loss: 0.0191 - MSE: 0.0191 - val_loss: 0.0262 - val_MSE: 0.0262\n",
      "Epoch 17/100\n",
      "1260/1260 [==============================] - 1s 825us/step - loss: 0.0185 - MSE: 0.0185 - val_loss: 0.0191 - val_MSE: 0.0191\n",
      "Epoch 18/100\n",
      "1260/1260 [==============================] - 1s 803us/step - loss: 0.0186 - MSE: 0.0186 - val_loss: 0.0177 - val_MSE: 0.0177\n",
      "Epoch 19/100\n",
      "1260/1260 [==============================] - 1s 801us/step - loss: 0.0187 - MSE: 0.0187 - val_loss: 0.0176 - val_MSE: 0.0176\n",
      "Epoch 20/100\n",
      "1260/1260 [==============================] - 1s 804us/step - loss: 0.0180 - MSE: 0.0180 - val_loss: 0.0184 - val_MSE: 0.0184\n",
      "Epoch 21/100\n",
      "1260/1260 [==============================] - 1s 805us/step - loss: 0.0220 - MSE: 0.0220 - val_loss: 0.0182 - val_MSE: 0.0182\n",
      "Epoch 22/100\n",
      "1260/1260 [==============================] - 1s 810us/step - loss: 0.0185 - MSE: 0.0185 - val_loss: 0.0216 - val_MSE: 0.0216\n",
      "Epoch 23/100\n",
      "1260/1260 [==============================] - 1s 813us/step - loss: 0.0205 - MSE: 0.0205 - val_loss: 0.0194 - val_MSE: 0.0194\n",
      "Epoch 24/100\n",
      "1260/1260 [==============================] - 1s 893us/step - loss: 0.0188 - MSE: 0.0188 - val_loss: 0.0180 - val_MSE: 0.0180\n",
      "Epoch 25/100\n",
      "1260/1260 [==============================] - 1s 851us/step - loss: 0.0183 - MSE: 0.0183 - val_loss: 0.0229 - val_MSE: 0.0229\n",
      "Epoch 26/100\n",
      "1260/1260 [==============================] - 1s 824us/step - loss: 0.0177 - MSE: 0.0177 - val_loss: 0.0194 - val_MSE: 0.0194\n",
      "Epoch 27/100\n",
      "1260/1260 [==============================] - 1s 856us/step - loss: 0.0183 - MSE: 0.0183 - val_loss: 0.0177 - val_MSE: 0.0177\n",
      "Epoch 28/100\n",
      "1260/1260 [==============================] - 1s 810us/step - loss: 0.0178 - MSE: 0.0178 - val_loss: 0.0176 - val_MSE: 0.0176\n",
      "Epoch 29/100\n",
      "1260/1260 [==============================] - 1s 818us/step - loss: 0.0178 - MSE: 0.0178 - val_loss: 0.0193 - val_MSE: 0.0193\n",
      "Epoch 30/100\n",
      "1260/1260 [==============================] - 1s 805us/step - loss: 0.0179 - MSE: 0.0179 - val_loss: 0.0180 - val_MSE: 0.0180\n",
      "Epoch 31/100\n",
      "1260/1260 [==============================] - 1s 833us/step - loss: 0.0182 - MSE: 0.0182 - val_loss: 0.0182 - val_MSE: 0.0182\n",
      "Epoch 32/100\n",
      "1260/1260 [==============================] - 1s 816us/step - loss: 0.0176 - MSE: 0.0176 - val_loss: 0.0176 - val_MSE: 0.0176\n",
      "Epoch 33/100\n",
      "1260/1260 [==============================] - 1s 813us/step - loss: 0.0183 - MSE: 0.0183 - val_loss: 0.0178 - val_MSE: 0.0178\n",
      "Epoch 34/100\n",
      "1260/1260 [==============================] - 1s 803us/step - loss: 0.0181 - MSE: 0.0181 - val_loss: 0.0206 - val_MSE: 0.0206\n",
      "Epoch 35/100\n",
      "1260/1260 [==============================] - 1s 826us/step - loss: 0.0182 - MSE: 0.0182 - val_loss: 0.0178 - val_MSE: 0.0178\n",
      "Epoch 36/100\n",
      "1260/1260 [==============================] - 1s 805us/step - loss: 0.0176 - MSE: 0.0176 - val_loss: 0.0191 - val_MSE: 0.0191\n",
      "Epoch 37/100\n",
      "1260/1260 [==============================] - 1s 836us/step - loss: 0.0178 - MSE: 0.0178 - val_loss: 0.0180 - val_MSE: 0.0180\n",
      "Epoch 38/100\n",
      "1260/1260 [==============================] - 1s 819us/step - loss: 0.0177 - MSE: 0.0177 - val_loss: 0.0176 - val_MSE: 0.0176\n",
      "Epoch 39/100\n",
      "1260/1260 [==============================] - 1s 866us/step - loss: 0.0174 - MSE: 0.0174 - val_loss: 0.0195 - val_MSE: 0.0195\n",
      "Epoch 40/100\n",
      "1260/1260 [==============================] - 1s 837us/step - loss: 0.0177 - MSE: 0.0177 - val_loss: 0.0178 - val_MSE: 0.0178\n",
      "Epoch 41/100\n",
      "1260/1260 [==============================] - 1s 850us/step - loss: 0.0184 - MSE: 0.0184 - val_loss: 0.0227 - val_MSE: 0.0227\n",
      "Epoch 42/100\n",
      "1260/1260 [==============================] - 1s 832us/step - loss: 0.0191 - MSE: 0.0191 - val_loss: 0.0177 - val_MSE: 0.0177\n",
      "Epoch 43/100\n",
      "1260/1260 [==============================] - 1s 811us/step - loss: 0.0179 - MSE: 0.0179 - val_loss: 0.0197 - val_MSE: 0.0197\n",
      "Epoch 44/100\n",
      "1260/1260 [==============================] - 1s 807us/step - loss: 0.0182 - MSE: 0.0182 - val_loss: 0.0199 - val_MSE: 0.0199\n",
      "Epoch 45/100\n",
      "1260/1260 [==============================] - 1s 801us/step - loss: 0.0180 - MSE: 0.0180 - val_loss: 0.0178 - val_MSE: 0.0178\n",
      "Epoch 46/100\n",
      "1260/1260 [==============================] - 1s 838us/step - loss: 0.0173 - MSE: 0.0173 - val_loss: 0.0183 - val_MSE: 0.0183\n",
      "Epoch 47/100\n",
      "1260/1260 [==============================] - 1s 824us/step - loss: 0.0167 - MSE: 0.0167 - val_loss: 0.0182 - val_MSE: 0.0182\n",
      "Epoch 48/100\n",
      "1260/1260 [==============================] - 1s 823us/step - loss: 0.0178 - MSE: 0.0178 - val_loss: 0.0177 - val_MSE: 0.0177\n",
      "QWK, Prompt 6, Fold 5: 0.8010777585989138\n",
      "Prompt: 7\n",
      "Fold 1\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1569, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1099 samples, validate on 235 samples\n",
      "Epoch 1/100\n",
      "1099/1099 [==============================] - 8s 7ms/step - loss: 0.0382 - MSE: 0.0382 - val_loss: 0.0253 - val_MSE: 0.0253\n",
      "Epoch 2/100\n",
      "1099/1099 [==============================] - 1s 874us/step - loss: 0.0210 - MSE: 0.0210 - val_loss: 0.0217 - val_MSE: 0.0217\n",
      "Epoch 3/100\n",
      "1099/1099 [==============================] - 1s 824us/step - loss: 0.0202 - MSE: 0.0202 - val_loss: 0.0228 - val_MSE: 0.0228\n",
      "Epoch 4/100\n",
      "1099/1099 [==============================] - ETA: 0s - loss: 0.0199 - MSE: 0.019 - 1s 801us/step - loss: 0.0197 - MSE: 0.0197 - val_loss: 0.0237 - val_MSE: 0.0237\n",
      "Epoch 5/100\n",
      "1099/1099 [==============================] - 1s 794us/step - loss: 0.0201 - MSE: 0.0201 - val_loss: 0.0195 - val_MSE: 0.0195\n",
      "Epoch 6/100\n",
      "1099/1099 [==============================] - 1s 790us/step - loss: 0.0195 - MSE: 0.0195 - val_loss: 0.0205 - val_MSE: 0.0205\n",
      "Epoch 7/100\n",
      "1099/1099 [==============================] - 1s 801us/step - loss: 0.0214 - MSE: 0.0214 - val_loss: 0.0219 - val_MSE: 0.0219\n",
      "Epoch 8/100\n",
      "1099/1099 [==============================] - 1s 795us/step - loss: 0.0182 - MSE: 0.0182 - val_loss: 0.0199 - val_MSE: 0.0199\n",
      "Epoch 9/100\n",
      "1099/1099 [==============================] - 1s 796us/step - loss: 0.0191 - MSE: 0.0191 - val_loss: 0.0194 - val_MSE: 0.0194\n",
      "Epoch 10/100\n",
      "1099/1099 [==============================] - 1s 784us/step - loss: 0.0191 - MSE: 0.0191 - val_loss: 0.0305 - val_MSE: 0.0305\n",
      "Epoch 11/100\n",
      "1099/1099 [==============================] - 1s 795us/step - loss: 0.0188 - MSE: 0.0188 - val_loss: 0.0191 - val_MSE: 0.0191\n",
      "Epoch 12/100\n",
      "1099/1099 [==============================] - 1s 786us/step - loss: 0.0176 - MSE: 0.0176 - val_loss: 0.0221 - val_MSE: 0.0221\n",
      "Epoch 13/100\n",
      "1099/1099 [==============================] - 1s 791us/step - loss: 0.0178 - MSE: 0.0178 - val_loss: 0.0227 - val_MSE: 0.0227\n",
      "Epoch 14/100\n",
      "1099/1099 [==============================] - 1s 798us/step - loss: 0.0175 - MSE: 0.0175 - val_loss: 0.0206 - val_MSE: 0.0206\n",
      "Epoch 15/100\n",
      "1099/1099 [==============================] - 1s 790us/step - loss: 0.0173 - MSE: 0.0173 - val_loss: 0.0206 - val_MSE: 0.0206\n",
      "Epoch 16/100\n",
      "1099/1099 [==============================] - 1s 790us/step - loss: 0.0185 - MSE: 0.0185 - val_loss: 0.0190 - val_MSE: 0.0190\n",
      "Epoch 17/100\n",
      "1099/1099 [==============================] - 1s 787us/step - loss: 0.0171 - MSE: 0.0171 - val_loss: 0.0190 - val_MSE: 0.0190\n",
      "Epoch 18/100\n",
      "1099/1099 [==============================] - 1s 791us/step - loss: 0.0169 - MSE: 0.0169 - val_loss: 0.0238 - val_MSE: 0.0238\n",
      "Epoch 19/100\n",
      "1099/1099 [==============================] - 1s 795us/step - loss: 0.0179 - MSE: 0.0179 - val_loss: 0.0195 - val_MSE: 0.0195\n",
      "Epoch 20/100\n",
      "1099/1099 [==============================] - 1s 843us/step - loss: 0.0181 - MSE: 0.0181 - val_loss: 0.0217 - val_MSE: 0.0217\n",
      "Epoch 21/100\n",
      "1099/1099 [==============================] - 1s 802us/step - loss: 0.0171 - MSE: 0.0171 - val_loss: 0.0225 - val_MSE: 0.0225\n",
      "Epoch 22/100\n",
      "1099/1099 [==============================] - 1s 806us/step - loss: 0.0180 - MSE: 0.0180 - val_loss: 0.0207 - val_MSE: 0.0207\n",
      "Epoch 23/100\n",
      "1099/1099 [==============================] - 1s 785us/step - loss: 0.0189 - MSE: 0.0189 - val_loss: 0.0214 - val_MSE: 0.0214\n",
      "Epoch 24/100\n",
      "1099/1099 [==============================] - 1s 793us/step - loss: 0.0165 - MSE: 0.0165 - val_loss: 0.0201 - val_MSE: 0.0201\n",
      "Epoch 25/100\n",
      "1099/1099 [==============================] - 1s 803us/step - loss: 0.0170 - MSE: 0.0170 - val_loss: 0.0200 - val_MSE: 0.0200\n",
      "Epoch 26/100\n",
      "1099/1099 [==============================] - 1s 879us/step - loss: 0.0166 - MSE: 0.0166 - val_loss: 0.0282 - val_MSE: 0.0282\n",
      "QWK, Prompt 7, Fold 1: 0.68485094550868\n",
      "Fold 2\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1569, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1099 samples, validate on 235 samples\n",
      "Epoch 1/100\n",
      "1099/1099 [==============================] - 7s 6ms/step - loss: 0.0366 - MSE: 0.0366 - val_loss: 0.0262 - val_MSE: 0.0262\n",
      "Epoch 2/100\n",
      "1099/1099 [==============================] - 1s 858us/step - loss: 0.0218 - MSE: 0.0218 - val_loss: 0.0239 - val_MSE: 0.0239\n",
      "Epoch 3/100\n",
      "1099/1099 [==============================] - 1s 802us/step - loss: 0.0200 - MSE: 0.0200 - val_loss: 0.0241 - val_MSE: 0.0241\n",
      "Epoch 4/100\n",
      "1099/1099 [==============================] - 1s 823us/step - loss: 0.0191 - MSE: 0.0191 - val_loss: 0.0217 - val_MSE: 0.0217\n",
      "Epoch 5/100\n",
      "1099/1099 [==============================] - 1s 798us/step - loss: 0.0203 - MSE: 0.0203 - val_loss: 0.0237 - val_MSE: 0.0237\n",
      "Epoch 6/100\n",
      "1099/1099 [==============================] - 1s 803us/step - loss: 0.0182 - MSE: 0.0182 - val_loss: 0.0216 - val_MSE: 0.0216\n",
      "Epoch 7/100\n",
      "1099/1099 [==============================] - 1s 807us/step - loss: 0.0194 - MSE: 0.0194 - val_loss: 0.0217 - val_MSE: 0.0217\n",
      "Epoch 8/100\n",
      "1099/1099 [==============================] - 1s 817us/step - loss: 0.0182 - MSE: 0.0182 - val_loss: 0.0266 - val_MSE: 0.0266\n",
      "Epoch 9/100\n",
      "1099/1099 [==============================] - 1s 831us/step - loss: 0.0179 - MSE: 0.0179 - val_loss: 0.0244 - val_MSE: 0.0244\n",
      "Epoch 10/100\n",
      "1099/1099 [==============================] - 1s 812us/step - loss: 0.0178 - MSE: 0.0178 - val_loss: 0.0218 - val_MSE: 0.0218\n",
      "Epoch 11/100\n",
      "1099/1099 [==============================] - 1s 847us/step - loss: 0.0167 - MSE: 0.0167 - val_loss: 0.0219 - val_MSE: 0.0219\n",
      "Epoch 12/100\n",
      "1099/1099 [==============================] - 1s 825us/step - loss: 0.0174 - MSE: 0.0174 - val_loss: 0.0214 - val_MSE: 0.0214\n",
      "Epoch 13/100\n",
      "1099/1099 [==============================] - 1s 811us/step - loss: 0.0173 - MSE: 0.0173 - val_loss: 0.0227 - val_MSE: 0.0227\n",
      "Epoch 14/100\n",
      "1099/1099 [==============================] - 1s 798us/step - loss: 0.0186 - MSE: 0.0186 - val_loss: 0.0215 - val_MSE: 0.0215\n",
      "Epoch 15/100\n",
      "1099/1099 [==============================] - 1s 798us/step - loss: 0.0199 - MSE: 0.0199 - val_loss: 0.0230 - val_MSE: 0.0230\n",
      "Epoch 16/100\n",
      "1099/1099 [==============================] - 1s 799us/step - loss: 0.0174 - MSE: 0.0174 - val_loss: 0.0216 - val_MSE: 0.0216\n",
      "Epoch 17/100\n",
      "1099/1099 [==============================] - 1s 841us/step - loss: 0.0183 - MSE: 0.0183 - val_loss: 0.0247 - val_MSE: 0.0247\n",
      "Epoch 18/100\n",
      "1099/1099 [==============================] - 1s 808us/step - loss: 0.0167 - MSE: 0.0167 - val_loss: 0.0220 - val_MSE: 0.0220\n",
      "Epoch 19/100\n",
      "1099/1099 [==============================] - 1s 836us/step - loss: 0.0165 - MSE: 0.0165 - val_loss: 0.0224 - val_MSE: 0.0224\n",
      "Epoch 20/100\n",
      "1099/1099 [==============================] - 1s 799us/step - loss: 0.0172 - MSE: 0.0172 - val_loss: 0.0217 - val_MSE: 0.0217\n",
      "Epoch 21/100\n",
      "1099/1099 [==============================] - 1s 801us/step - loss: 0.0175 - MSE: 0.0175 - val_loss: 0.0231 - val_MSE: 0.0231\n",
      "Epoch 22/100\n",
      "1099/1099 [==============================] - 1s 795us/step - loss: 0.0170 - MSE: 0.0170 - val_loss: 0.0230 - val_MSE: 0.0230\n",
      "QWK, Prompt 7, Fold 2: 0.7301637381706331\n",
      "Fold 3\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1569, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1099 samples, validate on 235 samples\n",
      "Epoch 1/100\n",
      "1099/1099 [==============================] - 8s 7ms/step - loss: 0.0292 - MSE: 0.0292 - val_loss: 0.0192 - val_MSE: 0.0192\n",
      "Epoch 2/100\n",
      "1099/1099 [==============================] - 1s 862us/step - loss: 0.0217 - MSE: 0.0217 - val_loss: 0.0190 - val_MSE: 0.0190\n",
      "Epoch 3/100\n",
      "1099/1099 [==============================] - 1s 806us/step - loss: 0.0206 - MSE: 0.0206 - val_loss: 0.0181 - val_MSE: 0.0181\n",
      "Epoch 4/100\n",
      "1099/1099 [==============================] - 1s 830us/step - loss: 0.0193 - MSE: 0.0193 - val_loss: 0.0192 - val_MSE: 0.0192\n",
      "Epoch 5/100\n",
      "1099/1099 [==============================] - 1s 823us/step - loss: 0.0198 - MSE: 0.0198 - val_loss: 0.0238 - val_MSE: 0.0238\n",
      "Epoch 6/100\n",
      "1099/1099 [==============================] - 1s 795us/step - loss: 0.0215 - MSE: 0.0215 - val_loss: 0.0171 - val_MSE: 0.0171\n",
      "Epoch 7/100\n",
      "1099/1099 [==============================] - 1s 827us/step - loss: 0.0200 - MSE: 0.0200 - val_loss: 0.0209 - val_MSE: 0.0209\n",
      "Epoch 8/100\n",
      "1099/1099 [==============================] - 1s 827us/step - loss: 0.0188 - MSE: 0.0188 - val_loss: 0.0189 - val_MSE: 0.0189\n",
      "Epoch 9/100\n",
      "1099/1099 [==============================] - 1s 835us/step - loss: 0.0214 - MSE: 0.0214 - val_loss: 0.0308 - val_MSE: 0.0308\n",
      "Epoch 10/100\n",
      "1099/1099 [==============================] - 1s 874us/step - loss: 0.0196 - MSE: 0.0196 - val_loss: 0.0178 - val_MSE: 0.0178\n",
      "Epoch 11/100\n",
      "1099/1099 [==============================] - 1s 867us/step - loss: 0.0183 - MSE: 0.0183 - val_loss: 0.0173 - val_MSE: 0.0173\n",
      "Epoch 12/100\n",
      "1099/1099 [==============================] - 1s 872us/step - loss: 0.0182 - MSE: 0.0182 - val_loss: 0.0200 - val_MSE: 0.0200\n",
      "Epoch 13/100\n",
      "1099/1099 [==============================] - 1s 839us/step - loss: 0.0178 - MSE: 0.0178 - val_loss: 0.0177 - val_MSE: 0.0177\n",
      "Epoch 14/100\n",
      "1099/1099 [==============================] - 1s 864us/step - loss: 0.0196 - MSE: 0.0196 - val_loss: 0.0188 - val_MSE: 0.0188\n",
      "Epoch 15/100\n",
      "1099/1099 [==============================] - 1s 861us/step - loss: 0.0171 - MSE: 0.0171 - val_loss: 0.0196 - val_MSE: 0.0196\n",
      "Epoch 16/100\n",
      "1099/1099 [==============================] - 1s 855us/step - loss: 0.0174 - MSE: 0.0174 - val_loss: 0.0174 - val_MSE: 0.0174\n",
      "QWK, Prompt 7, Fold 3: 0.7395996812902914\n",
      "Fold 4\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1569, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1099 samples, validate on 235 samples\n",
      "Epoch 1/100\n",
      "1099/1099 [==============================] - 8s 8ms/step - loss: 0.0280 - MSE: 0.0280 - val_loss: 0.0320 - val_MSE: 0.0320\n",
      "Epoch 2/100\n",
      "1099/1099 [==============================] - 1s 975us/step - loss: 0.0223 - MSE: 0.0223 - val_loss: 0.0307 - val_MSE: 0.0307\n",
      "Epoch 3/100\n",
      "1099/1099 [==============================] - 1s 952us/step - loss: 0.0242 - MSE: 0.0242 - val_loss: 0.0212 - val_MSE: 0.0212\n",
      "Epoch 4/100\n",
      "1099/1099 [==============================] - 1s 910us/step - loss: 0.0208 - MSE: 0.0208 - val_loss: 0.0181 - val_MSE: 0.0181\n",
      "Epoch 5/100\n",
      "1099/1099 [==============================] - 1s 931us/step - loss: 0.0202 - MSE: 0.0202 - val_loss: 0.0177 - val_MSE: 0.0177\n",
      "Epoch 6/100\n",
      "1099/1099 [==============================] - 1s 911us/step - loss: 0.0191 - MSE: 0.0191 - val_loss: 0.0237 - val_MSE: 0.0237\n",
      "Epoch 7/100\n",
      "1099/1099 [==============================] - 1s 954us/step - loss: 0.0209 - MSE: 0.0209 - val_loss: 0.0175 - val_MSE: 0.0175\n",
      "Epoch 8/100\n",
      "1099/1099 [==============================] - 1s 830us/step - loss: 0.0188 - MSE: 0.0188 - val_loss: 0.0181 - val_MSE: 0.0181\n",
      "Epoch 9/100\n",
      "1099/1099 [==============================] - 1s 792us/step - loss: 0.0205 - MSE: 0.0205 - val_loss: 0.0193 - val_MSE: 0.0193\n",
      "Epoch 10/100\n",
      "1099/1099 [==============================] - 1s 801us/step - loss: 0.0181 - MSE: 0.0181 - val_loss: 0.0205 - val_MSE: 0.0205\n",
      "Epoch 11/100\n",
      "1099/1099 [==============================] - 1s 794us/step - loss: 0.0192 - MSE: 0.0192 - val_loss: 0.0190 - val_MSE: 0.0190\n",
      "Epoch 12/100\n",
      "1099/1099 [==============================] - 1s 791us/step - loss: 0.0179 - MSE: 0.0179 - val_loss: 0.0193 - val_MSE: 0.0193\n",
      "Epoch 13/100\n",
      "1099/1099 [==============================] - 1s 805us/step - loss: 0.0184 - MSE: 0.0184 - val_loss: 0.0178 - val_MSE: 0.0178\n",
      "Epoch 14/100\n",
      "1099/1099 [==============================] - 1s 799us/step - loss: 0.0176 - MSE: 0.0176 - val_loss: 0.0210 - val_MSE: 0.0210\n",
      "Epoch 15/100\n",
      "1099/1099 [==============================] - 1s 791us/step - loss: 0.0187 - MSE: 0.0187 - val_loss: 0.0177 - val_MSE: 0.0177\n",
      "Epoch 16/100\n",
      "1099/1099 [==============================] - 1s 803us/step - loss: 0.0181 - MSE: 0.0181 - val_loss: 0.0175 - val_MSE: 0.0175\n",
      "Epoch 17/100\n",
      "1099/1099 [==============================] - 1s 796us/step - loss: 0.0175 - MSE: 0.0175 - val_loss: 0.0190 - val_MSE: 0.0190\n",
      "QWK, Prompt 7, Fold 4: 0.7383328953084858\n",
      "Fold 5\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (1569, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 1099 samples, validate on 235 samples\n",
      "Epoch 1/100\n",
      "1099/1099 [==============================] - 8s 7ms/step - loss: 0.0337 - MSE: 0.0337 - val_loss: 0.0227 - val_MSE: 0.0227\n",
      "Epoch 2/100\n",
      "1099/1099 [==============================] - ETA: 0s - loss: 0.0209 - MSE: 0.020 - 1s 917us/step - loss: 0.0208 - MSE: 0.0208 - val_loss: 0.0271 - val_MSE: 0.0271\n",
      "Epoch 3/100\n",
      "1099/1099 [==============================] - 1s 841us/step - loss: 0.0210 - MSE: 0.0210 - val_loss: 0.0199 - val_MSE: 0.0199\n",
      "Epoch 4/100\n",
      "1099/1099 [==============================] - 1s 817us/step - loss: 0.0216 - MSE: 0.0216 - val_loss: 0.0230 - val_MSE: 0.0230\n",
      "Epoch 5/100\n",
      "1099/1099 [==============================] - 1s 803us/step - loss: 0.0204 - MSE: 0.0204 - val_loss: 0.0208 - val_MSE: 0.0208\n",
      "Epoch 6/100\n",
      "1099/1099 [==============================] - 1s 808us/step - loss: 0.0193 - MSE: 0.0193 - val_loss: 0.0243 - val_MSE: 0.0243\n",
      "Epoch 7/100\n",
      "1099/1099 [==============================] - 1s 830us/step - loss: 0.0176 - MSE: 0.0176 - val_loss: 0.0196 - val_MSE: 0.0196\n",
      "Epoch 8/100\n",
      "1099/1099 [==============================] - 1s 851us/step - loss: 0.0187 - MSE: 0.0187 - val_loss: 0.0196 - val_MSE: 0.0196\n",
      "Epoch 9/100\n",
      "1099/1099 [==============================] - 1s 833us/step - loss: 0.0186 - MSE: 0.0186 - val_loss: 0.0255 - val_MSE: 0.0255\n",
      "Epoch 10/100\n",
      "1099/1099 [==============================] - 1s 829us/step - loss: 0.0198 - MSE: 0.0198 - val_loss: 0.0212 - val_MSE: 0.0212\n",
      "Epoch 11/100\n",
      "1099/1099 [==============================] - 1s 817us/step - loss: 0.0176 - MSE: 0.0176 - val_loss: 0.0198 - val_MSE: 0.0198\n",
      "Epoch 12/100\n",
      "1099/1099 [==============================] - ETA: 0s - loss: 0.0174 - MSE: 0.017 - 1s 796us/step - loss: 0.0172 - MSE: 0.0172 - val_loss: 0.0192 - val_MSE: 0.0192\n",
      "Epoch 13/100\n",
      "1099/1099 [==============================] - 1s 822us/step - loss: 0.0175 - MSE: 0.0175 - val_loss: 0.0230 - val_MSE: 0.0230\n",
      "Epoch 14/100\n",
      "1099/1099 [==============================] - 1s 810us/step - loss: 0.0175 - MSE: 0.0175 - val_loss: 0.0208 - val_MSE: 0.0208\n",
      "Epoch 15/100\n",
      "1099/1099 [==============================] - 1s 810us/step - loss: 0.0165 - MSE: 0.0165 - val_loss: 0.0231 - val_MSE: 0.0231\n",
      "Epoch 16/100\n",
      "1099/1099 [==============================] - 1s 799us/step - loss: 0.0175 - MSE: 0.0175 - val_loss: 0.0195 - val_MSE: 0.0195\n",
      "Epoch 17/100\n",
      "1099/1099 [==============================] - 1s 848us/step - loss: 0.0165 - MSE: 0.0165 - val_loss: 0.0205 - val_MSE: 0.0205\n",
      "Epoch 18/100\n",
      "1099/1099 [==============================] - 1s 822us/step - loss: 0.0164 - MSE: 0.0164 - val_loss: 0.0204 - val_MSE: 0.0204\n",
      "Epoch 19/100\n",
      "1099/1099 [==============================] - 1s 844us/step - loss: 0.0180 - MSE: 0.0180 - val_loss: 0.0193 - val_MSE: 0.0193\n",
      "Epoch 20/100\n",
      "1099/1099 [==============================] - 1s 824us/step - loss: 0.0166 - MSE: 0.0166 - val_loss: 0.0193 - val_MSE: 0.0193\n",
      "Epoch 21/100\n",
      "1099/1099 [==============================] - 1s 866us/step - loss: 0.0170 - MSE: 0.0170 - val_loss: 0.0206 - val_MSE: 0.0206\n",
      "Epoch 22/100\n",
      "1099/1099 [==============================] - 1s 824us/step - loss: 0.0168 - MSE: 0.0168 - val_loss: 0.0205 - val_MSE: 0.0205\n",
      "QWK, Prompt 7, Fold 5: 0.7023940371190766\n",
      "Prompt: 8\n",
      "Fold 1\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (723, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 507 samples, validate on 108 samples\n",
      "Epoch 1/100\n",
      "507/507 [==============================] - 8s 16ms/step - loss: 0.0230 - MSE: 0.0230 - val_loss: 0.0202 - val_MSE: 0.0202\n",
      "Epoch 2/100\n",
      "507/507 [==============================] - 0s 916us/step - loss: 0.0133 - MSE: 0.0133 - val_loss: 0.0083 - val_MSE: 0.0083\n",
      "Epoch 3/100\n",
      "507/507 [==============================] - 0s 950us/step - loss: 0.0082 - MSE: 0.0082 - val_loss: 0.0090 - val_MSE: 0.0090\n",
      "Epoch 4/100\n",
      "507/507 [==============================] - 0s 968us/step - loss: 0.0074 - MSE: 0.0074 - val_loss: 0.0129 - val_MSE: 0.0129\n",
      "Epoch 5/100\n",
      "507/507 [==============================] - 1s 1ms/step - loss: 0.0108 - MSE: 0.0108 - val_loss: 0.0090 - val_MSE: 0.0090\n",
      "Epoch 6/100\n",
      "507/507 [==============================] - 1s 994us/step - loss: 0.0092 - MSE: 0.0092 - val_loss: 0.0098 - val_MSE: 0.0098\n",
      "Epoch 7/100\n",
      "507/507 [==============================] - 0s 952us/step - loss: 0.0072 - MSE: 0.0072 - val_loss: 0.0069 - val_MSE: 0.0069\n",
      "Epoch 8/100\n",
      "507/507 [==============================] - 1s 1ms/step - loss: 0.0067 - MSE: 0.0067 - val_loss: 0.0093 - val_MSE: 0.0093\n",
      "Epoch 9/100\n",
      "507/507 [==============================] - 0s 925us/step - loss: 0.0069 - MSE: 0.0069 - val_loss: 0.0074 - val_MSE: 0.0074\n",
      "Epoch 10/100\n",
      "507/507 [==============================] - 0s 931us/step - loss: 0.0069 - MSE: 0.0069 - val_loss: 0.0070 - val_MSE: 0.0070\n",
      "Epoch 11/100\n",
      "507/507 [==============================] - 0s 970us/step - loss: 0.0065 - MSE: 0.0065 - val_loss: 0.0109 - val_MSE: 0.0109\n",
      "Epoch 12/100\n",
      "507/507 [==============================] - 0s 949us/step - loss: 0.0075 - MSE: 0.0075 - val_loss: 0.0074 - val_MSE: 0.0074\n",
      "Epoch 13/100\n",
      "507/507 [==============================] - 0s 951us/step - loss: 0.0066 - MSE: 0.0066 - val_loss: 0.0085 - val_MSE: 0.0085\n",
      "Epoch 14/100\n",
      "507/507 [==============================] - 0s 965us/step - loss: 0.0074 - MSE: 0.0074 - val_loss: 0.0088 - val_MSE: 0.0088\n",
      "Epoch 15/100\n",
      "507/507 [==============================] - 0s 940us/step - loss: 0.0067 - MSE: 0.0067 - val_loss: 0.0075 - val_MSE: 0.0075\n",
      "Epoch 16/100\n",
      "507/507 [==============================] - 0s 934us/step - loss: 0.0073 - MSE: 0.0073 - val_loss: 0.0081 - val_MSE: 0.0081\n",
      "Epoch 17/100\n",
      "507/507 [==============================] - 0s 967us/step - loss: 0.0079 - MSE: 0.0079 - val_loss: 0.0070 - val_MSE: 0.0070\n",
      "QWK, Prompt 8, Fold 1: 0.5958923512747875\n",
      "Fold 2\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (723, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 507 samples, validate on 108 samples\n",
      "Epoch 1/100\n",
      "507/507 [==============================] - 8s 15ms/step - loss: 0.0384 - MSE: 0.0384 - val_loss: 0.0170 - val_MSE: 0.0170\n",
      "Epoch 2/100\n",
      "507/507 [==============================] - 0s 933us/step - loss: 0.0118 - MSE: 0.0118 - val_loss: 0.0091 - val_MSE: 0.0091\n",
      "Epoch 3/100\n",
      "507/507 [==============================] - 0s 920us/step - loss: 0.0084 - MSE: 0.0084 - val_loss: 0.0076 - val_MSE: 0.0076\n",
      "Epoch 4/100\n",
      "507/507 [==============================] - 0s 896us/step - loss: 0.0073 - MSE: 0.0073 - val_loss: 0.0073 - val_MSE: 0.0073\n",
      "Epoch 5/100\n",
      "507/507 [==============================] - 0s 859us/step - loss: 0.0073 - MSE: 0.0073 - val_loss: 0.0072 - val_MSE: 0.0072\n",
      "Epoch 6/100\n",
      "507/507 [==============================] - 0s 906us/step - loss: 0.0080 - MSE: 0.0080 - val_loss: 0.0073 - val_MSE: 0.0073\n",
      "Epoch 7/100\n",
      "507/507 [==============================] - 0s 851us/step - loss: 0.0065 - MSE: 0.0065 - val_loss: 0.0069 - val_MSE: 0.0069\n",
      "Epoch 8/100\n",
      "507/507 [==============================] - 0s 867us/step - loss: 0.0070 - MSE: 0.0070 - val_loss: 0.0078 - val_MSE: 0.0078\n",
      "Epoch 9/100\n",
      "507/507 [==============================] - 0s 851us/step - loss: 0.0065 - MSE: 0.0065 - val_loss: 0.0113 - val_MSE: 0.0113\n",
      "Epoch 10/100\n",
      "507/507 [==============================] - 0s 837us/step - loss: 0.0067 - MSE: 0.0067 - val_loss: 0.0079 - val_MSE: 0.0079\n",
      "Epoch 11/100\n",
      "507/507 [==============================] - 0s 870us/step - loss: 0.0078 - MSE: 0.0078 - val_loss: 0.0073 - val_MSE: 0.0073\n",
      "Epoch 12/100\n",
      "507/507 [==============================] - 0s 846us/step - loss: 0.0095 - MSE: 0.0095 - val_loss: 0.0070 - val_MSE: 0.0070\n",
      "Epoch 13/100\n",
      "507/507 [==============================] - 0s 910us/step - loss: 0.0092 - MSE: 0.0092 - val_loss: 0.0070 - val_MSE: 0.0070\n",
      "Epoch 14/100\n",
      "507/507 [==============================] - 0s 876us/step - loss: 0.0061 - MSE: 0.0061 - val_loss: 0.0076 - val_MSE: 0.0076\n",
      "Epoch 15/100\n",
      "507/507 [==============================] - 0s 843us/step - loss: 0.0063 - MSE: 0.0063 - val_loss: 0.0112 - val_MSE: 0.0112\n",
      "Epoch 16/100\n",
      "507/507 [==============================] - 0s 887us/step - loss: 0.0080 - MSE: 0.0080 - val_loss: 0.0072 - val_MSE: 0.0072\n",
      "Epoch 17/100\n",
      "507/507 [==============================] - 0s 872us/step - loss: 0.0060 - MSE: 0.0060 - val_loss: 0.0073 - val_MSE: 0.0073\n",
      "QWK, Prompt 8, Fold 2: 0.6115866193234909\n",
      "Fold 3\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (723, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 507 samples, validate on 108 samples\n",
      "Epoch 1/100\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.0343 - MSE: 0.0343 - val_loss: 0.0134 - val_MSE: 0.0134\n",
      "Epoch 2/100\n",
      "507/507 [==============================] - 0s 955us/step - loss: 0.0128 - MSE: 0.0128 - val_loss: 0.0073 - val_MSE: 0.0073\n",
      "Epoch 3/100\n",
      "507/507 [==============================] - 0s 887us/step - loss: 0.0082 - MSE: 0.0082 - val_loss: 0.0077 - val_MSE: 0.0077\n",
      "Epoch 4/100\n",
      "507/507 [==============================] - 0s 920us/step - loss: 0.0073 - MSE: 0.0073 - val_loss: 0.0072 - val_MSE: 0.0072\n",
      "Epoch 5/100\n",
      "507/507 [==============================] - 0s 912us/step - loss: 0.0075 - MSE: 0.0075 - val_loss: 0.0073 - val_MSE: 0.0073\n",
      "Epoch 6/100\n",
      "507/507 [==============================] - 0s 864us/step - loss: 0.0069 - MSE: 0.0069 - val_loss: 0.0065 - val_MSE: 0.0065\n",
      "Epoch 7/100\n",
      "507/507 [==============================] - 0s 867us/step - loss: 0.0070 - MSE: 0.0070 - val_loss: 0.0073 - val_MSE: 0.0073\n",
      "Epoch 8/100\n",
      "507/507 [==============================] - 0s 879us/step - loss: 0.0072 - MSE: 0.0072 - val_loss: 0.0066 - val_MSE: 0.0066\n",
      "Epoch 9/100\n",
      "507/507 [==============================] - 0s 831us/step - loss: 0.0067 - MSE: 0.0067 - val_loss: 0.0086 - val_MSE: 0.0086\n",
      "Epoch 10/100\n",
      "507/507 [==============================] - 0s 865us/step - loss: 0.0066 - MSE: 0.0066 - val_loss: 0.0072 - val_MSE: 0.0072\n",
      "Epoch 11/100\n",
      "507/507 [==============================] - 0s 827us/step - loss: 0.0064 - MSE: 0.0064 - val_loss: 0.0066 - val_MSE: 0.0066\n",
      "Epoch 12/100\n",
      "507/507 [==============================] - 0s 838us/step - loss: 0.0071 - MSE: 0.0071 - val_loss: 0.0076 - val_MSE: 0.0076\n",
      "Epoch 13/100\n",
      "507/507 [==============================] - 0s 846us/step - loss: 0.0069 - MSE: 0.0069 - val_loss: 0.0087 - val_MSE: 0.0087\n",
      "Epoch 14/100\n",
      "507/507 [==============================] - 0s 823us/step - loss: 0.0077 - MSE: 0.0077 - val_loss: 0.0086 - val_MSE: 0.0086\n",
      "Epoch 15/100\n",
      "507/507 [==============================] - 0s 849us/step - loss: 0.0064 - MSE: 0.0064 - val_loss: 0.0074 - val_MSE: 0.0074\n",
      "Epoch 16/100\n",
      "507/507 [==============================] - ETA: 0s - loss: 0.0067 - MSE: 0.006 - 0s 879us/step - loss: 0.0067 - MSE: 0.0067 - val_loss: 0.0077 - val_MSE: 0.0077\n",
      "QWK, Prompt 8, Fold 3: 0.7194503554126861\n",
      "Fold 4\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (723, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 507 samples, validate on 108 samples\n",
      "Epoch 1/100\n",
      "507/507 [==============================] - 8s 16ms/step - loss: 0.0389 - MSE: 0.0389 - val_loss: 0.0094 - val_MSE: 0.0094\n",
      "Epoch 2/100\n",
      "507/507 [==============================] - 0s 923us/step - loss: 0.0097 - MSE: 0.0097 - val_loss: 0.0071 - val_MSE: 0.0071\n",
      "Epoch 3/100\n",
      "507/507 [==============================] - 0s 882us/step - loss: 0.0080 - MSE: 0.0080 - val_loss: 0.0064 - val_MSE: 0.0064\n",
      "Epoch 4/100\n",
      "507/507 [==============================] - 0s 946us/step - loss: 0.0082 - MSE: 0.0082 - val_loss: 0.0111 - val_MSE: 0.0111\n",
      "Epoch 5/100\n",
      "507/507 [==============================] - 0s 878us/step - loss: 0.0094 - MSE: 0.0094 - val_loss: 0.0061 - val_MSE: 0.0061\n",
      "Epoch 6/100\n",
      "507/507 [==============================] - 0s 871us/step - loss: 0.0078 - MSE: 0.0078 - val_loss: 0.0191 - val_MSE: 0.0191\n",
      "Epoch 7/100\n",
      "507/507 [==============================] - 0s 883us/step - loss: 0.0104 - MSE: 0.0104 - val_loss: 0.0057 - val_MSE: 0.0057\n",
      "Epoch 8/100\n",
      "507/507 [==============================] - 0s 845us/step - loss: 0.0079 - MSE: 0.0079 - val_loss: 0.0061 - val_MSE: 0.0061\n",
      "Epoch 9/100\n",
      "507/507 [==============================] - 0s 857us/step - loss: 0.0064 - MSE: 0.0064 - val_loss: 0.0057 - val_MSE: 0.0057\n",
      "Epoch 10/100\n",
      "507/507 [==============================] - 0s 869us/step - loss: 0.0073 - MSE: 0.0073 - val_loss: 0.0055 - val_MSE: 0.0055\n",
      "Epoch 11/100\n",
      "507/507 [==============================] - 0s 876us/step - loss: 0.0072 - MSE: 0.0072 - val_loss: 0.0102 - val_MSE: 0.0102\n",
      "Epoch 12/100\n",
      "507/507 [==============================] - 0s 938us/step - loss: 0.0085 - MSE: 0.0085 - val_loss: 0.0084 - val_MSE: 0.0084\n",
      "Epoch 13/100\n",
      "507/507 [==============================] - 0s 837us/step - loss: 0.0075 - MSE: 0.0075 - val_loss: 0.0060 - val_MSE: 0.0060\n",
      "Epoch 14/100\n",
      "507/507 [==============================] - 0s 899us/step - loss: 0.0062 - MSE: 0.0062 - val_loss: 0.0056 - val_MSE: 0.0056\n",
      "Epoch 15/100\n",
      "507/507 [==============================] - 1s 987us/step - loss: 0.0058 - MSE: 0.0058 - val_loss: 0.0054 - val_MSE: 0.0054\n",
      "Epoch 16/100\n",
      "507/507 [==============================] - 0s 907us/step - loss: 0.0062 - MSE: 0.0062 - val_loss: 0.0057 - val_MSE: 0.0057\n",
      "Epoch 17/100\n",
      "507/507 [==============================] - 0s 907us/step - loss: 0.0059 - MSE: 0.0059 - val_loss: 0.0064 - val_MSE: 0.0064\n",
      "Epoch 18/100\n",
      "507/507 [==============================] - 0s 917us/step - loss: 0.0069 - MSE: 0.0069 - val_loss: 0.0102 - val_MSE: 0.0102\n",
      "Epoch 19/100\n",
      "507/507 [==============================] - 0s 969us/step - loss: 0.0070 - MSE: 0.0070 - val_loss: 0.0055 - val_MSE: 0.0055\n",
      "Epoch 20/100\n",
      "507/507 [==============================] - 1s 1ms/step - loss: 0.0057 - MSE: 0.0057 - val_loss: 0.0057 - val_MSE: 0.0057\n",
      "Epoch 21/100\n",
      "507/507 [==============================] - 1s 1ms/step - loss: 0.0057 - MSE: 0.0057 - val_loss: 0.0055 - val_MSE: 0.0055\n",
      "Epoch 22/100\n",
      "507/507 [==============================] - 0s 974us/step - loss: 0.0062 - MSE: 0.0062 - val_loss: 0.0058 - val_MSE: 0.0058\n",
      "Epoch 23/100\n",
      "507/507 [==============================] - 0s 946us/step - loss: 0.0058 - MSE: 0.0058 - val_loss: 0.0054 - val_MSE: 0.0054\n",
      "Epoch 24/100\n",
      "507/507 [==============================] - 0s 976us/step - loss: 0.0055 - MSE: 0.0055 - val_loss: 0.0067 - val_MSE: 0.0067\n",
      "Epoch 25/100\n",
      "507/507 [==============================] - 0s 928us/step - loss: 0.0060 - MSE: 0.0060 - val_loss: 0.0111 - val_MSE: 0.0111\n",
      "QWK, Prompt 8, Fold 4: 0.5077440054337625\n",
      "Fold 5\n",
      "Processing GloVe embedding\n",
      "Shape of data tensor: (723, 500)\n",
      "Splitting training/test data\n",
      "RNN:  | CNN: 300 | Agg: tmp\n",
      "Train on 507 samples, validate on 108 samples\n",
      "Epoch 1/100\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.0252 - MSE: 0.0252 - val_loss: 0.0126 - val_MSE: 0.0126\n",
      "Epoch 2/100\n",
      "507/507 [==============================] - 0s 918us/step - loss: 0.0115 - MSE: 0.0115 - val_loss: 0.0070 - val_MSE: 0.0070\n",
      "Epoch 3/100\n",
      "507/507 [==============================] - 0s 871us/step - loss: 0.0084 - MSE: 0.0084 - val_loss: 0.0062 - val_MSE: 0.0062\n",
      "Epoch 4/100\n",
      "507/507 [==============================] - 0s 857us/step - loss: 0.0097 - MSE: 0.0097 - val_loss: 0.0071 - val_MSE: 0.0071\n",
      "Epoch 5/100\n",
      "507/507 [==============================] - 0s 849us/step - loss: 0.0079 - MSE: 0.0079 - val_loss: 0.0066 - val_MSE: 0.0066\n",
      "Epoch 6/100\n",
      "507/507 [==============================] - 0s 818us/step - loss: 0.0077 - MSE: 0.0077 - val_loss: 0.0127 - val_MSE: 0.0127\n",
      "Epoch 7/100\n",
      "507/507 [==============================] - 0s 857us/step - loss: 0.0080 - MSE: 0.0080 - val_loss: 0.0090 - val_MSE: 0.0090\n",
      "Epoch 8/100\n",
      "507/507 [==============================] - 0s 948us/step - loss: 0.0073 - MSE: 0.0073 - val_loss: 0.0049 - val_MSE: 0.0049\n",
      "Epoch 9/100\n",
      "507/507 [==============================] - 0s 931us/step - loss: 0.0064 - MSE: 0.0064 - val_loss: 0.0057 - val_MSE: 0.0057\n",
      "Epoch 10/100\n",
      "507/507 [==============================] - 0s 891us/step - loss: 0.0068 - MSE: 0.0068 - val_loss: 0.0086 - val_MSE: 0.0086\n",
      "Epoch 11/100\n",
      "507/507 [==============================] - 0s 880us/step - loss: 0.0072 - MSE: 0.0072 - val_loss: 0.0048 - val_MSE: 0.0048\n",
      "Epoch 12/100\n",
      "507/507 [==============================] - 0s 857us/step - loss: 0.0064 - MSE: 0.0064 - val_loss: 0.0091 - val_MSE: 0.0091\n",
      "Epoch 13/100\n",
      "507/507 [==============================] - 0s 859us/step - loss: 0.0071 - MSE: 0.0071 - val_loss: 0.0058 - val_MSE: 0.0058\n",
      "Epoch 14/100\n",
      "507/507 [==============================] - 0s 894us/step - loss: 0.0061 - MSE: 0.0061 - val_loss: 0.0052 - val_MSE: 0.0052\n",
      "Epoch 15/100\n",
      "507/507 [==============================] - 0s 864us/step - loss: 0.0079 - MSE: 0.0079 - val_loss: 0.0134 - val_MSE: 0.0134\n",
      "Epoch 16/100\n",
      "507/507 [==============================] - 0s 874us/step - loss: 0.0116 - MSE: 0.0116 - val_loss: 0.0063 - val_MSE: 0.0063\n",
      "Epoch 17/100\n",
      "507/507 [==============================] - 0s 868us/step - loss: 0.0072 - MSE: 0.0072 - val_loss: 0.0062 - val_MSE: 0.0062\n",
      "Epoch 18/100\n",
      "507/507 [==============================] - 0s 878us/step - loss: 0.0093 - MSE: 0.0093 - val_loss: 0.0070 - val_MSE: 0.0070\n",
      "Epoch 19/100\n",
      "507/507 [==============================] - 0s 916us/step - loss: 0.0071 - MSE: 0.0071 - val_loss: 0.0050 - val_MSE: 0.0050\n",
      "Epoch 20/100\n",
      "507/507 [==============================] - 0s 925us/step - loss: 0.0068 - MSE: 0.0068 - val_loss: 0.0094 - val_MSE: 0.0094\n",
      "Epoch 21/100\n",
      "507/507 [==============================] - 0s 860us/step - loss: 0.0062 - MSE: 0.0062 - val_loss: 0.0056 - val_MSE: 0.0056\n",
      "QWK, Prompt 8, Fold 5: 0.6213649559612262\n",
      "Processing time: 1:15:36.566657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pipeline('LSTM_CNN','lstm',1,'tmp')\n",
    "# pipeline('LSTM','lstm',0,'tmp')\n",
    "# pipeline('RNN_CNN','rnn',1,'tmp')\n",
    "# pipeline('BLSTM_CNN','blstm',1,'mot')\n",
    "# pipeline('BLSTM','blstm',0,'mot')\n",
    "# pipeline('RNN','rnn',0,'tmp')\n",
    "# pipeline('GRU_CNN','gru',1,'tmp')\n",
    "# pipeline('GRU','gru',0,'tmp')\n",
    "pipeline('CNN','',1,'tmp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
